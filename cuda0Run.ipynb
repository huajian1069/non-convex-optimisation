{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import skimage.measure\n",
    "import plyfile\n",
    "from plyfile import PlyData\n",
    "from sklearn.neighbors import KDTree\n",
    "import trimesh\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import cma\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pressure_predictor(load_directory):\n",
    "    model = SplineCNN8Residuals(3)\n",
    "    model.load_state_dict(torch.load(load_directory + \"/cfdModel.nn\"))\n",
    "    return model.to(\"cuda:0\").eval()\n",
    "\n",
    "def load_latent_vectors(load_directory, checkpoint):\n",
    "    filename = os.path.join(\n",
    "        load_directory, checkpoint + \".pth\"\n",
    "    )\n",
    "    if not os.path.isfile(filename):\n",
    "        raise Exception(\n",
    "            \"The experiment directory ({}) does not include a latent code file\"\n",
    "            + \" for checkpoint '{}'\".format(load_directory, checkpoint)\n",
    "        )\n",
    "    data = torch.load(filename)\n",
    "    return data[\"latent_codes\"].cuda(0)\n",
    "\n",
    "def load_decoder(load_directory, checkpoint):\n",
    "    specs_filename = os.path.join(load_directory, \"specs.json\")\n",
    "    if not os.path.isfile(specs_filename):\n",
    "        raise Exception(\n",
    "            'The experiment directory does not include specifications file \"specs.json\"'\n",
    "        )\n",
    "    specs = json.load(open(specs_filename))\n",
    "    latent_size = specs[\"CodeLength\"]\n",
    "    decoder = Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "    decoder = torch.nn.DataParallel(decoder)\n",
    "    saved_model_state = torch.load(os.path.join(load_directory, checkpoint +\".pth\"))\n",
    "    decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "    decoder = decoder.module.cuda(0)\n",
    "    decoder.eval()\n",
    "    return decoder\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_size,\n",
    "        dims,\n",
    "        dropout=None,\n",
    "        dropout_prob=0.0,\n",
    "        norm_layers=(),\n",
    "        latent_in=(),\n",
    "        weight_norm=False,\n",
    "        xyz_in_all=None,\n",
    "        use_tanh=False,\n",
    "        latent_dropout=False,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        def make_sequence():\n",
    "            return []\n",
    "\n",
    "        dims = [latent_size + 3] + dims + [1]\n",
    "\n",
    "        self.num_layers = len(dims)\n",
    "        self.norm_layers = norm_layers\n",
    "        self.latent_in = latent_in\n",
    "        self.latent_dropout = latent_dropout\n",
    "        if self.latent_dropout:\n",
    "            self.lat_dp = nn.Dropout(0.2)\n",
    "\n",
    "        self.xyz_in_all = xyz_in_all\n",
    "        self.weight_norm = weight_norm\n",
    "\n",
    "        for layer in range(0, self.num_layers - 1):\n",
    "            if layer + 1 in latent_in:\n",
    "                out_dim = dims[layer + 1] - dims[0]\n",
    "            else:\n",
    "                out_dim = dims[layer + 1]\n",
    "                if self.xyz_in_all and layer != self.num_layers - 2:\n",
    "                    out_dim -= 3\n",
    "\n",
    "            if weight_norm and layer in self.norm_layers:\n",
    "                setattr(\n",
    "                    self,\n",
    "                    \"lin\" + str(layer),\n",
    "                    nn.utils.weight_norm(nn.Linear(dims[layer], out_dim)),\n",
    "                )\n",
    "            else:\n",
    "                setattr(self, \"lin\" + str(layer), nn.Linear(dims[layer], out_dim))\n",
    "\n",
    "            if (\n",
    "                (not weight_norm)\n",
    "                and self.norm_layers is not None\n",
    "                and layer in self.norm_layers\n",
    "            ):\n",
    "                setattr(self, \"bn\" + str(layer), nn.LayerNorm(out_dim))\n",
    "\n",
    "        self.use_tanh = use_tanh\n",
    "        if use_tanh:\n",
    "            self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.dropout = dropout\n",
    "        self.th = nn.Tanh()\n",
    "\n",
    "    # input: N x (L+3)\n",
    "    def forward(self, input):\n",
    "        xyz = input[:, -3:]\n",
    "\n",
    "        if input.shape[1] > 3 and self.latent_dropout:\n",
    "            latent_vecs = input[:, :-3]\n",
    "            latent_vecs = F.dropout(latent_vecs, p=0.2, training=self.training)\n",
    "            x = torch.cat([latent_vecs, xyz], 1)\n",
    "        else:\n",
    "            x = input\n",
    "\n",
    "        for layer in range(0, self.num_layers - 1):\n",
    "            lin = getattr(self, \"lin\" + str(layer))\n",
    "            if layer in self.latent_in:\n",
    "                x = torch.cat([x, input], 1)\n",
    "            elif layer != 0 and self.xyz_in_all:\n",
    "                x = torch.cat([x, xyz], 1)\n",
    "            x = lin(x)\n",
    "            # last layer Tanh\n",
    "            if layer == self.num_layers - 2 and self.use_tanh:\n",
    "                x = self.tanh(x)\n",
    "            if layer < self.num_layers - 2:\n",
    "                if (\n",
    "                    self.norm_layers is not None\n",
    "                    and layer in self.norm_layers\n",
    "                    and not self.weight_norm\n",
    "                ):\n",
    "                    bn = getattr(self, \"bn\" + str(layer))\n",
    "                    x = bn(x)\n",
    "                x = self.relu(x)\n",
    "                if self.dropout is not None and layer in self.dropout:\n",
    "                    x = F.dropout(x, p=self.dropout_prob, training=self.training)\n",
    "\n",
    "        if hasattr(self, \"th\"):\n",
    "            x = self.th(x)\n",
    "\n",
    "        return x\n",
    "class SplineBlock(nn.Module):\n",
    "    def __init__(self, num_in_features, num_outp_features, mid_features, kernel=3, dim=3, batchnorm1=True):\n",
    "        super(SplineBlock, self).__init__()\n",
    "        self.batchnorm1 = batchnorm1\n",
    "        self.conv1 = SplineConv(num_in_features, mid_features, dim, kernel, is_open_spline=False)\n",
    "        if self.batchnorm1:\n",
    "            self.batchnorm1 = torch.nn.BatchNorm1d(mid_features)\n",
    "        self.conv2 = SplineConv(mid_features, 2 * mid_features, dim, kernel, is_open_spline=False)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(2 * mid_features)\n",
    "        self.conv3 = SplineConv(2 * mid_features + 3, num_outp_features, dim, kernel, is_open_spline=False)\n",
    "  \n",
    "    def forward(self, res, data):\n",
    "        if self.batchnorm1:\n",
    "            res = F.elu(self.batchnorm1(self.conv1(res, data['edge_index'], data['edge_attr'])))\n",
    "        else:\n",
    "            res = F.elu(self.conv1(res, data['edge_index'], data['edge_attr']))\n",
    "        res = F.elu(self.batchnorm2(self.conv2(res, data['edge_index'], data['edge_attr'])))\n",
    "#         res = F.elu(self.conv2(res, data.edge_index, data.edge_attr))\n",
    "        res = torch.cat([res, data['x']], dim=1)\n",
    "        res = self.conv3(res, data['edge_index'], data['edge_attr'])\n",
    "        return res\n",
    "\n",
    "class SplineCNN8Residuals(nn.Module):\n",
    "    def __init__(self, num_features, kernel=3, dim=3):\n",
    "        super(SplineCNN8Residuals, self).__init__()\n",
    "        self.block1 = SplineBlock(num_features, 16, 8, kernel, dim)\n",
    "        self.block2 = SplineBlock(16, 64, 32, kernel, dim)\n",
    "        self.block3 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block4 = SplineBlock(64, 8, 16, kernel, dim)\n",
    "        self.block5 = SplineBlock(11, 32, 16, kernel, dim)\n",
    "        self.block6 = SplineBlock(32, 64, 32, kernel, dim)\n",
    "        self.block7 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block8 = SplineBlock(75, 4, 16, kernel, dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        res = data['x']\n",
    "        res = self.block1(res, data)\n",
    "        res = self.block2(res, data)\n",
    "        res = self.block3(res, data)\n",
    "        res4 = self.block4(res, data)\n",
    "        res = torch.cat([res4, data['x']], dim=1)\n",
    "        res = self.block5(res, data)\n",
    "        res = self.block6(res, data)\n",
    "        res = self.block7(res, data)\n",
    "        res = torch.cat([res, res4, data['x']], dim=1)\n",
    "        res = self.block8(res, data)\n",
    "        return res\n",
    "\n",
    "def create_mesh(\n",
    "    decoder, latent_vec, filename='', N=256, max_batch=32 ** 3, offset=None, scale=None\n",
    "):\n",
    "    ply_filename = filename\n",
    "\n",
    "    decoder.eval()\n",
    "\n",
    "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "    voxel_origin = [-1, -1, -1]\n",
    "    voxel_size = 2.0 / (N - 1)\n",
    "\n",
    "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "    samples = torch.zeros(N ** 3, 4).cuda()\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z index\n",
    "    samples[:, 2] = overall_index % N\n",
    "    samples[:, 1] = (overall_index.long() // N) % N\n",
    "    samples[:, 0] = ((overall_index.long() // N) // N) % N\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z coordinate\n",
    "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
    "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
    "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
    "\n",
    "    num_samples = N ** 3\n",
    "\n",
    "    samples.requires_grad = False\n",
    "    head = 0\n",
    "\n",
    "    while head < num_samples:\n",
    "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda(0)\n",
    "        num_subsample = min(max_batch, num_samples-head)\n",
    "        latent_repeat = latent_vec.expand(num_subsample, -1)\n",
    "        inputs = torch.cat([latent_repeat, sample_subset], 1)\n",
    "        samples[head : min(head + max_batch, num_samples), 3] = \\\n",
    "                decoder(inputs).squeeze(1).detach()\n",
    "        head += max_batch\n",
    "        \n",
    "    sdf_values = samples[:, 3].reshape(N, N, N).data\n",
    "\n",
    "    return convert_sdf_samples_to_ply(\n",
    "        sdf_values,\n",
    "        voxel_origin,\n",
    "        voxel_size,\n",
    "        ply_filename + \".ply\",\n",
    "        offset,\n",
    "        scale,\n",
    "    )\n",
    "\n",
    "def convert_sdf_samples_to_ply(\n",
    "    pytorch_3d_sdf_tensor,\n",
    "    voxel_grid_origin,\n",
    "    voxel_size,\n",
    "    ply_filename_out,\n",
    "    offset=None,\n",
    "    scale=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert sdf samples to .ply\n",
    "\n",
    "    :param pytorch_3d_sdf_tensor: a torch.FloatTensor of shape (n,n,n)\n",
    "    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n",
    "    :voxel_size: float, the size of the voxels\n",
    "    :ply_filename_out: string, path of the filename to save to\n",
    "\n",
    "    This function adapted from: https://github.com/RobotLocomotion/spartan\n",
    "    \"\"\"\n",
    "\n",
    "    numpy_3d_sdf_tensor = pytorch_3d_sdf_tensor.cpu().numpy()\n",
    "\n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes_lewiner(\n",
    "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3\n",
    "    )\n",
    "\n",
    "    # transform from voxel coordinates to camera coordinates\n",
    "    # note x and y are flipped in the output of marching_cubes\n",
    "    mesh_points = np.zeros_like(verts)\n",
    "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
    "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
    "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
    "\n",
    "    # apply additional offset and scale\n",
    "    if scale is not None:\n",
    "        mesh_points = mesh_points / scale\n",
    "    if offset is not None:\n",
    "        mesh_points = mesh_points - offset\n",
    "\n",
    "    # try writing to the ply file\n",
    "\n",
    "    num_verts = verts.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "\n",
    "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "    norms_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "\n",
    "    for i in range(0, num_verts):\n",
    "        verts_tuple[i] = tuple(mesh_points[i, :])\n",
    "        norms_tuple[i] = tuple(normals[i, :])\n",
    "\n",
    "    faces_building = []\n",
    "    for i in range(0, num_faces):\n",
    "        faces_building.append(((faces[i, :].tolist(),)))\n",
    "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
    "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
    "    el_norms = plyfile.PlyElement.describe(norms_tuple, \"normals\")\n",
    "\n",
    "    ply_data = plyfile.PlyData([el_verts, el_faces, el_norms])\n",
    "    return ply_data\n",
    "\n",
    "def compute_lift_faces_diff(mesh, preds):\n",
    "    pressures = torch.mean(preds[mesh['face'], 0], axis=0)\n",
    "\n",
    "    # TODO: cahnge to x if needed\n",
    "    pos = mesh['x']\n",
    "    cross_prod = (pos[mesh['face'][1]] - pos[mesh['face'][0]]).cross(\n",
    "                  pos[mesh['face'][2]] - pos[mesh['face'][0]])\n",
    "    area = -cross_prod[:, 0] / 2\n",
    "    lift = torch.mul(pressures, area)\n",
    "    return torch.sum(lift[~torch.isnan(lift)])\n",
    "\n",
    "def boundsLoss(points, box=[(-1, 1, 0)]):\n",
    "    loss = 0\n",
    "    for l, r, i in box:\n",
    "        loss +=  torch.mean(F.relu(-points[:, i] + l))  \\\n",
    "               + torch.mean(F.relu( points[:, i] - r))\n",
    "    return loss\n",
    "\n",
    "def innerBoundsLoss(points, r=1, center=(0, 0, 0)):\n",
    "    radiuses = torch.sum( (points - torch.Tensor(center).to('cuda:0')) ** 2 , dim=1)\n",
    "    return torch.mean(F.relu(r - radiuses))\n",
    "\n",
    "def calculate_loss(mesh, local_preds, constraint_rad=0.1):\n",
    "    loss = compute_lift_faces_diff(mesh, local_preds)\n",
    "    first = loss.clone().detach().cpu().numpy()\n",
    "    loss += boundsLoss(mesh['x'], box=[(-0.6, 0.6, 0)])\n",
    "    second = loss.clone().detach().cpu().numpy()\n",
    "    loss += innerBoundsLoss(mesh['x'], r=constraint_rad**2, center=(-0.05, 0.05, 0))  \\\n",
    "          + innerBoundsLoss(mesh['x'], r=(constraint_rad / 2)**2, center=(0.3, 0, 0))\n",
    "    print(\"three parts (321) of loss: %.3f, %.3f, %.3f\"%(loss.detach().cpu().numpy() - second, second-first, first))\n",
    "    return loss\n",
    "\n",
    "def transformPoints(points, AvgTransform):\n",
    "    matrix = torch.cuda.FloatTensor(AvgTransform).cuda(0)\n",
    "    column = torch.zeros((len(points), 1), device=\"cuda:0\") + 1\n",
    "    stacked = torch.cat([points, column], dim=1)\n",
    "    transformed = torch.matmul(matrix, stacked.t()).t()[:, :3]\n",
    "    return transformed\n",
    "\n",
    "def transform_mesh(points, ply_mesh, AvgTransform):\n",
    "    transformed_points = transformPoints(points, AvgTransform)\n",
    "    \n",
    "    edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
    "    np_points = transformed_points.cpu().detach().numpy()\n",
    "    edge_attr = [np_points[a] - np_points[b] for a, b in edges]\n",
    "    mesh = {'x': transformed_points, \n",
    "        'face':torch.tensor(ply_mesh['face']['vertex_indices'], dtype=torch.long).to('cuda:0').t(),\n",
    "        'edge_attr':torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "        'edge_index':torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0')\n",
    "        }\n",
    "    return mesh\n",
    "\n",
    "\n",
    "def decode_sdf(decoder, latent_vector, queries):\n",
    "    num_samples = queries.shape[0]\n",
    "\n",
    "    if latent_vector is None:\n",
    "        inputs = queries\n",
    "    else:\n",
    "        latent_repeat = latent_vector.expand(num_samples, -1)\n",
    "        inputs = torch.cat([latent_repeat, queries], 1)\n",
    "\n",
    "    sdf = decoder(inputs)\n",
    "\n",
    "    return sdf\n",
    "\n",
    "\n",
    "def get_trimesh_from_torch_geo_with_colors(mesh, preds, vmin=-8, vmax=8):\n",
    "    norm = mpl.colors.Normalize(vmin= vmin, vmax=vmax)\n",
    "    cmap = cm.hot\n",
    "    m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    \n",
    "    verticies = mesh['x'].cpu().detach()\n",
    "    faces = mesh['face'].t().cpu().detach()\n",
    "    return trimesh.Trimesh(vertices=verticies, faces=faces, \n",
    "                           vertex_colors=list(map(lambda c: m.to_rgba(c),  preds[:, 0].cpu().detach())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_to_load_data = '../Non-convex/starting_data'\n",
    "experiment_directory = \"data_for_this_experiments\"\n",
    "\n",
    "model = load_pressure_predictor(DIR_to_load_data)\n",
    "\n",
    "decoder = load_decoder(DIR_to_load_data, \"decoderModel\")\n",
    "\n",
    "latent_vectors = load_latent_vectors(DIR_to_load_data, \"latentCodes\").detach()\n",
    "\n",
    "AvgTransform = np.load(DIR_to_load_data + \"/avg_trans_matrix.npy\") #computeAvgTransform()\n",
    "\n",
    "LATENT_TO_OPTIMIZE = latent_vectors[32]\n",
    "LATENT_KD_TREE = KDTree(np.array([lv.cpu().detach().numpy()[0] for lv in latent_vectors]))\n",
    "# /cvlabdata2/home/artem/Data/cars_remeshed_dsdf/transforms/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_result_20 = latent_vectors.squeeze()\n",
    "#LATENT_KD_TREE_20d = KDTree(pca_result_20)\n",
    "\n",
    "#pca_result_20_t = torch.tensor(pca_result_20, dtype=torch.float).cuda(0)\n",
    "def func2d(latent):\n",
    "    latent = torch.tensor(latent, dtype=torch.float).cuda(0).reshape(1,-1)\n",
    "    distances, indeces = LATENT_KD_TREE.query(latent.cpu().detach().reshape(1,-1), k=10)\n",
    "    pen = 0.2 * torch.sum((latent - latent_vectors.squeeze()[indeces.squeeze()]) ** 2, dim=1).mean() \n",
    "    if pen > 0.5:\n",
    "        return 100.0\n",
    "    return pen.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three parts (321) of loss: 0.000, 0.000, 0.072\n",
      "iter time:  17.532371044158936\n",
      "penalty:  0.04936825856566429\n",
      "full:  0.12116144597530365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12116144597530365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_drag(latent_vectors[126])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cma_new_latent_reg = np.load(\"../Compare_optimisers/new_cma/cma_withReg_dif_loc32PCA.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three parts (321) of loss: 0.000, 0.000, -0.012\n",
      "iter time:  15.902981042861938\n",
      "penalty:  0.09217564016580582\n",
      "full:  0.07993105798959732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07993105798959732"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_drag(cma_new_latent_reg[-1, 8, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "IN_N = 5\n",
    "\n",
    "def func_drag(latent):\n",
    "    start = time.time()\n",
    "    latent = torch.tensor(latent, dtype=torch.float).cuda(0).reshape(1,-1)\n",
    "    with torch.no_grad():\n",
    "        ply_mesh = create_mesh(decoder,\n",
    "                                    latent,\n",
    "                                    N=N,\n",
    "                                    max_batch=int(2 ** 18),\n",
    "                                    offset=None,\n",
    "                                    scale=None)\n",
    "    #print(\"************out of space***********\", e)\n",
    "    points = torch.tensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                      ply_mesh['vertex']['y'][:, None], \n",
    "                                      ply_mesh['vertex']['z'][:, None]))).cuda(0)\n",
    "    mesh = transform_mesh(points, ply_mesh, AvgTransform)\n",
    "    local_preds = model(mesh)\n",
    "    loss = calculate_loss(mesh, local_preds, constraint_rad=0.05)\n",
    "    end = time.time()\n",
    "    print(\"iter time: \", end-start)\n",
    "    return (loss).item()\n",
    "\n",
    "def func_grad(latent):\n",
    "    #try:\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        ply_mesh = create_mesh(decoder,\n",
    "                                    latent,\n",
    "                                    N=N,\n",
    "                                    max_batch=int(2 ** 18),\n",
    "                                    offset=None,\n",
    "                                    scale=None)\n",
    "    end = time.time()\n",
    "    print(\"mesh time: \", end-start)\n",
    "   # except Exception as e:\n",
    "   #     raise e\n",
    "   #     print(\"************out of space***********\", e)\n",
    "    points = torch.tensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                      ply_mesh['vertex']['y'][:, None], \n",
    "                                      ply_mesh['vertex']['z'][:, None]))).cuda(0)\n",
    "    points.requires_grad = True\n",
    "    sdf_value = decode_sdf(decoder, latent.detach(), points)\n",
    "    sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda(0))\n",
    "    \n",
    "    initial_dir = points.grad.clone()\n",
    "    points.grad.data.zero_()\n",
    "    mesh = transform_mesh(points, ply_mesh, AvgTransform)\n",
    "    local_preds = model(mesh)\n",
    "    phy_loss = calculate_loss(mesh, local_preds, constraint_rad=0.05)\n",
    "    phy_loss.backward()\n",
    "    sign = [-p1.dot(p2) for p1, p2 in zip(initial_dir, points.grad)]\n",
    "    \n",
    "    multipliers = torch.cuda.FloatTensor(sign).cuda(0)\n",
    "    sdf_value = torch.squeeze(decode_sdf(decoder, latent, points.detach()))\n",
    "    math_loss = torch.sum(sdf_value * multipliers)\n",
    "    apenalty = func2d(latent)\n",
    "    (math_loss + apenalty).backward()\n",
    "    final = time.time()\n",
    "    print(\"iter time: \", final-start)\n",
    "    print(\"penalty: \", apenalty.item())\n",
    "    print(\"full: \", (phy_loss + apenalty).item(), '\\n')\n",
    "    return (phy_loss+apenalty).item()\n",
    "\n",
    "def inner_opt(x, Xs, fits):\n",
    "    x = torch.tensor(x, dtype=torch.float).cuda(0).requires_grad_(True)\n",
    "    opt = torch.optim.SGD([x], lr=0.4)\n",
    "    i = 0\n",
    "    while i < IN_N:\n",
    "        phy_loss = func_grad(x)\n",
    "        Xs.append(x.clone().cpu().detach().numpy())\n",
    "        fits.append(phy_loss)\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        i += 1\n",
    "        if i == IN_N:\n",
    "            fit = phy_loss\n",
    "        np.save(\"../Compare_optimisers/new_cma_sgd/cma_sgd_withReg_2.npy\", Xs)\n",
    "        np.save(\"../Compare_optimisers/new_cma_sgd/cma_sgd_fitness_withReg_2.npy\", fits)\n",
    "    print(\"one time is done\", len(Xs), \"\\n\")\n",
    "    return x.detach().cpu().numpy(), fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x0, sigma0 = latent_vectors[32].cpu().numpy(), 0.05\n",
    "#%time inner_opt(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, sigma0 = latent_vectors[254].cpu().numpy(), 0.05\n",
    "es = cma.CMAEvolutionStrategy(x0, sigma0)\n",
    "i = 0\n",
    "Xs = []\n",
    "fits = []\n",
    "Xqueue = []\n",
    "fiTqueue = []\n",
    "while i < 30:\n",
    "    X = es.ask()\n",
    "    if i == 0:\n",
    "        new_x_fit = [inner_opt(x, Xs, fits) for x in X]\n",
    "    else:\n",
    "        new_x_fit = [inner_opt(x, Xs, fits) for x in X[:5]]\n",
    "    X, fitness = zip(*new_x_fit)\n",
    "    Xqueue += X\n",
    "    fiTqueue += fitness\n",
    "    #Xs.append(X)\n",
    "    #fits.append(fitness)\n",
    "    es.tell(Xqueue[-20:], fiTqueue[-20:])\n",
    "    es.disp(1)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "data_avg = latent_vectors - latent_vectors.mean(dim=0)\n",
    "pca_2 = PCA(n_components=50)\n",
    "pca_2.fit(data_avg.cpu().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f24a80416d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2 = pca_2.transform(latent_vectors.squeeze().cpu())\n",
    "d34 = pca_2.transform(latent_vectors[32].cpu())\n",
    "plt.scatter(d2[:,0], d2[:,1])\n",
    "plt.scatter(d34[0,0], d34[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, sigma0 = pca_2.transform(latent_vectors[32].cpu().numpy()), 0.3\n",
    "es = cma.CMAEvolutionStrategy(x0, sigma0)\n",
    "i = 0\n",
    "Xs = []\n",
    "fits = []\n",
    "pure_drags = []\n",
    "while i < 15:\n",
    "    X = es.ask()\n",
    "    fit = [func_drag(pca_2.inverse_transform(x)) for x in X]\n",
    "    apenalty = [func2d(pca_2.inverse_transform(x)) for x in X]\n",
    "    print(\"penalty: \", apenalty)\n",
    "    fitness = fit\n",
    "    fitness = [fit[j]+apenalty[j] for j in range(len(X))]\n",
    "    es.tell(X, fitness)\n",
    "    Xs.append(pca_2.inverse_transform(X))\n",
    "    fits.append(fitness)\n",
    "    #pure_drags.append(pure_drag)\n",
    "    np.save(\"../Compare_optimisers/new_cma/cma_withReg_dif_loc32PCA50.npy\", Xs)\n",
    "    np.save(\"../Compare_optimisers/new_cma/cma_fitness_withReg_dif_loc32PCA50.npy\", fits)\n",
    "    #pure_drags.save(\"../Compare_optimisers/new_cma/cma_pure_drag_noReg.npy\")\n",
    "    es.disp(1)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10_w,20)-aCMA-ES (mu_w=5.9,w_1=27%) in dimension 256 (seed=958968, Sat Sep 12 21:24:45 2020)\n",
      "three parts (321) of loss: 0.000, 0.000, 0.070\n",
      "iter time:  16.185012578964233\n",
      "three parts (321) of loss: 0.000, 0.000, 0.099\n",
      "iter time:  16.360897541046143\n",
      "three parts (321) of loss: 0.000, 0.000, 0.087\n",
      "iter time:  16.53553342819214\n",
      "three parts (321) of loss: 0.000, 0.000, 0.070\n",
      "iter time:  16.18245816230774\n",
      "three parts (321) of loss: 0.000, 0.000, 0.083\n",
      "iter time:  16.135868310928345\n",
      "three parts (321) of loss: 0.000, 0.000, 0.075\n",
      "iter time:  16.365902423858643\n",
      "three parts (321) of loss: 0.000, 0.000, 0.070\n",
      "iter time:  16.753356218338013\n",
      "three parts (321) of loss: 0.000, 0.000, 0.102\n",
      "iter time:  16.254286766052246\n",
      "three parts (321) of loss: 0.000, 0.000, 0.074\n",
      "iter time:  15.975697755813599\n",
      "three parts (321) of loss: 0.000, 0.000, 0.071\n",
      "iter time:  16.525811910629272\n",
      "three parts (321) of loss: 0.000, 0.000, 0.075\n",
      "iter time:  15.918381214141846\n",
      "three parts (321) of loss: 0.000, 0.000, 0.084\n",
      "iter time:  15.60683274269104\n",
      "three parts (321) of loss: 0.000, 0.000, 0.075\n",
      "iter time:  15.612653970718384\n",
      "three parts (321) of loss: 0.000, 0.000, 0.084\n",
      "iter time:  15.80264663696289\n",
      "three parts (321) of loss: 0.000, 0.000, 0.069\n",
      "iter time:  16.36414384841919\n",
      "three parts (321) of loss: 0.000, 0.000, 0.087\n",
      "iter time:  16.964178323745728\n",
      "three parts (321) of loss: 0.000, 0.000, 0.074\n",
      "iter time:  16.141392707824707\n",
      "three parts (321) of loss: 0.000, 0.000, 0.067\n",
      "iter time:  16.182460069656372\n",
      "three parts (321) of loss: 0.000, 0.000, 0.075\n",
      "iter time:  16.10864806175232\n",
      "three parts (321) of loss: 0.000, 0.000, 0.067\n",
      "iter time:  16.310340404510498\n",
      "penalty:  [0.19056400656700134, 0.21795260906219482, 0.18133477866649628, 0.20771291851997375, 0.2127426415681839, 0.20297066867351532, 0.203497514128685, 0.1797468066215515, 0.1882677525281906, 0.19367815554141998, 0.17351128160953522, 0.18905064463615417, 0.19854103028774261, 0.2224898636341095, 0.2157038301229477, 0.20367629826068878, 0.18131302297115326, 0.21985474228858948, 0.2013280838727951, 0.19135046005249023]\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     20 2.481431216001511e-01 1.0e+00 4.89e-02  5e-02  5e-02 5:24.3\n",
      "three parts (321) of loss: 0.000, 0.000, 0.074\n",
      "iter time:  16.326175451278687\n",
      "three parts (321) of loss: 0.000, 0.000, 0.087\n",
      "iter time:  16.02821707725525\n",
      "three parts (321) of loss: 0.000, 0.000, 0.083\n",
      "iter time:  15.51555871963501\n",
      "three parts (321) of loss: 0.000, 0.000, 0.060\n",
      "iter time:  16.12160634994507\n",
      "three parts (321) of loss: 0.000, 0.000, 0.049\n",
      "iter time:  16.01424264907837\n",
      "three parts (321) of loss: 0.000, 0.000, 0.050\n",
      "iter time:  16.11397099494934\n",
      "three parts (321) of loss: 0.000, 0.000, 0.069\n",
      "iter time:  16.67966938018799\n",
      "three parts (321) of loss: 0.000, 0.000, 0.070\n",
      "iter time:  16.24759030342102\n",
      "three parts (321) of loss: 0.000, 0.000, 0.058\n",
      "iter time:  16.174985647201538\n",
      "three parts (321) of loss: 0.000, 0.000, 0.070\n",
      "iter time:  15.591402769088745\n",
      "three parts (321) of loss: 0.000, 0.000, 0.077\n",
      "iter time:  15.777575492858887\n",
      "three parts (321) of loss: 0.000, 0.000, 0.087\n",
      "iter time:  15.859286785125732\n",
      "three parts (321) of loss: 0.000, 0.000, 0.066\n",
      "iter time:  16.3047137260437\n",
      "three parts (321) of loss: 0.000, 0.000, 0.064\n",
      "iter time:  16.09642219543457\n",
      "three parts (321) of loss: 0.000, 0.000, 0.070\n",
      "iter time:  16.08624005317688\n",
      "three parts (321) of loss: 0.000, 0.000, 0.087\n",
      "iter time:  15.935749292373657\n",
      "three parts (321) of loss: 0.000, 0.000, 0.050\n",
      "iter time:  15.985826969146729\n",
      "three parts (321) of loss: 0.000, 0.000, 0.075\n",
      "iter time:  16.085302591323853\n",
      "three parts (321) of loss: 0.000, 0.000, 0.061\n",
      "iter time:  15.715857982635498\n",
      "three parts (321) of loss: 0.000, 0.000, 0.060\n",
      "iter time:  15.969290971755981\n",
      "penalty:  [0.24505309760570526, 0.20065879821777344, 0.1924227625131607, 0.2071726769208908, 0.2169731855392456, 0.19691231846809387, 0.2116774171590805, 0.23458150029182434, 0.21445833146572113, 0.22244830429553986, 0.22042854130268097, 0.2068312019109726, 0.21239593625068665, 0.22391219437122345, 0.21164226531982422, 0.19107064604759216, 0.205027773976326, 0.21156609058380127, 0.24170167744159698, 0.20252855122089386]\n",
      "    2     40 2.470769211649895e-01 1.0e+00 4.79e-02  5e-02  5e-02 10:45.0\n",
      "three parts (321) of loss: 0.000, 0.000, 0.039\n",
      "iter time:  15.967324495315552\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.603142499923706\n",
      "three parts (321) of loss: 0.000, 0.000, 0.063\n",
      "iter time:  16.35787057876587\n",
      "three parts (321) of loss: 0.000, 0.000, 0.060\n",
      "iter time:  16.057586193084717\n",
      "three parts (321) of loss: 0.000, 0.000, 0.039\n",
      "iter time:  16.222118377685547\n",
      "three parts (321) of loss: 0.000, 0.000, 0.056\n",
      "iter time:  16.085233688354492\n",
      "three parts (321) of loss: 0.000, 0.000, 0.055\n",
      "iter time:  16.07826042175293\n",
      "three parts (321) of loss: 0.000, 0.000, 0.068\n",
      "iter time:  16.274145364761353\n",
      "three parts (321) of loss: 0.000, 0.000, 0.060\n",
      "iter time:  16.30041217803955\n",
      "three parts (321) of loss: 0.000, 0.000, 0.063\n",
      "iter time:  16.270121574401855\n",
      "three parts (321) of loss: 0.000, 0.000, 0.062\n",
      "iter time:  15.972990274429321\n",
      "three parts (321) of loss: 0.000, 0.000, 0.068\n",
      "iter time:  15.846304416656494\n",
      "three parts (321) of loss: 0.000, 0.000, 0.059\n",
      "iter time:  15.861788511276245\n",
      "three parts (321) of loss: 0.000, 0.000, 0.052\n",
      "iter time:  15.926291227340698\n",
      "three parts (321) of loss: 0.000, 0.000, 0.072\n",
      "iter time:  16.298214197158813\n",
      "three parts (321) of loss: 0.000, 0.000, 0.063\n",
      "iter time:  15.926962852478027\n",
      "three parts (321) of loss: 0.000, 0.000, 0.060\n",
      "iter time:  15.941381931304932\n",
      "three parts (321) of loss: 0.000, 0.000, 0.084\n",
      "iter time:  16.057544708251953\n",
      "three parts (321) of loss: 0.000, 0.000, 0.056\n",
      "iter time:  16.184875965118408\n",
      "three parts (321) of loss: 0.000, 0.000, 0.064\n",
      "iter time:  15.796656847000122\n",
      "penalty:  [0.23825518786907196, 0.22435115277767181, 0.23108096420764923, 0.228581503033638, 0.21229831874370575, 0.23719556629657745, 0.22949181497097015, 0.21338295936584473, 0.23102925717830658, 0.20458638668060303, 0.2044801563024521, 0.236870676279068, 0.1965906172990799, 0.20581641793251038, 0.2441495656967163, 0.23593704402446747, 0.21840448677539825, 0.208984375, 0.22138670086860657, 0.2127932757139206]\n",
      "    3     60 2.513431385159492e-01 1.0e+00 4.71e-02  5e-02  5e-02 16:06.1\n",
      "three parts (321) of loss: 0.000, 0.000, 0.047\n",
      "iter time:  15.911193370819092\n",
      "three parts (321) of loss: 0.000, 0.000, 0.039\n",
      "iter time:  15.683067560195923\n",
      "three parts (321) of loss: 0.000, 0.000, 0.057\n",
      "iter time:  15.430643320083618\n",
      "three parts (321) of loss: 0.000, 0.000, 0.054\n",
      "iter time:  15.463018417358398\n",
      "three parts (321) of loss: 0.000, 0.000, 0.061\n",
      "iter time:  15.810234069824219\n",
      "three parts (321) of loss: 0.000, 0.000, 0.066\n",
      "iter time:  15.981241703033447\n",
      "three parts (321) of loss: 0.000, 0.000, 0.069\n",
      "iter time:  15.906294345855713\n",
      "three parts (321) of loss: 0.000, 0.000, 0.043\n",
      "iter time:  15.82769775390625\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.6367928981781\n",
      "three parts (321) of loss: 0.000, 0.000, 0.074\n",
      "iter time:  15.690110921859741\n",
      "three parts (321) of loss: 0.000, 0.000, 0.046\n",
      "iter time:  15.597468137741089\n",
      "three parts (321) of loss: 0.000, 0.000, 0.080\n",
      "iter time:  16.12049174308777\n",
      "three parts (321) of loss: 0.000, 0.000, 0.055\n",
      "iter time:  15.94851803779602\n",
      "three parts (321) of loss: 0.000, 0.000, 0.051\n",
      "iter time:  15.484467267990112\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.767529726028442\n",
      "three parts (321) of loss: 0.000, 0.000, 0.022\n",
      "iter time:  15.320843696594238\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  16.431296348571777\n",
      "three parts (321) of loss: 0.000, 0.000, 0.024\n",
      "iter time:  15.171542167663574\n",
      "three parts (321) of loss: 0.000, 0.000, 0.064\n",
      "iter time:  15.463700771331787\n",
      "three parts (321) of loss: 0.000, 0.000, 0.068\n",
      "iter time:  15.658254384994507\n",
      "penalty:  [0.21958081424236298, 0.23429134488105774, 0.2609393000602722, 0.22727923095226288, 0.20627181231975555, 0.24378974735736847, 0.229856476187706, 0.22720372676849365, 0.2414458841085434, 0.24475975334644318, 0.22035005688667297, 0.2528934180736542, 0.20997893810272217, 0.19574283063411713, 0.22507870197296143, 0.24903152883052826, 0.24549010396003723, 0.22564561665058136, 0.23663654923439026, 0.24565552175045013]\n",
      "    4     80 2.472162991762161e-01 1.0e+00 4.63e-02  5e-02  5e-02 21:20.5\n",
      "three parts (321) of loss: 0.000, 0.000, 0.041\n",
      "iter time:  16.069232940673828\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.869618654251099\n",
      "three parts (321) of loss: 0.000, 0.000, 0.047\n",
      "iter time:  15.94493556022644\n",
      "three parts (321) of loss: 0.000, 0.000, 0.035\n",
      "iter time:  16.30379295349121\n",
      "three parts (321) of loss: 0.000, 0.000, 0.034\n",
      "iter time:  15.585746049880981\n",
      "three parts (321) of loss: 0.000, 0.000, 0.059\n",
      "iter time:  15.36235237121582\n",
      "three parts (321) of loss: 0.000, 0.000, 0.028\n",
      "iter time:  15.646089792251587\n",
      "three parts (321) of loss: 0.000, 0.000, 0.044\n",
      "iter time:  16.103735208511353\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  16.22461724281311\n",
      "three parts (321) of loss: 0.000, 0.000, 0.042\n",
      "iter time:  15.913613080978394\n",
      "three parts (321) of loss: 0.000, 0.000, 0.053\n",
      "iter time:  15.563764095306396\n",
      "three parts (321) of loss: 0.000, 0.000, 0.057\n",
      "iter time:  15.525336503982544\n",
      "three parts (321) of loss: 0.000, 0.000, 0.039\n",
      "iter time:  15.561805963516235\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.74524998664856\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  15.613316774368286\n",
      "three parts (321) of loss: 0.000, 0.000, 0.035\n",
      "iter time:  15.275941848754883\n",
      "three parts (321) of loss: 0.000, 0.000, 0.032\n",
      "iter time:  15.70092487335205\n",
      "three parts (321) of loss: 0.000, 0.000, 0.049\n",
      "iter time:  16.011640310287476\n",
      "three parts (321) of loss: 0.000, 0.000, 0.065\n",
      "iter time:  16.10579752922058\n",
      "three parts (321) of loss: 0.000, 0.000, 0.060\n",
      "iter time:  15.679612874984741\n",
      "penalty:  [0.234638974070549, 0.22934632003307343, 0.2378760427236557, 0.24902839958667755, 0.2256782352924347, 0.24634544551372528, 0.2279214709997177, 0.22187145054340363, 0.231964573264122, 0.2318911850452423, 0.23840022087097168, 0.2333042472600937, 0.24591012299060822, 0.2493092268705368, 0.24079449474811554, 0.22031548619270325, 0.24193111062049866, 0.21445265412330627, 0.2164463847875595, 0.18543748557567596]\n",
      "    5    100 2.454248666763306e-01 1.0e+00 4.55e-02  5e-02  5e-02 26:36.3\n",
      "three parts (321) of loss: 0.000, 0.000, 0.062\n",
      "iter time:  15.762329578399658\n",
      "three parts (321) of loss: 0.000, 0.000, 0.042\n",
      "iter time:  15.480405569076538\n",
      "three parts (321) of loss: 0.000, 0.000, 0.055\n",
      "iter time:  15.976567506790161\n",
      "three parts (321) of loss: 0.000, 0.000, 0.053\n",
      "iter time:  15.976088523864746\n",
      "three parts (321) of loss: 0.000, 0.000, 0.058\n",
      "iter time:  16.35370707511902\n",
      "three parts (321) of loss: 0.000, 0.000, 0.042\n",
      "iter time:  15.369667530059814\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.468369483947754\n",
      "three parts (321) of loss: 0.000, 0.000, 0.042\n",
      "iter time:  15.83555293083191\n",
      "three parts (321) of loss: 0.000, 0.000, 0.058\n",
      "iter time:  15.89495301246643\n",
      "three parts (321) of loss: 0.000, 0.000, 0.037\n",
      "iter time:  15.616719961166382\n",
      "three parts (321) of loss: 0.000, 0.000, 0.055\n",
      "iter time:  15.878176212310791\n",
      "three parts (321) of loss: 0.000, 0.000, 0.034\n",
      "iter time:  16.10155487060547\n",
      "three parts (321) of loss: 0.000, 0.000, 0.064\n",
      "iter time:  15.988290071487427\n",
      "three parts (321) of loss: 0.000, 0.000, 0.044\n",
      "iter time:  15.50182819366455\n",
      "three parts (321) of loss: 0.000, 0.000, 0.034\n",
      "iter time:  15.737637519836426\n",
      "three parts (321) of loss: 0.000, 0.000, 0.046\n",
      "iter time:  15.876508712768555\n",
      "three parts (321) of loss: 0.000, 0.000, 0.026\n",
      "iter time:  15.549593448638916\n",
      "three parts (321) of loss: 0.000, 0.000, 0.060\n",
      "iter time:  16.036882162094116\n",
      "three parts (321) of loss: 0.000, 0.000, 0.033\n",
      "iter time:  15.479162454605103\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.807789087295532\n",
      "penalty:  [0.20969529449939728, 0.20667730271816254, 0.21163614094257355, 0.23862147331237793, 0.211973175406456, 0.23465394973754883, 0.23242318630218506, 0.23968346416950226, 0.22873139381408691, 0.2294239103794098, 0.23204384744167328, 0.21592728793621063, 0.22373230755329132, 0.21849468350410461, 0.21599940955638885, 0.24007676541805267, 0.25172221660614014, 0.23374143242835999, 0.20798562467098236, 0.2599257230758667]\n",
      "    6    120 2.405152022838593e-01 1.0e+00 4.48e-02  4e-02  4e-02 31:52.1\n",
      "three parts (321) of loss: 0.000, 0.000, 0.042\n",
      "iter time:  15.94300127029419\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.437175035476685\n",
      "three parts (321) of loss: 0.000, 0.000, 0.059\n",
      "iter time:  15.962713241577148\n",
      "three parts (321) of loss: 0.000, 0.000, 0.033\n",
      "iter time:  15.54362440109253\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  15.573291778564453\n",
      "three parts (321) of loss: 0.000, 0.000, 0.036\n",
      "iter time:  15.355382919311523\n",
      "three parts (321) of loss: 0.000, 0.000, 0.054\n",
      "iter time:  15.908775806427002\n",
      "three parts (321) of loss: 0.000, 0.000, 0.051\n",
      "iter time:  16.128870725631714\n",
      "three parts (321) of loss: 0.000, 0.000, 0.052\n",
      "iter time:  15.589815378189087\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.56417465209961\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  15.475347757339478\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.576140403747559\n",
      "three parts (321) of loss: 0.000, 0.000, 0.061\n",
      "iter time:  15.705183744430542\n",
      "three parts (321) of loss: 0.000, 0.000, 0.043\n",
      "iter time:  15.397186517715454\n",
      "three parts (321) of loss: 0.000, 0.000, 0.052\n",
      "iter time:  15.153966188430786\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.586774587631226\n",
      "three parts (321) of loss: 0.000, 0.000, 0.044\n",
      "iter time:  15.315686225891113\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.456921100616455\n",
      "three parts (321) of loss: 0.000, 0.000, 0.052\n",
      "iter time:  15.944582223892212\n",
      "three parts (321) of loss: 0.000, 0.000, 0.043\n",
      "iter time:  15.562724351882935\n",
      "penalty:  [0.2699659764766693, 0.2460596114397049, 0.2190331518650055, 0.2584163546562195, 0.2591615915298462, 0.2520333230495453, 0.23948407173156738, 0.21971376240253448, 0.23386859893798828, 0.22825665771961212, 0.2173110991716385, 0.21824979782104492, 0.22552846372127533, 0.2305237054824829, 0.23646509647369385, 0.24092541635036469, 0.24333278834819794, 0.2554423213005066, 0.23617906868457794, 0.23861025273799896]\n",
      "    7    140 2.563961222767830e-01 1.0e+00 4.41e-02  4e-02  4e-02 37:04.3\n",
      "three parts (321) of loss: 0.000, 0.000, 0.046\n",
      "iter time:  15.795021533966064\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.339326858520508\n",
      "three parts (321) of loss: 0.000, 0.000, 0.044\n",
      "iter time:  15.237262725830078\n",
      "three parts (321) of loss: 0.000, 0.000, 0.027\n",
      "iter time:  15.290349960327148\n",
      "three parts (321) of loss: 0.000, 0.000, 0.034\n",
      "iter time:  15.608496904373169\n",
      "three parts (321) of loss: 0.000, 0.000, 0.037\n",
      "iter time:  15.392208337783813\n",
      "three parts (321) of loss: 0.000, 0.000, 0.061\n",
      "iter time:  15.707540035247803\n",
      "three parts (321) of loss: 0.000, 0.000, 0.056\n",
      "iter time:  15.343600034713745\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.32260012626648\n",
      "three parts (321) of loss: 0.000, 0.000, 0.050\n",
      "iter time:  15.611778974533081\n",
      "three parts (321) of loss: 0.000, 0.000, 0.053\n",
      "iter time:  15.363443851470947\n",
      "three parts (321) of loss: 0.000, 0.000, 0.058\n",
      "iter time:  15.732547283172607\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.47361135482788\n",
      "three parts (321) of loss: 0.000, 0.000, 0.065\n",
      "iter time:  15.80832576751709\n",
      "three parts (321) of loss: 0.000, 0.000, 0.049\n",
      "iter time:  15.308845281600952\n",
      "three parts (321) of loss: 0.000, 0.000, 0.050\n",
      "iter time:  15.546634912490845\n",
      "three parts (321) of loss: 0.000, 0.000, 0.033\n",
      "iter time:  15.551269769668579\n",
      "three parts (321) of loss: 0.000, 0.000, 0.043\n",
      "iter time:  15.26603889465332\n",
      "three parts (321) of loss: 0.000, 0.000, 0.025\n",
      "iter time:  14.992571115493774\n",
      "three parts (321) of loss: 0.000, 0.000, 0.052\n",
      "iter time:  15.796339988708496\n",
      "penalty:  [0.24349287152290344, 0.2266254872083664, 0.2309298813343048, 0.2675916850566864, 0.25394654273986816, 0.22327683866024017, 0.255752831697464, 0.21385696530342102, 0.2529122531414032, 0.23871994018554688, 0.24091295897960663, 0.25683051347732544, 0.24788807332515717, 0.2216198891401291, 0.22290273010730743, 0.2582016885280609, 0.23939473927021027, 0.24008767306804657, 0.242941215634346, 0.21767890453338623]\n",
      "    8    160 2.601658925414085e-01 1.0e+00 4.35e-02  4e-02  4e-02 42:13.8\n",
      "three parts (321) of loss: 0.000, 0.000, 0.028\n",
      "iter time:  15.36101770401001\n",
      "three parts (321) of loss: 0.000, 0.000, 0.051\n",
      "iter time:  15.547300815582275\n",
      "three parts (321) of loss: 0.000, 0.000, 0.029\n",
      "iter time:  15.353085994720459\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  15.405363321304321\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  15.300736427307129\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.54308557510376\n",
      "three parts (321) of loss: 0.000, 0.000, 0.043\n",
      "iter time:  15.333550930023193\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.767708778381348\n",
      "three parts (321) of loss: 0.000, 0.000, 0.034\n",
      "iter time:  15.17945384979248\n",
      "three parts (321) of loss: 0.000, 0.000, 0.024\n",
      "iter time:  15.421195030212402\n",
      "three parts (321) of loss: 0.000, 0.000, 0.047\n",
      "iter time:  15.588928699493408\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  15.843465566635132\n",
      "three parts (321) of loss: 0.000, 0.000, 0.047\n",
      "iter time:  15.342692136764526\n",
      "three parts (321) of loss: 0.000, 0.000, 0.060\n",
      "iter time:  15.620214223861694\n",
      "three parts (321) of loss: 0.000, 0.000, 0.041\n",
      "iter time:  15.272696018218994\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.455572843551636\n",
      "three parts (321) of loss: 0.000, 0.000, 0.047\n",
      "iter time:  15.425894021987915\n",
      "three parts (321) of loss: 0.000, 0.000, 0.034\n",
      "iter time:  15.496407985687256\n",
      "three parts (321) of loss: 0.000, 0.000, 0.050\n",
      "iter time:  15.585996150970459\n",
      "three parts (321) of loss: 0.000, 0.000, 0.053\n",
      "iter time:  15.613643407821655\n",
      "penalty:  [0.2528389096260071, 0.22865095734596252, 0.2454766035079956, 0.2312300205230713, 0.2631107270717621, 0.24903087317943573, 0.24777023494243622, 0.2317671775817871, 0.22552107274532318, 0.2505533695220947, 0.2502148747444153, 0.2238176316022873, 0.26103779673576355, 0.23646239936351776, 0.24412675201892853, 0.23735712468624115, 0.25286024808883667, 0.23821750283241272, 0.2382257729768753, 0.2302456647157669]\n",
      "    9    180 2.591959834098816e-01 1.0e+00 4.30e-02  4e-02  4e-02 47:23.3\n",
      "three parts (321) of loss: 0.000, 0.000, 0.047\n",
      "iter time:  15.5742769241333\n",
      "three parts (321) of loss: 0.000, 0.000, 0.025\n",
      "iter time:  15.53951358795166\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.169243574142456\n",
      "three parts (321) of loss: 0.000, 0.000, 0.029\n",
      "iter time:  15.404091835021973\n",
      "three parts (321) of loss: 0.000, 0.000, 0.025\n",
      "iter time:  15.185558080673218\n",
      "three parts (321) of loss: 0.000, 0.000, 0.041\n",
      "iter time:  15.533281326293945\n",
      "three parts (321) of loss: 0.000, 0.000, 0.046\n",
      "iter time:  15.41197156906128\n",
      "three parts (321) of loss: 0.000, 0.000, 0.048\n",
      "iter time:  15.446281909942627\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.325122117996216\n",
      "three parts (321) of loss: 0.000, 0.000, 0.058\n",
      "iter time:  15.534645557403564\n",
      "three parts (321) of loss: 0.000, 0.000, 0.013\n",
      "iter time:  14.974944829940796\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.722540855407715\n",
      "three parts (321) of loss: 0.000, 0.000, 0.035\n",
      "iter time:  15.438703298568726\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.466845989227295\n",
      "three parts (321) of loss: 0.000, 0.000, 0.041\n",
      "iter time:  15.234958410263062\n",
      "three parts (321) of loss: 0.000, 0.000, 0.046\n",
      "iter time:  15.896749258041382\n",
      "three parts (321) of loss: 0.000, 0.000, 0.039\n",
      "iter time:  15.118374586105347\n",
      "three parts (321) of loss: 0.000, 0.000, 0.030\n",
      "iter time:  15.192991018295288\n",
      "three parts (321) of loss: 0.000, 0.000, 0.041\n",
      "iter time:  15.469393014907837\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.238946199417114\n",
      "penalty:  [0.2288714200258255, 0.2577863037586212, 0.24393711984157562, 0.24071423709392548, 0.23723648488521576, 0.2531771957874298, 0.23993945121765137, 0.2442876547574997, 0.25608590245246887, 0.2453145831823349, 0.27889391779899597, 0.24607093632221222, 0.23181092739105225, 0.24798786640167236, 0.24760864675045013, 0.2532501816749573, 0.2544865310192108, 0.24558918178081512, 0.24326686561107635, 0.23818325996398926]\n",
      "   10    200 2.627291381359100e-01 1.0e+00 4.24e-02  4e-02  4e-02 52:31.3\n",
      "three parts (321) of loss: 0.000, 0.000, 0.037\n",
      "iter time:  15.270673990249634\n",
      "three parts (321) of loss: 0.000, 0.000, 0.028\n",
      "iter time:  15.431111812591553\n",
      "three parts (321) of loss: 0.000, 0.000, 0.027\n",
      "iter time:  15.033665180206299\n",
      "three parts (321) of loss: 0.000, 0.000, 0.029\n",
      "iter time:  15.21661114692688\n",
      "three parts (321) of loss: 0.000, 0.000, 0.014\n",
      "iter time:  15.0285484790802\n",
      "three parts (321) of loss: 0.000, 0.000, 0.033\n",
      "iter time:  15.1768217086792\n",
      "three parts (321) of loss: 0.000, 0.000, 0.026\n",
      "iter time:  15.168543577194214\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.342691421508789\n",
      "three parts (321) of loss: 0.000, 0.000, 0.028\n",
      "iter time:  15.308609247207642\n",
      "three parts (321) of loss: 0.000, 0.000, 0.037\n",
      "iter time:  15.220476627349854\n",
      "three parts (321) of loss: 0.000, 0.000, 0.024\n",
      "iter time:  15.123014450073242\n",
      "three parts (321) of loss: 0.000, 0.000, 0.030\n",
      "iter time:  15.395965576171875\n",
      "three parts (321) of loss: 0.000, 0.000, 0.037\n",
      "iter time:  15.378653287887573\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.172417402267456\n",
      "three parts (321) of loss: 0.000, 0.000, 0.032\n",
      "iter time:  15.239586114883423\n",
      "three parts (321) of loss: 0.000, 0.000, 0.037\n",
      "iter time:  15.386119365692139\n",
      "three parts (321) of loss: 0.000, 0.000, 0.034\n",
      "iter time:  15.458495378494263\n",
      "three parts (321) of loss: 0.000, 0.000, 0.036\n",
      "iter time:  15.181134700775146\n",
      "three parts (321) of loss: 0.000, 0.000, 0.031\n",
      "iter time:  15.270277976989746\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.311905145645142\n",
      "penalty:  [0.23657558858394623, 0.25450143218040466, 0.24572837352752686, 0.28624841570854187, 0.26941394805908203, 0.26815053820610046, 0.2583710253238678, 0.2931605279445648, 0.250001460313797, 0.24110303819179535, 0.2533285915851593, 0.27581286430358887, 0.2623482048511505, 0.26915404200553894, 0.27348592877388, 0.25409170985221863, 0.24148929119110107, 0.2552524507045746, 0.250989705324173, 0.22284667193889618]\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "   11    220 2.626089975237846e-01 1.0e+00 4.19e-02  4e-02  4e-02 57:36.4\n",
      "three parts (321) of loss: 0.000, 0.000, 0.035\n",
      "iter time:  15.450926303863525\n",
      "three parts (321) of loss: 0.000, 0.000, 0.038\n",
      "iter time:  15.317002058029175\n",
      "three parts (321) of loss: 0.000, 0.000, 0.039\n",
      "iter time:  15.302300214767456\n",
      "three parts (321) of loss: 0.000, 0.000, 0.041\n",
      "iter time:  15.088907957077026\n",
      "three parts (321) of loss: 0.000, 0.000, 0.018\n",
      "iter time:  14.71521806716919\n",
      "three parts (321) of loss: 0.000, 0.000, 0.037\n",
      "iter time:  15.046447277069092\n",
      "three parts (321) of loss: 0.000, 0.000, 0.027\n",
      "iter time:  15.15238618850708\n",
      "three parts (321) of loss: 0.000, 0.000, 0.037\n",
      "iter time:  14.944175481796265\n",
      "three parts (321) of loss: 0.000, 0.000, 0.036\n",
      "iter time:  15.500444650650024\n",
      "three parts (321) of loss: 0.000, 0.000, 0.029\n",
      "iter time:  14.861037015914917\n",
      "three parts (321) of loss: 0.000, 0.000, 0.025\n",
      "iter time:  15.235378503799438\n",
      "three parts (321) of loss: 0.000, 0.000, 0.033\n",
      "iter time:  15.447521924972534\n",
      "three parts (321) of loss: 0.000, 0.000, 0.042\n",
      "iter time:  15.208271741867065\n",
      "three parts (321) of loss: 0.000, 0.000, 0.040\n",
      "iter time:  15.506979942321777\n",
      "three parts (321) of loss: 0.000, 0.000, 0.033\n",
      "iter time:  15.235245704650879\n",
      "three parts (321) of loss: 0.000, 0.000, 0.013\n",
      "iter time:  15.074702978134155\n",
      "three parts (321) of loss: 0.000, 0.000, 0.028\n",
      "iter time:  15.028843402862549\n",
      "three parts (321) of loss: 0.000, 0.000, 0.018\n",
      "iter time:  15.087759494781494\n",
      "three parts (321) of loss: 0.000, 0.000, 0.045\n",
      "iter time:  15.243669509887695\n",
      "three parts (321) of loss: 0.000, 0.000, 0.019\n",
      "iter time:  15.359899044036865\n",
      "penalty:  [0.26277467608451843, 0.25847896933555603, 0.22340404987335205, 0.2303188145160675, 0.2660634219646454, 0.24837830662727356, 0.24658203125, 0.23701229691505432, 0.24163322150707245, 0.24014978110790253, 0.24328844249248505, 0.2481597512960434, 0.22712627053260803, 0.24654309451580048, 0.23828208446502686, 0.30022355914115906, 0.25734177231788635, 0.25374001264572144, 0.2404918521642685, 0.23435083031654358]\n",
      "   12    240 2.535218931734562e-01 1.0e+00 4.14e-02  4e-02  4e-02 62:40.3\n",
      "three parts (321) of loss: 0.000, 0.000, 0.009\n",
      "iter time:  14.935553550720215\n",
      "three parts (321) of loss: 0.000, 0.000, 0.022\n",
      "iter time:  15.537754535675049\n",
      "three parts (321) of loss: 0.000, 0.000, 0.031\n",
      "iter time:  15.124494075775146\n",
      "three parts (321) of loss: 0.000, 0.000, 0.025\n",
      "iter time:  15.117562532424927\n",
      "three parts (321) of loss: 0.000, 0.000, 0.021\n",
      "iter time:  15.142395734786987\n",
      "three parts (321) of loss: 0.000, 0.000, 0.035\n",
      "iter time:  15.33065128326416\n",
      "three parts (321) of loss: 0.000, 0.000, 0.016\n",
      "iter time:  15.193115949630737\n",
      "three parts (321) of loss: 0.000, 0.000, 0.018\n",
      "iter time:  15.251380920410156\n",
      "three parts (321) of loss: 0.000, 0.000, 0.028\n",
      "iter time:  15.307312965393066\n",
      "three parts (321) of loss: 0.000, 0.000, 0.035\n",
      "iter time:  15.250975131988525\n",
      "three parts (321) of loss: 0.000, 0.000, 0.033\n",
      "iter time:  15.342426061630249\n",
      "three parts (321) of loss: 0.000, 0.000, 0.030\n",
      "iter time:  15.40587592124939\n",
      "three parts (321) of loss: 0.000, 0.000, 0.042\n",
      "iter time:  15.354653120040894\n",
      "three parts (321) of loss: 0.000, 0.000, 0.036\n",
      "iter time:  15.31420636177063\n",
      "three parts (321) of loss: 0.000, 0.000, 0.028\n",
      "iter time:  15.092849493026733\n",
      "three parts (321) of loss: 0.000, 0.000, 0.020\n",
      "iter time:  15.19146180152893\n",
      "three parts (321) of loss: 0.000, 0.000, 0.026\n",
      "iter time:  15.326271533966064\n",
      "three parts (321) of loss: 0.000, 0.000, 0.019\n",
      "iter time:  15.31746220588684\n",
      "three parts (321) of loss: 0.000, 0.000, 0.018\n",
      "iter time:  15.05000638961792\n",
      "three parts (321) of loss: 0.000, 0.000, 0.031\n",
      "iter time:  15.220292091369629\n",
      "penalty:  [0.2588901221752167, 0.23863957822322845, 0.21553866565227509, 0.22048039734363556, 0.2526107132434845, 0.26188457012176514, 0.27015063166618347, 0.2815649211406708, 0.28542912006378174, 0.2642265260219574, 0.24300312995910645, 0.24606327712535858, 0.22658470273017883, 0.23511390388011932, 0.26121899485588074, 0.24336302280426025, 0.2426108568906784, 0.24209976196289062, 0.2837773263454437, 0.24896419048309326]\n",
      "   13    260 2.459020204842091e-01 1.0e+00 4.09e-02  4e-02  4e-02 67:45.2\n",
      "three parts (321) of loss: 0.000, 0.000, 0.016\n",
      "iter time:  15.054550647735596\n",
      "three parts (321) of loss: 0.000, 0.000, 0.018\n",
      "iter time:  15.185072422027588\n",
      "three parts (321) of loss: 0.000, 0.000, 0.012\n",
      "iter time:  14.994114398956299\n",
      "three parts (321) of loss: 0.000, 0.000, 0.032\n",
      "iter time:  15.062865972518921\n",
      "three parts (321) of loss: 0.000, 0.000, 0.029\n",
      "iter time:  15.47821044921875\n",
      "three parts (321) of loss: 0.000, 0.000, 0.029\n",
      "iter time:  15.20915937423706\n",
      "three parts (321) of loss: 0.000, 0.000, 0.014\n",
      "iter time:  15.229142189025879\n",
      "three parts (321) of loss: 0.000, 0.000, 0.017\n",
      "iter time:  15.160136222839355\n",
      "three parts (321) of loss: 0.000, 0.000, 0.022\n",
      "iter time:  15.103999853134155\n",
      "three parts (321) of loss: 0.000, 0.000, 0.033\n",
      "iter time:  15.250344276428223\n",
      "three parts (321) of loss: 0.000, 0.000, 0.020\n",
      "iter time:  15.11982274055481\n",
      "three parts (321) of loss: 0.000, 0.000, 0.013\n",
      "iter time:  14.979355335235596\n",
      "three parts (321) of loss: 0.000, 0.000, 0.028\n",
      "iter time:  15.018363952636719\n",
      "three parts (321) of loss: 0.000, 0.000, 0.041\n",
      "iter time:  15.246537685394287\n",
      "three parts (321) of loss: 0.000, 0.000, 0.027\n",
      "iter time:  15.105295181274414\n",
      "three parts (321) of loss: 0.000, 0.000, 0.031\n",
      "iter time:  15.29703164100647\n",
      "three parts (321) of loss: 0.000, 0.000, 0.029\n",
      "iter time:  15.155378103256226\n",
      "three parts (321) of loss: 0.000, 0.000, 0.010\n",
      "iter time:  14.829555988311768\n",
      "three parts (321) of loss: 0.000, 0.000, 0.019\n",
      "iter time:  15.004693984985352\n",
      "three parts (321) of loss: 0.000, 0.000, 0.012\n",
      "iter time:  15.02032470703125\n",
      "penalty:  [0.26509472727775574, 0.25674647092819214, 0.2486056089401245, 0.25509530305862427, 0.232356458902359, 0.23985925316810608, 0.25772640109062195, 0.2478266954421997, 0.2691799998283386, 0.2383435070514679, 0.2467372864484787, 0.23520992696285248, 0.2449946254491806, 0.24866822361946106, 0.2244046926498413, 0.2248656004667282, 0.269132137298584, 0.24844740331172943, 0.25309818983078003, 0.2488524168729782]\n",
      "   14    280 2.480067797005177e-01 1.0e+00 4.04e-02  4e-02  4e-02 72:47.7\n",
      "three parts (321) of loss: 0.000, 0.000, 0.016\n",
      "iter time:  14.918429613113403\n",
      "three parts (321) of loss: 0.000, 0.000, 0.017\n",
      "iter time:  15.247100830078125\n",
      "three parts (321) of loss: 0.000, 0.000, 0.023\n",
      "iter time:  15.365315914154053\n",
      "three parts (321) of loss: 0.000, 0.000, 0.039\n",
      "iter time:  15.13633394241333\n",
      "three parts (321) of loss: 0.000, 0.000, 0.015\n",
      "iter time:  15.146499872207642\n",
      "three parts (321) of loss: 0.000, 0.000, 0.019\n",
      "iter time:  14.986890077590942\n",
      "three parts (321) of loss: 0.000, 0.000, 0.006\n",
      "iter time:  14.922349691390991\n",
      "three parts (321) of loss: 0.000, 0.000, 0.014\n",
      "iter time:  15.19241714477539\n",
      "three parts (321) of loss: 0.000, 0.000, 0.025\n",
      "iter time:  14.950260162353516\n",
      "three parts (321) of loss: 0.000, 0.000, 0.011\n",
      "iter time:  15.000791788101196\n",
      "three parts (321) of loss: 0.000, 0.000, 0.017\n",
      "iter time:  15.304006814956665\n",
      "three parts (321) of loss: 0.000, 0.000, 0.006\n",
      "iter time:  14.962907075881958\n",
      "three parts (321) of loss: 0.000, 0.000, 0.023\n",
      "iter time:  15.325002193450928\n",
      "three parts (321) of loss: 0.000, 0.000, 0.009\n",
      "iter time:  14.776768684387207\n",
      "three parts (321) of loss: 0.000, 0.000, 0.008\n",
      "iter time:  14.847655296325684\n",
      "three parts (321) of loss: 0.000, 0.000, 0.007\n",
      "iter time:  14.621377229690552\n",
      "three parts (321) of loss: 0.000, 0.000, 0.019\n",
      "iter time:  15.223001480102539\n",
      "three parts (321) of loss: 0.000, 0.000, 0.032\n",
      "iter time:  15.067939519882202\n",
      "three parts (321) of loss: 0.000, 0.000, 0.009\n",
      "iter time:  15.019806623458862\n",
      "three parts (321) of loss: 0.000, 0.000, 0.009\n",
      "iter time:  14.90918517112732\n",
      "penalty:  [0.2639317214488983, 0.27140718698501587, 0.25424250960350037, 0.2365761548280716, 0.234395369887352, 0.2732035517692566, 0.2583666741847992, 0.2731752097606659, 0.22826512157917023, 0.2713669538497925, 0.23709869384765625, 0.24116745591163635, 0.25891607999801636, 0.2636922001838684, 0.27808883786201477, 0.23676875233650208, 0.26416173577308655, 0.2521623373031616, 0.24870502948760986, 0.25672468543052673]\n",
      "   15    300 2.442545741796494e-01 1.0e+00 4.00e-02  4e-02  4e-02 77:48.7\n"
     ]
    }
   ],
   "source": [
    "x0, sigma0 = latent_vectors[32].cpu().numpy(), 0.05\n",
    "es = cma.CMAEvolutionStrategy(x0, sigma0)\n",
    "i = 0\n",
    "Xs = []\n",
    "fits = []\n",
    "pure_drags = []\n",
    "while i < 15:\n",
    "    X = es.ask()\n",
    "    fit = [func_drag(x) for x in X]\n",
    "    apenalty = [func2d(x) for x in X]\n",
    "    print(\"penalty: \", apenalty)\n",
    "    fitness = [fit[j]+apenalty[j] for j in range(len(X))]\n",
    "    es.tell(X, fitness)\n",
    "    Xs.append(X)\n",
    "    fits.append(fit)\n",
    "    #pure_drags.append(pure_drag)\n",
    "    np.save(\"../Compare_optimisers/new_cma/cma_withReg_dif_loc32.npy\", Xs)\n",
    "    np.save(\"../Compare_optimisers/new_cma/cma_fitness_withReg_dif_loc32.npy\", fits)\n",
    "    #pure_drags.save(\"../Compare_optimisers/new_cma/cma_pure_drag_noReg.npy\")\n",
    "    es.disp(1)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
