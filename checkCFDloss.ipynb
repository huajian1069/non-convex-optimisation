{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "checkCFDloss.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wgCgJ6AieVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import skimage.measure\n",
        "import plyfile\n",
        "from plyfile import PlyData\n",
        "from sklearn.neighbors import KDTree\n",
        "import trimesh\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
        "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtBoNNSMieVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "86d328bb-69b8-4e45-baf7-d2e03557e517"
      },
      "source": [
        "print(torch.__version__)\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6JlQ7MWzsDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ce243b5e-97f2-4d59-f35e-3a4a7fa026eb"
      },
      "source": [
        "! nvcc --version"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oINuP6Sz5B8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "05dae263-cb5f-4e55-9d75-27d49680e9f5"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul 31 14:39:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    76W / 149W |  11344MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuy6igvMnjMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir networks\n",
        "! mv ../deep_sdf_decoder.py networks/"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U0sLodQi_fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install plyfile\n",
        "!pip install trimesh\n",
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6caIMKgieVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "000355cc-790d-4c58-cddf-71829e6698ce"
      },
      "source": [
        "torch.tensor([32,2.3]).cuda()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32.0000,  2.3000], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQDXwZHwieV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_params_subdir = \"ModelParameters\"\n",
        "optimizer_params_subdir = \"OptimizerParameters\"\n",
        "latent_codes_subdir = \"LatentCodes\"\n",
        "logs_filename = \"Logs.pth\"\n",
        "reconstructions_subdir = \"Reconstructions\"\n",
        "reconstruction_meshes_subdir = \"Meshes\"\n",
        "reconstruction_codes_subdir = \"Codes\"\n",
        "specifications_filename = \"specs.json\"\n",
        "data_source_map_filename = \".datasources.json\"\n",
        "evaluation_subdir = \"Evaluation\"\n",
        "sdf_samples_subdir = \"SdfSamples\"\n",
        "surface_samples_subdir = \"SurfaceSamples\"\n",
        "normalization_param_subdir = \"NormalizationParameters\"\n",
        "training_meshes_subdir = \"TrainingMeshes\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vlOE0_iieV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_latent_vectors(experiment_directory, checkpoint):\n",
        "\n",
        "    filename = os.path.join(\n",
        "        experiment_directory, checkpoint + \".pth\"\n",
        "    )\n",
        "    if not os.path.isfile(filename):\n",
        "        raise Exception(\n",
        "            \"The experiment directory ({}) does not include a latent code file\"\n",
        "            + \" for checkpoint '{}'\".format(experiment_directory, checkpoint)\n",
        "        )\n",
        "    data = torch.load(filename)\n",
        "    return data[\"latent_codes\"].cuda()\n",
        "\n",
        "def load_model(experiment_directory, checkpoint):\n",
        "    specs_filename = os.path.join(experiment_directory, \"specs.json\")\n",
        "\n",
        "    if not os.path.isfile(specs_filename):\n",
        "        raise Exception(\n",
        "            'The experiment directory does not include specifications file \"specs.json\"'\n",
        "        )\n",
        "\n",
        "    specs = json.load(open(specs_filename))\n",
        "\n",
        "    arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
        "\n",
        "    latent_size = specs[\"CodeLength\"]\n",
        "\n",
        "    decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
        "\n",
        "    decoder = torch.nn.DataParallel(decoder)\n",
        "\n",
        "    saved_model_state = torch.load(\n",
        "        os.path.join(experiment_directory, checkpoint + \".pth\")\n",
        "    )\n",
        "\n",
        "    decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
        "\n",
        "    decoder = decoder.module.cuda()\n",
        "\n",
        "    decoder.eval()\n",
        "    \n",
        "    return decoder\n",
        "\n",
        "def create_mesh(\n",
        "    decoder, latent_vec, filename='', N=256, max_batch=32 ** 3, offset=None, scale=None\n",
        "):\n",
        "    start = time.time()\n",
        "    ply_filename = filename\n",
        "\n",
        "    decoder.eval()\n",
        "\n",
        "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
        "    voxel_origin = [-1, -1, -1]\n",
        "    voxel_size = 2.0 / (N - 1)\n",
        "\n",
        "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
        "    samples = torch.zeros(N ** 3, 4)\n",
        "\n",
        "    # transform first 3 columns\n",
        "    # to be the x, y, z index\n",
        "    samples[:, 2] = overall_index % N\n",
        "    samples[:, 1] = (overall_index.long() / N) % N\n",
        "    samples[:, 0] = ((overall_index.long() / N) / N) % N\n",
        "\n",
        "    # transform first 3 columns\n",
        "    # to be the x, y, z coordinate\n",
        "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
        "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
        "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
        "\n",
        "    num_samples = N ** 3\n",
        "\n",
        "    samples.requires_grad = False\n",
        "\n",
        "    head = 0\n",
        "\n",
        "    while head < num_samples:\n",
        "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()\n",
        "\n",
        "        samples[head : min(head + max_batch, num_samples), 3] = \\\n",
        "                decode_sdf(decoder, latent_vec, sample_subset).squeeze(1).detach().cpu()\n",
        "        head += max_batch\n",
        "\n",
        "    sdf_values = samples[:, 3]\n",
        "    sdf_values = sdf_values.reshape(N, N, N)\n",
        "\n",
        "    end = time.time()\n",
        "    #print(\"sampling takes: %f\" % (end - start))\n",
        "\n",
        "    return convert_sdf_samples_to_ply(\n",
        "        sdf_values.data.cpu(),\n",
        "        voxel_origin,\n",
        "        voxel_size,\n",
        "        ply_filename + \".ply\",\n",
        "        offset,\n",
        "        scale,\n",
        "    )\n",
        "\n",
        "def convert_sdf_samples_to_ply(\n",
        "    pytorch_3d_sdf_tensor,\n",
        "    voxel_grid_origin,\n",
        "    voxel_size,\n",
        "    ply_filename_out,\n",
        "    offset=None,\n",
        "    scale=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Convert sdf samples to .ply\n",
        "\n",
        "    :param pytorch_3d_sdf_tensor: a torch.FloatTensor of shape (n,n,n)\n",
        "    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n",
        "    :voxel_size: float, the size of the voxels\n",
        "    :ply_filename_out: string, path of the filename to save to\n",
        "\n",
        "    This function adapted from: https://github.com/RobotLocomotion/spartan\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    numpy_3d_sdf_tensor = pytorch_3d_sdf_tensor.numpy()\n",
        "\n",
        "    verts, faces, normals, values = skimage.measure.marching_cubes_lewiner(\n",
        "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3\n",
        "    )\n",
        "\n",
        "    # transform from voxel coordinates to camera coordinates\n",
        "    # note x and y are flipped in the output of marching_cubes\n",
        "    mesh_points = np.zeros_like(verts)\n",
        "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
        "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
        "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
        "\n",
        "    # apply additional offset and scale\n",
        "    if scale is not None:\n",
        "        mesh_points = mesh_points / scale\n",
        "    if offset is not None:\n",
        "        mesh_points = mesh_points - offset\n",
        "\n",
        "    # try writing to the ply file\n",
        "\n",
        "    num_verts = verts.shape[0]\n",
        "    num_faces = faces.shape[0]\n",
        "\n",
        "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
        "    norms_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
        "\n",
        "    for i in range(0, num_verts):\n",
        "        verts_tuple[i] = tuple(mesh_points[i, :])\n",
        "        norms_tuple[i] = tuple(normals[i, :])\n",
        "\n",
        "    faces_building = []\n",
        "    for i in range(0, num_faces):\n",
        "        faces_building.append(((faces[i, :].tolist(),)))\n",
        "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
        "\n",
        "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
        "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
        "    el_norms = plyfile.PlyElement.describe(norms_tuple, \"normals\")\n",
        "\n",
        "    ply_data = plyfile.PlyData([el_verts, el_faces, el_norms])\n",
        "    return ply_data\n",
        "\n",
        "def decode_sdf(decoder, latent_vector, queries):\n",
        "    num_samples = queries.shape[0]\n",
        "\n",
        "    if latent_vector is None:\n",
        "        inputs = queries\n",
        "    else:\n",
        "        latent_repeat = latent_vector.expand(num_samples, -1)\n",
        "        inputs = torch.cat([latent_repeat, queries], 1)\n",
        "\n",
        "    sdf = decoder(inputs)\n",
        "\n",
        "    return sdf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JM2oaapieWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_lift_faces_diff(data_instance, answers, axis=0):\n",
        "    pressures = torch.mean(answers[data_instance['face'], 0], axis=0)\n",
        "\n",
        "    # TODO: cahnge to x if needed\n",
        "    pos = data_instance['x']\n",
        "    cross_prod = (pos[data_instance['face'][1]] - pos[data_instance['face'][0]]).cross(\n",
        "                  pos[data_instance['face'][2]] - pos[data_instance['face'][0]])\n",
        "    mult = -cross_prod[:, axis] / 2\n",
        "    lift = torch.mul(pressures, mult)\n",
        "    return torch.sum(lift[~torch.isnan(lift)])\n",
        "\n",
        "def boundsLoss(points, box=[(-1, 1, 0)]):\n",
        "    loss = 0\n",
        "    for l, r, i in box:\n",
        "        loss +=  torch.mean(F.relu(-points[:, i] + l))  \\\n",
        "               + torch.mean(F.relu( points[:, i] - r))\n",
        "    return loss\n",
        "\n",
        "def innerBoundsLoss(points, r=1, center=(0, 0, 0)):\n",
        "    radiuses = torch.sum( (points - torch.Tensor(center).to('cuda:0')) ** 2 , dim=1)\n",
        "    return torch.mean(F.relu(r - radiuses))\n",
        "\n",
        "def calculate_loss(mesh, local_preds, axis=0, constraint_rad=0.1):\n",
        "    loss =  (1 - axis) * compute_lift_faces_diff(mesh, local_preds, axis=0) + \\\n",
        "                  axis * compute_lift_faces_diff(mesh, local_preds, axis=1)\n",
        "    \n",
        "    loss += boundsLoss(mesh['x'], box=[(-0.6, 0.6, 0)])\n",
        "    loss += innerBoundsLoss(mesh['x'], r=constraint_rad**2, center=(-0.05, 0.05, 0))  \\\n",
        "          + innerBoundsLoss(mesh['x'], r=(constraint_rad / 2)**2, center=(0.3, 0, 0))\n",
        "    return loss\n",
        "\n",
        "def soft_constraints(latent, latent_vectors, num_neignours_constr, alpha_penalty):\n",
        "    # Soft-constraints\n",
        "    distances, indeces = LATENT_KD_TREE.query(latent.cpu().detach(), k=num_neignours_constr)\n",
        "    torch.sum((initial_la - latent_vectors[indeces.squeeze()]) ** 2, dim=2).mean()\n",
        "    return penalty * alpha_penalty"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I_hhsIwieWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeAvgTransform():\n",
        "    objects = list()\n",
        "    for (dirpath, dirnames, filenames) in os.walk(\"/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/transforms/\"):\n",
        "        objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.npy']\n",
        "    \n",
        "    matricies = []\n",
        "    for obj in objects:\n",
        "        matricies.append(np.load(obj))\n",
        "    \n",
        "    return np.mean(np.array(matricies), axis=0)\n",
        "\n",
        "def transformPoints(points):\n",
        "    matrix = torch.cuda.FloatTensor(AvgTransform)\n",
        "    column = torch.zeros((len(points), 1), device=\"cuda:0\") + 1\n",
        "    stacked = torch.cat([points, column], dim=1)\n",
        "    transformed = torch.matmul(matrix, stacked.t()).t()[:, :3]\n",
        "    return transformed\n",
        "\n",
        "def make_mesh_from_points(points, ply_mesh):\n",
        "    transformed_points = transformPoints(points)\n",
        "    \n",
        "    edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
        "    np_points = transformed_points.cpu().detach().numpy()\n",
        "    edge_attr = [np_points[a] - np_points[b] for a, b in edges]\n",
        "    mesh = {'x': transformed_points, \n",
        "        'face':torch.tensor(ply_mesh['face']['vertex_indices'], dtype=torch.long).to('cuda:0').t(),\n",
        "        'edge_attr':torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
        "        'edge_index':torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0')\n",
        "        }\n",
        "    return mesh"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw1U5NI-ieWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SplineBlock(nn.Module):\n",
        "    def __init__(self, num_in_features, num_outp_features, mid_features, kernel=3, dim=3, batchnorm1=True):\n",
        "        super(SplineBlock, self).__init__()\n",
        "        self.batchnorm1 = batchnorm1\n",
        "        self.conv1 = SplineConv(num_in_features, mid_features, dim, kernel, is_open_spline=False)\n",
        "        if self.batchnorm1:\n",
        "            self.batchnorm1 = torch.nn.BatchNorm1d(mid_features)\n",
        "        self.conv2 = SplineConv(mid_features, 2 * mid_features, dim, kernel, is_open_spline=False)\n",
        "        self.batchnorm2 = torch.nn.BatchNorm1d(2 * mid_features)\n",
        "        self.conv3 = SplineConv(2 * mid_features + 3, num_outp_features, dim, kernel, is_open_spline=False)\n",
        "  \n",
        "    def forward(self, res, data):\n",
        "        if self.batchnorm1:\n",
        "            res = F.elu(self.batchnorm1(self.conv1(res, data['edge_index'], data['edge_attr'])))\n",
        "        else:\n",
        "            res = F.elu(self.conv1(res, data['edge_index'], data['edge_attr']))\n",
        "        res = F.elu(self.batchnorm2(self.conv2(res, data['edge_index'], data['edge_attr'])))\n",
        "#         res = F.elu(self.conv2(res, data.edge_index, data.edge_attr))\n",
        "        res = torch.cat([res, data['x']], dim=1)\n",
        "        res = self.conv3(res, data['edge_index'], data['edge_attr'])\n",
        "        return res\n",
        "\n",
        "class SplineCNN8Residuals(nn.Module):\n",
        "    def __init__(self, num_features, kernel=3, dim=3):\n",
        "        super(SplineCNN8Residuals, self).__init__()\n",
        "        self.block1 = SplineBlock(num_features, 16, 8, kernel, dim)\n",
        "        self.block2 = SplineBlock(16, 64, 32, kernel, dim)\n",
        "        self.block3 = SplineBlock(64, 64, 128, kernel, dim)\n",
        "        self.block4 = SplineBlock(64, 8, 16, kernel, dim)\n",
        "        self.block5 = SplineBlock(11, 32, 16, kernel, dim)\n",
        "        self.block6 = SplineBlock(32, 64, 32, kernel, dim)\n",
        "        self.block7 = SplineBlock(64, 64, 128, kernel, dim)\n",
        "        self.block8 = SplineBlock(75, 4, 16, kernel, dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        res = data['x']\n",
        "        res = self.block1(res, data)\n",
        "        res = self.block2(res, data)\n",
        "        res = self.block3(res, data)\n",
        "        res4 = self.block4(res, data)\n",
        "        res = torch.cat([res4, data['x']], dim=1)\n",
        "        res = self.block5(res, data)\n",
        "        res = self.block6(res, data)\n",
        "        res = self.block7(res, data)\n",
        "        res = torch.cat([res, res4, data['x']], dim=1)\n",
        "        res = self.block8(res, data)\n",
        "        return res\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwDmuXRZieWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DIR_for_dump_data = './data_for_this_experiments'\n",
        "experiment_directory = DIR_for_dump_data\n",
        "\n",
        "model = SplineCNN8Residuals(3)\n",
        "model.load_state_dict(torch.load(experiment_directory + \"/cfdModel.nn\"))\n",
        "model = model.to(\"cuda:0\")\n",
        "model = model.eval()\n",
        "\n",
        "decoder = load_model(experiment_directory, \"decoderModel\")\n",
        "latent_vectors = load_latent_vectors(experiment_directory, \"latentCodes\")\n",
        "latent_vectors = latent_vectors.detach()\n",
        "\n",
        "LATENT_TO_OPTIMIZE = latent_vectors[32]\n",
        "LATENT_KD_TREE = KDTree(np.array([lv.cpu().detach().numpy()[0] for lv in latent_vectors]))\n",
        "AvgTransform = np.load(DIR_for_dump_data + \"/avg_trans_matrix.npy\") #computeAvgTransform()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j20y4chdieWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V863f0ccmme7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed10375f-2c29-45ec-9a2b-207d7fed98b5"
      },
      "source": [
        ""
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3987, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j5ogXlB0hfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4193bfb1-a7e1-489d-b699-649fa806a951"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul 31 12:53:53 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    76W / 149W |  10670MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3z7xq1QieWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_la = latent_vectors[32]\n",
        "ply_mesh = create_mesh( decoder,\n",
        "                        initial_la,\n",
        "                        N=256,\n",
        "                        max_batch=int(2 ** 18),\n",
        "                        offset=None,\n",
        "                        scale=None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HL3A11cx3wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
        "                                            ply_mesh['vertex']['y'][:, None], \n",
        "                                            ply_mesh['vertex']['z'][:, None])))\n",
        "\n",
        "# from mesh to pressure field\n",
        "points.requires_grad = True\n",
        "mesh = make_mesh_from_points(points, ply_mesh)\n",
        "#del ply_mesh, points\n",
        "local_preds = model(mesh)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQgi519pBA_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = calculate_loss(mesh, local_preds, axis=0, constraint_rad=0.05)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayzvv36zI1S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()\n",
        "dL_dp = points.grad.clone()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr_1kLvqJTQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "points.grad.data.zero_()\n",
        "sdf_value = decode_sdf(decoder, initial_la, points)\n",
        "sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda())"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLPn3Y81J5Ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assemble constant \n",
        "mults = [-p1.dot(p2) for p1, p2 in zip(dL_dp, points.grad)]       \n",
        "multipliers = torch.cuda.FloatTensor(mults)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7RtRhTUJewl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "points = points.detach()\n",
        "initial_la = initial_la.detach().requires_grad_(True)\n",
        "latent_inputs = initial_la.expand(points.shape[0], -1)\n",
        "inputs = torch.cat([latent_inputs, points], 1).cuda() \n",
        "sdf_value = decoder(inputs)\n",
        "final_loss = torch.sum(sdf_value.squeeze() * multipliers)\n",
        "final_loss.backward()"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1cxfRK9ozBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "fba5cec2-6a64-4275-f58e-9752fbdebedb"
      },
      "source": [
        "initial_la.grad"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0396, -0.0083, -0.0276,  0.0331, -0.0008, -0.0024, -0.0181,  0.0739,\n",
              "         -0.0333, -0.0102, -0.0067, -0.0213, -0.0454, -0.0162, -0.0028,  0.0183,\n",
              "         -0.0696, -0.0109,  0.0306, -0.0645, -0.0863, -0.0393, -0.0550, -0.0007,\n",
              "          0.0282, -0.0353, -0.0485,  0.0431, -0.0520, -0.0740, -0.0174, -0.0010,\n",
              "         -0.0017, -0.0137,  0.0510,  0.0153, -0.0357, -0.0131, -0.0125,  0.0192,\n",
              "         -0.0038, -0.0423, -0.0079, -0.0215, -0.0523, -0.0109, -0.0048,  0.0535,\n",
              "          0.0255,  0.0199,  0.0198,  0.0064,  0.0490,  0.0064,  0.0281, -0.0743,\n",
              "          0.0041, -0.0052, -0.0256,  0.0042, -0.0384, -0.0225, -0.0540,  0.0127,\n",
              "          0.0082, -0.0139,  0.0199, -0.0067, -0.0105, -0.0246,  0.0348, -0.0164,\n",
              "          0.0306,  0.0128,  0.0442,  0.0247, -0.0145,  0.0225,  0.0438, -0.0461,\n",
              "          0.0077, -0.0616,  0.0379,  0.0124,  0.0081, -0.0238, -0.0464,  0.0750,\n",
              "         -0.0029,  0.0397,  0.0058,  0.0321, -0.0299,  0.0104,  0.0462,  0.0054,\n",
              "         -0.0312,  0.0109, -0.0335,  0.0319, -0.0373, -0.0489, -0.0163, -0.0462,\n",
              "         -0.0746,  0.0152, -0.0224,  0.0255,  0.0442, -0.0360, -0.0040, -0.0775,\n",
              "         -0.0159,  0.0923, -0.0171, -0.0137,  0.0115,  0.0841, -0.0199,  0.0125,\n",
              "         -0.0039, -0.0242, -0.0618,  0.0203,  0.0133, -0.0404, -0.0148,  0.0225,\n",
              "         -0.0444,  0.0025, -0.0281,  0.0269, -0.0348,  0.0538, -0.0501,  0.0117,\n",
              "          0.0018, -0.0267, -0.0008,  0.0139,  0.0628,  0.0559, -0.0162,  0.0102,\n",
              "          0.0256,  0.0050, -0.0311,  0.0026,  0.0241,  0.0304,  0.0599,  0.0607,\n",
              "         -0.0096, -0.0109,  0.0016, -0.0518, -0.0125,  0.0336, -0.0241,  0.0197,\n",
              "         -0.0324, -0.0368, -0.1035,  0.0266,  0.0118,  0.0434,  0.0107, -0.0175,\n",
              "          0.0047,  0.0466,  0.0275, -0.0172, -0.0600, -0.0224,  0.0641,  0.0014,\n",
              "         -0.0107,  0.0176, -0.0567,  0.0116,  0.0094, -0.0101,  0.0084, -0.0948,\n",
              "          0.0171, -0.0152, -0.0292, -0.0071,  0.0144,  0.0259, -0.0261,  0.0424,\n",
              "         -0.0003, -0.0395, -0.0686, -0.0182, -0.0188,  0.0886, -0.0235,  0.0142,\n",
              "         -0.0279, -0.0769,  0.0798,  0.0360, -0.0122,  0.0180,  0.0400,  0.0449,\n",
              "         -0.0441,  0.0245,  0.0718,  0.0309,  0.0085,  0.0019, -0.0085, -0.0039,\n",
              "         -0.0556,  0.0186,  0.0418,  0.0275,  0.0118,  0.0494,  0.0697,  0.0324,\n",
              "         -0.0018, -0.0211, -0.0462, -0.0725, -0.0430, -0.0303,  0.0450,  0.0378,\n",
              "          0.0130,  0.0364, -0.0068, -0.0061,  0.0332, -0.0036, -0.0445,  0.0518,\n",
              "         -0.0579,  0.0420,  0.0430, -0.0236, -0.0186, -0.0090, -0.0175, -0.0912,\n",
              "          0.0268, -0.0894,  0.0221, -0.0560,  0.0381, -0.0112,  0.0053,  0.0416]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T440V-0ao248",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b0ddcc89-4900-4f2b-8403-228a8fea66f3"
      },
      "source": [
        "initial_la.grad.data.zero_()"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3A3dHkwYmKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apenalty = soft_constraints(initial_la, latent_vectors, num_neignours_constr=10, alpha_penalty=0.2)\n",
        "apenalty.backward()"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJJO70Umo7LV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "4b78bd74-8ce6-4c60-f209-a7eafae12fa0"
      },
      "source": [
        "initial_la.grad"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.8731e-03, -2.5570e-04, -7.4762e-03,  1.2652e-02,  1.4758e-03,\n",
              "          1.9030e-03, -3.0499e-04, -6.2661e-03, -2.8730e-03, -3.8519e-03,\n",
              "          2.0746e-02,  1.2408e-02, -8.2761e-03, -1.8472e-02, -1.3300e-02,\n",
              "         -5.8893e-03,  8.9912e-03, -7.6419e-03, -2.6125e-02, -3.4942e-03,\n",
              "         -7.3661e-03,  3.0520e-03,  4.4310e-03,  2.1242e-04,  1.2191e-02,\n",
              "          6.5079e-03,  7.8723e-03, -1.3821e-02,  6.0391e-03,  1.5209e-02,\n",
              "          2.5002e-02, -1.9178e-02, -9.3768e-03, -7.3147e-03,  6.8979e-03,\n",
              "         -1.4118e-02, -2.7267e-03, -1.0791e-02, -2.5826e-03, -1.4086e-02,\n",
              "         -1.6083e-02, -1.3382e-03,  2.0466e-02,  1.5020e-02, -2.1272e-03,\n",
              "         -5.7258e-03,  1.1572e-02,  8.8721e-03, -7.7078e-03, -3.0275e-04,\n",
              "         -3.7853e-03, -9.0178e-04, -1.0578e-02, -4.5459e-02,  2.6372e-03,\n",
              "          7.1483e-03, -4.4091e-03,  2.6710e-03,  5.5337e-03,  1.6178e-02,\n",
              "          1.4492e-02, -1.3250e-02, -2.5350e-03,  1.5047e-02, -1.6097e-02,\n",
              "          2.2751e-03, -9.3751e-03, -4.2976e-03,  6.7859e-03,  1.4200e-02,\n",
              "         -3.0050e-02, -8.5571e-03, -1.6280e-02, -1.9832e-03,  3.1548e-02,\n",
              "          1.1177e-02,  2.6958e-02,  2.3942e-03,  8.2337e-03,  1.0360e-02,\n",
              "         -5.7740e-03,  1.8681e-02,  8.9792e-03,  1.8657e-02, -5.3581e-03,\n",
              "          1.1930e-03, -1.6311e-02,  4.5366e-03,  9.7712e-03,  1.7685e-03,\n",
              "          6.6204e-03,  8.8018e-03,  5.6227e-03, -1.7905e-02, -1.9636e-02,\n",
              "         -1.1183e-02, -2.1265e-02,  8.9083e-03, -1.7518e-02,  3.6275e-04,\n",
              "         -1.7867e-02, -1.1799e-02,  7.8599e-03,  2.4414e-03, -1.8163e-02,\n",
              "         -6.6256e-03, -4.1672e-03, -9.0831e-03,  3.9118e-03, -1.5821e-02,\n",
              "         -9.0312e-03, -8.6554e-03, -1.0598e-02,  1.3169e-02,  1.8716e-02,\n",
              "          1.3212e-02,  1.4646e-02,  2.8523e-02, -4.5826e-03, -2.8218e-03,\n",
              "         -1.4276e-02, -2.7227e-03, -7.6966e-04,  1.7295e-03,  1.4436e-02,\n",
              "          5.0497e-04, -1.0188e-03, -2.5997e-03,  1.1154e-02,  1.0114e-02,\n",
              "         -1.8594e-02, -9.9120e-03,  1.4172e-02,  1.4151e-02,  1.3319e-02,\n",
              "          4.1637e-03,  1.0849e-02, -8.8726e-04,  5.4756e-03, -1.3589e-02,\n",
              "          7.6214e-03, -6.2312e-03, -1.7220e-03, -4.5891e-03,  8.0795e-03,\n",
              "          6.1258e-03, -2.4276e-02,  1.5484e-02, -1.7749e-02,  1.0265e-02,\n",
              "         -4.4898e-03,  2.0962e-02, -2.1940e-02, -7.6242e-03,  2.2610e-02,\n",
              "         -1.4756e-03,  5.9006e-04,  5.0618e-03, -6.2635e-03,  6.5576e-04,\n",
              "         -1.4252e-03, -1.1651e-02, -1.2109e-02,  1.2041e-03, -8.7188e-03,\n",
              "         -7.1363e-03, -1.0076e-02, -1.0695e-02, -1.5561e-04, -1.0174e-02,\n",
              "          1.5885e-02,  2.4363e-02, -5.6042e-03, -2.0882e-02, -1.8315e-03,\n",
              "         -1.5356e-02,  2.7824e-03,  5.1039e-03,  6.5965e-03, -6.1735e-03,\n",
              "          8.9791e-05,  4.5295e-03, -2.0012e-02,  3.4040e-04,  1.7265e-02,\n",
              "         -5.8929e-03, -6.1733e-03, -3.0988e-02, -4.5026e-04, -4.9090e-03,\n",
              "         -2.2199e-02, -3.5304e-03, -1.7224e-02, -1.6293e-04,  1.2730e-02,\n",
              "          2.6787e-02, -5.9392e-03,  1.9179e-02,  6.2865e-03, -9.8761e-03,\n",
              "         -8.5125e-03, -1.4197e-02, -9.7909e-03,  1.0342e-02,  1.1760e-02,\n",
              "          1.9781e-03, -1.0388e-02,  1.2658e-02, -4.0653e-03,  1.1923e-03,\n",
              "          7.7604e-03,  1.0063e-02,  1.2786e-02,  7.6747e-03,  2.3491e-03,\n",
              "          1.1414e-03, -1.5507e-03,  1.3856e-02,  3.3775e-03,  5.1639e-03,\n",
              "         -1.8827e-02,  2.3368e-02, -3.3967e-04, -5.3916e-03,  2.4885e-03,\n",
              "         -1.7318e-02,  3.2494e-03, -3.5972e-02, -8.8039e-03,  7.9165e-04,\n",
              "         -4.8701e-03,  4.4780e-03,  9.9244e-03, -1.5980e-02, -1.2237e-03,\n",
              "         -2.1165e-02, -4.4712e-03,  1.2602e-02,  2.9333e-03, -1.6891e-03,\n",
              "          9.2437e-03,  4.0478e-03,  1.6400e-02, -1.2476e-02,  1.1526e-02,\n",
              "          7.3541e-03,  3.0290e-03,  9.6307e-03,  8.1426e-03, -6.2637e-03,\n",
              "         -5.8573e-03,  6.0206e-04,  1.3691e-02, -8.4645e-03, -3.8016e-03,\n",
              "         -5.2270e-04]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTs5dZL0CuEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ef245aa-ee5b-498c-bad0-054458a7631d"
      },
      "source": [
        "final_loss"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0002, device='cuda:0', grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu57UXaPofQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d943245e-229e-42a9-e299-264325375b4c"
      },
      "source": [
        "penalty"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3987, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpIdfkoR_P4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cc7c36f-56c3-4769-ac0b-5234b45d4ff9"
      },
      "source": [
        "innerBoundsLoss(mesh['x'], r=(0.5 / 2)**2, center=(0.3, 0, 0))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(966.7463, device='cuda:0', grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-pitvgF_znG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "395691c7-70f2-4a76-c31b-21d710e385e0"
      },
      "source": [
        "boundsLoss(mesh['x'], box=[(-0.006, 0.006, 0)])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsOoQcbC1ai1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec93170e-e62f-4933-dd4a-b5debd0f3c2a"
      },
      "source": [
        "local_preds[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7641, -0.4888, -0.5677,  0.0418], device='cuda:0',\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccq6n-_m1h4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efc9c605-a1c0-4b2d-e527-31090152df0f"
      },
      "source": [
        "points.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100733, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y6WBozCieWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ply_mesh.write(\"data_for_this_experiments/mesh32.ply\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkBBg5DtieWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from latent to mesh/point\n",
        "with torch.no_grad():\n",
        "    ply_mesh = create_mesh( decoder,\n",
        "                            latent,\n",
        "                            N=N,\n",
        "                            max_batch=int(2 ** 18),\n",
        "                            offset=None,\n",
        "                            scale=None)\n",
        "points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
        "                                            ply_mesh['vertex']['y'][:, None], \n",
        "                                            ply_mesh['vertex']['z'][:, None])))\n",
        "\n",
        "# from mesh to pressure field\n",
        "points.requires_grad = True\n",
        "mesh = make_mesh_from_points(points, ply_mesh)\n",
        "local_preds = model(mesh)\n",
        "loss = calculate_loss(mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
        "loss.backward()\n",
        "dL_dp = points.grad.clone()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# calculate mesh normal\n",
        "points.grad.data.zero_()\n",
        "sdf_value = decode_sdf(decoder, latent, points)\n",
        "sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda())\n",
        "\n",
        "# assemble constant \n",
        "mults = [-p1.dot(p2) for p1, p2 in zip(dL_dp, points.grad)]       \n",
        "multipliers = torch.cuda.FloatTensor(mults)\n",
        "\n",
        "\n",
        "\n",
        "# get gradient of sdf w.r.t. latent\n",
        "#optimizer.zero_grad()\n",
        "latent.grad.data.zero_()\n",
        "sdf_value = torch.squeeze(.decode_sdf(decoder, latent, points))\n",
        "final_loss = torch.sum(sdf_value * multipliers)\n",
        "final_loss.backward()\n",
        "\n",
        "# artificial loss\n",
        "apenalty = soft_constraints(latent, latent_vectors, num_neignours_constr)\n",
        "apenalty.backward()\n",
        "\n",
        "#print(\"Latent grad penalized: \", torch.sum(latent.grad ** 2))\n",
        "\n",
        "#optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zovrDIQKieWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def method4_to_arbitatry_loss(points, ply_mesh, model, constraint_rad=0.1, axis=0):\n",
        "    initial_dir = points.grad.clone()\n",
        "    points.grad.data.zero_()\n",
        "\n",
        "    mesh = make_mesh_from_points(points, ply_mesh)\n",
        "    #signs = compute_signs_for_loss(mesh, transformPoints(normals, AvgTransform))\n",
        "    local_preds = model(mesh)\n",
        "    loss = calculate_loss(mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
        "    loss.backward()\n",
        "\n",
        "    sign = [-p1.dot(p2) for p1, p2 in zip(initial_dir, points.grad)]\n",
        "    \n",
        "    return sign, loss, local_preds, mesh\n",
        "\n",
        "\n",
        "\n",
        "def optimize_shape_deepSDF(decoder, latent, ref_latent, initial_points=None, num_points=None, \n",
        "                           num_iters=100, point_iters=100,  punch_lr_at_reindex_by=1, num_neignours_constr=10,\n",
        "                           reindex_latent_each=50, reindex_num_iterations=500, reindex_num_samples=100,\n",
        "                           lr=0.2, decreased_by=2, adjust_lr_every=10, alpha_penalty=0.05,\n",
        "                           multiplier_func=method4_to_arbitatry_loss, verbose=None, save_to_dir=None, N=256):\n",
        "\n",
        "    def adjust_learning_rate(\n",
        "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
        "    ):\n",
        "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every)) \\\n",
        "                        * ((punch_lr_at_reindex_by) ** (num_iterations // reindex_latent_each))\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group[\"lr\"] = lr\n",
        "            \n",
        "        return lr\n",
        "    \n",
        "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
        "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
        "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
        "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
        "\n",
        "    decoder.eval()\n",
        "    latent = latent.clone()\n",
        "    latent.requires_grad = True\n",
        "    optimizer = torch.optim.SGD([latent], lr=lr)\n",
        "\n",
        "    loss_plot = []\n",
        "    latent_dist = []\n",
        "    lr_plot = []\n",
        "\n",
        "    #if initial_points is not None:\n",
        "    #    points = initial_points.clone()\n",
        "    #else:\n",
        "    #    points = get_points_from_latent(decoder, latent, N=N, point_num=num_points)\n",
        "\n",
        "    for i in range(num_iters):\n",
        "\n",
        "        time_start = time.time()\n",
        "\n",
        "        save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
        "        preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
        "\n",
        "\n",
        "        cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            ply_mesh = create_mesh( decoder,\n",
        "                                    latent,\n",
        "                                    N=N,\n",
        "                                    max_batch=int(2 ** 18),\n",
        "                                    offset=None,\n",
        "                                    scale=None)\n",
        "\n",
        "        points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
        "                                                    ply_mesh['vertex']['y'][:, None], \n",
        "                                                    ply_mesh['vertex']['z'][:, None])))\n",
        "\n",
        "        points.requires_grad = True\n",
        "\n",
        "        sdf_value = decode_sdf(decoder, latent, points)\n",
        "        ## ???\n",
        "        sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda())\n",
        "\n",
        "        mults, loss_value, preds, transformed_mesh = multiplier_func(points, ply_mesh)         \n",
        "        multipliers = torch.cuda.FloatTensor(mults)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        sdf_value = torch.squeeze(deep_sdf.utils.decode_sdf(decoder, latent, points))\n",
        "\n",
        "        final_loss = torch.sum(sdf_value * multipliers)\n",
        "        final_loss.backward()\n",
        "\n",
        "\n",
        "        # Soft-constraints\n",
        "        distances, indeces = LATENT_KD_TREE.query(latent.cpu().detach(), k=num_neignours_constr)\n",
        "        penalty = torch.mean(\n",
        "                    torch.stack([torch.sum( \n",
        "                                    (latent - latent_vectors[indeces[0][i]]) ** 2\n",
        "                                 )\n",
        "                                 for i in range(len(indeces[0]))]\n",
        "                               )\n",
        "                    )\n",
        "        apenalty = penalty * alpha_penalty\n",
        "        apenalty.backward()\n",
        "        #print(\"Latent grad penalized: \", torch.sum(latent.grad ** 2))\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Hard-constraints\n",
        "#             if (torch.sum(latent ** 2) > 1.2):\n",
        "#                 latent *= 1.2 / torch.sum(latent ** 2)\n",
        "\n",
        "#             loss_value, preds = loss_func(points, ply_mesh)            \n",
        "\n",
        "        tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, preds)\n",
        "        tri_mesh.export(save_path)\n",
        "        np.save(preds_save_path, preds.cpu().detach().numpy())\n",
        "\n",
        "        if save_to_dir is not None:\n",
        "            plot_points_from_torch\n",
        "\n",
        "        loss_plot.append(loss_value.cpu().detach().numpy())\n",
        "        latent_dist.append(torch.sum((latent - ref_latent) ** 2 ).cpu().detach().numpy() )\n",
        "        lr_plot.append(penalty)\n",
        "\n",
        "        time_end = time.time()\n",
        "\n",
        "        if verbose is not None and i % verbose == 0:\n",
        "            print('Iter ', i, 'Loss: ', loss_value.detach().cpu().numpy(), ' LD: ', lr_plot[-1])\n",
        "\n",
        "        np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), loss_plot)\n",
        "        np.save(os.path.join(save_to_dir, \"latent_dist.npy\"), latent_dist)\n",
        "        np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
        "        np.save(os.path.join(save_to_dir, \"latent%d.npy\" % i), latent.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "def make_full_transformation(initial_latent, ref_latent, experiment_name, \n",
        "                             decoder, model, alpha_penalty=0.05, constraint_rad=0.1, axis=0, **kwargs):\n",
        "    '''\n",
        "    kwargs:\n",
        "        num_iters=1000, \n",
        "        adjust_lr_every=10, \n",
        "        decreased_by=1.2,\n",
        "        lr=0.005,\n",
        "        \n",
        "        reindex_latent_each=100,\n",
        "        punch_lr_at_reindex_by=1,\n",
        "        reindex_num_iterations=500, \n",
        "        reindex_num_samples=100,\n",
        "        \n",
        "        verbose=10,\n",
        "    '''\n",
        "\n",
        "    #ref_points = get_points_from_latent(decoder, ref_latent, N=128)\n",
        "\n",
        "    save_to_dir = experiment_name\n",
        "    if not os.path.exists(save_to_dir):\n",
        "        os.makedirs(save_to_dir)\n",
        "\n",
        "    #np.save(os.path.join(save_to_dir, \"target_verts.npy\"), ref_points)\n",
        "\n",
        "    optimize_shape_deepSDF(decoder, initial_latent, ref_latent, initial_points=None,\n",
        "                                           alpha_penalty=alpha_penalty,\n",
        "                                           num_points=None, point_iters=2,\n",
        "                                           multiplier_func=lambda x, y: \n",
        "                                               method4_to_arbitatry_loss(x, y, model, \n",
        "                                                                         constraint_rad=constraint_rad, \n",
        "                                                                         axis=axis),\n",
        "                                           save_to_dir=save_to_dir, **kwargs)\n",
        "\n",
        "experiment_directory = \"/cvlabdata2/home/artem/DeepSDF/examples/cars_cleared/\"\n",
        "checkpoint = \"latest\"\n",
        "decoder = load_model(experiment_directory, checkpoint).to('cuda:0')\n",
        "latent_vectors = ws.load_latent_vectors(experiment_directory, checkpoint)\n",
        "model = None\n",
        "DIR_for_dump_data = './data_for_this_experiments'\n",
        "LATENT_TO_OPTIMIZE = latent_vectors[32]\n",
        "\n",
        "make_full_transformation(LATENT_TO_OPTIMIZE.detach(), LATENT_TO_OPTIMIZE.clone(), \n",
        "                                    DIR_for_dump_data, decoder, model,\n",
        "                         alpha_penalty=0.2, axis=0,\n",
        "                         constraint_rad=0.05,\n",
        "                         num_iters=30,\n",
        "                         adjust_lr_every=20,\n",
        "                         decreased_by=1.1, \n",
        "                         lr=0.2,\n",
        "                         verbose=None,\n",
        "                         N=256,\n",
        "                         num_neignours_constr=10,\n",
        "                         reindex_latent_each=10000,\n",
        "                         punch_lr_at_reindex_by=1,\n",
        "                         reindex_num_iterations=500,\n",
        "                         reindex_num_samples=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJJyuM71ieWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_H2o92JieWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-LdeJ1zieWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ85ST4pieWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY9La8xqieWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mesh = {'point_pos': tansformed_points, \n",
        "        'edge_vec':torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
        "        'edge_index':torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0')\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}