{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import deep_sdf.workspace as ws\n",
    "import skimage.measure\n",
    "import plyfile\n",
    "from plyfile import PlyData\n",
    "#from pyntcloud import PyntCloud\n",
    "import deep_sdf\n",
    "import deep_sdf.workspace as ws\n",
    "import trimesh\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_subdir = \"ModelParameters\"\n",
    "optimizer_params_subdir = \"OptimizerParameters\"\n",
    "latent_codes_subdir = \"LatentCodes\"\n",
    "logs_filename = \"Logs.pth\"\n",
    "reconstructions_subdir = \"Reconstructions\"\n",
    "reconstruction_meshes_subdir = \"Meshes\"\n",
    "reconstruction_codes_subdir = \"Codes\"\n",
    "specifications_filename = \"specs.json\"\n",
    "data_source_map_filename = \".datasources.json\"\n",
    "evaluation_subdir = \"Evaluation\"\n",
    "sdf_samples_subdir = \"SdfSamples\"\n",
    "surface_samples_subdir = \"SurfaceSamples\"\n",
    "normalization_param_subdir = \"NormalizationParameters\"\n",
    "training_meshes_subdir = \"TrainingMeshes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latent_vectors(experiment_directory, checkpoint):\n",
    "\n",
    "    filename = os.path.join(\n",
    "        experiment_directory, \"LatentCodes\", checkpoint + \".pth\"\n",
    "    )\n",
    "\n",
    "    if not os.path.isfile(filename):\n",
    "        raise Exception(\n",
    "            \"The experiment directory ({}) does not include a latent code file\"\n",
    "            + \" for checkpoint '{}'\".format(experiment_directory, checkpoint)\n",
    "        )\n",
    "\n",
    "    data = torch.load(filename)\n",
    "    num_vecs = data[\"latent_codes\"].size()[0]\n",
    "\n",
    "    lat_vecs = []\n",
    "    for i in range(num_vecs):\n",
    "        lat_vecs.append(data[\"latent_codes\"][i].cuda())\n",
    "\n",
    "    return lat_vecs\n",
    "\n",
    "def load_model(experiment_directory, checkpoint):\n",
    "    specs_filename = os.path.join(experiment_directory, \"specs.json\")\n",
    "\n",
    "    if not os.path.isfile(specs_filename):\n",
    "        raise Exception(\n",
    "            'The experiment directory does not include specifications file \"specs.json\"'\n",
    "        )\n",
    "\n",
    "    specs = json.load(open(specs_filename))\n",
    "\n",
    "    arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
    "\n",
    "    latent_size = specs[\"CodeLength\"]\n",
    "\n",
    "    decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "\n",
    "    decoder = torch.nn.DataParallel(decoder)\n",
    "\n",
    "    saved_model_state = torch.load(\n",
    "        os.path.join(experiment_directory, ws.model_params_subdir, checkpoint + \".pth\")\n",
    "    )\n",
    "    saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "    decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "\n",
    "    decoder = decoder.module.cuda()\n",
    "\n",
    "    decoder.eval()\n",
    "    \n",
    "    return decoder\n",
    "\n",
    "def create_mesh(\n",
    "    decoder, latent_vec, filename='', N=256, max_batch=32 ** 3, offset=None, scale=None\n",
    "):\n",
    "    start = time.time()\n",
    "    ply_filename = filename\n",
    "\n",
    "    decoder.eval()\n",
    "\n",
    "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "    voxel_origin = [-1, -1, -1]\n",
    "    voxel_size = 2.0 / (N - 1)\n",
    "\n",
    "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "    samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z index\n",
    "    samples[:, 2] = overall_index % N\n",
    "    samples[:, 1] = (overall_index.long() / N) % N\n",
    "    samples[:, 0] = ((overall_index.long() / N) / N) % N\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z coordinate\n",
    "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
    "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
    "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
    "\n",
    "    num_samples = N ** 3\n",
    "\n",
    "    samples.requires_grad = False\n",
    "\n",
    "    head = 0\n",
    "\n",
    "    while head < num_samples:\n",
    "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()\n",
    "\n",
    "        samples[head : min(head + max_batch, num_samples), 3] = \\\n",
    "                decode_sdf(decoder, latent_vec, sample_subset).squeeze(1).detach().cpu()\n",
    "        head += max_batch\n",
    "\n",
    "    sdf_values = samples[:, 3]\n",
    "    sdf_values = sdf_values.reshape(N, N, N)\n",
    "\n",
    "    end = time.time()\n",
    "    #print(\"sampling takes: %f\" % (end - start))\n",
    "\n",
    "    return convert_sdf_samples_to_ply(\n",
    "        sdf_values.data.cpu(),\n",
    "        voxel_origin,\n",
    "        voxel_size,\n",
    "        ply_filename + \".ply\",\n",
    "        offset,\n",
    "        scale,\n",
    "    )\n",
    "\n",
    "def convert_sdf_samples_to_ply(\n",
    "    pytorch_3d_sdf_tensor,\n",
    "    voxel_grid_origin,\n",
    "    voxel_size,\n",
    "    ply_filename_out,\n",
    "    offset=None,\n",
    "    scale=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert sdf samples to .ply\n",
    "\n",
    "    :param pytorch_3d_sdf_tensor: a torch.FloatTensor of shape (n,n,n)\n",
    "    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n",
    "    :voxel_size: float, the size of the voxels\n",
    "    :ply_filename_out: string, path of the filename to save to\n",
    "\n",
    "    This function adapted from: https://github.com/RobotLocomotion/spartan\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    numpy_3d_sdf_tensor = pytorch_3d_sdf_tensor.numpy()\n",
    "\n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes_lewiner(\n",
    "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3\n",
    "    )\n",
    "\n",
    "    # transform from voxel coordinates to camera coordinates\n",
    "    # note x and y are flipped in the output of marching_cubes\n",
    "    mesh_points = np.zeros_like(verts)\n",
    "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
    "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
    "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
    "\n",
    "    # apply additional offset and scale\n",
    "    if scale is not None:\n",
    "        mesh_points = mesh_points / scale\n",
    "    if offset is not None:\n",
    "        mesh_points = mesh_points - offset\n",
    "\n",
    "    # try writing to the ply file\n",
    "\n",
    "    num_verts = verts.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "\n",
    "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "    norms_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "\n",
    "    for i in range(0, num_verts):\n",
    "        verts_tuple[i] = tuple(mesh_points[i, :])\n",
    "        norms_tuple[i] = tuple(normals[i, :])\n",
    "\n",
    "    faces_building = []\n",
    "    for i in range(0, num_faces):\n",
    "        faces_building.append(((faces[i, :].tolist(),)))\n",
    "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
    "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
    "    el_norms = plyfile.PlyElement.describe(norms_tuple, \"normals\")\n",
    "\n",
    "    ply_data = plyfile.PlyData([el_verts, el_faces, el_norms])\n",
    "    return ply_data\n",
    "\n",
    "def decode_sdf(decoder, latent_vector, queries):\n",
    "    num_samples = queries.shape[0]\n",
    "\n",
    "    if latent_vector is None:\n",
    "        inputs = queries\n",
    "    else:\n",
    "        latent_repeat = latent_vector.expand(num_samples, -1)\n",
    "        inputs = torch.cat([latent_repeat, queries], 1)\n",
    "\n",
    "    sdf = decoder(inputs)\n",
    "\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lift_faces_diff(data_instance, answers, axis=0):\n",
    "    pressures = torch.mean(answers[data_instance.face, 0], axis=0)\n",
    "\n",
    "    # TODO: cahnge to x if needed\n",
    "    pos = data_instance.x\n",
    "    cross_prod = (pos[data_instance.face[1]] - pos[data_instance.face[0]]).cross(\n",
    "                  pos[data_instance.face[2]] - pos[data_instance.face[0]])\n",
    "    mult = -cross_prod[:, axis] / 2\n",
    "    lift = torch.mul(pressures, mult)\n",
    "    return torch.sum(lift[~torch.isnan(lift)])\n",
    "\n",
    "def boundsLoss(points, box=[(-1, 1, 0)]):\n",
    "    loss = 0\n",
    "    for l, r, i in box:\n",
    "        loss +=  torch.mean(F.relu(-points[:, i] + l))  \\\n",
    "               + torch.mean(F.relu( points[:, i] - r))\n",
    "    return loss\n",
    "\n",
    "def innerBoundsLoss(points, r=1, center=(0, 0, 0)):\n",
    "    radiuses = torch.sum( (points - torch.Tensor(center).to('cuda:0')) ** 2 , dim=1)\n",
    "    return torch.sum(F.relu(r - radiuses))\n",
    "\n",
    "def calculate_loss(mesh, local_preds, axis=0, constraint_rad=0.1):\n",
    "    loss =  (1 - axis) * compute_lift_faces_diff(mesh, local_preds, axis=0) + \\\n",
    "                  axis * compute_lift_faces_diff(mesh, local_preds, axis=1)\n",
    "    \n",
    "    loss += boundsLoss(mesh.x, box=[(-0.6, 0.6, 0)])\n",
    "    loss += innerBoundsLoss(mesh.x, r=constraint_rad**2, center=(-0.05, 0.05, 0))  \\\n",
    "          + innerBoundsLoss(mesh.x, r=(constraint_rad / 2)**2, center=(0.3, 0, 0))\n",
    "    return loss\n",
    "\n",
    "def soft_constraints(latent, latent_vectors, num_neignours_constr):\n",
    "    # Soft-constraints\n",
    "    distances, indeces = LATENT_KD_TREE.query(latent.cpu().detach(), k=num_neignours_constr)\n",
    "    penalty = torch.mean(\n",
    "            torch.stack([torch.sum( (latent - latent_vectors[indeces[0][i]]) ** 2)\n",
    "                         for i in range(len(indeces[0]))]))\n",
    "    return penalty * alpha_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAvgTransform():\n",
    "    objects = list()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(\"/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/transforms/\"):\n",
    "        objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.npy']\n",
    "    \n",
    "    matricies = []\n",
    "    for obj in objects:\n",
    "        matricies.append(np.load(obj))\n",
    "    \n",
    "    return np.mean(np.array(matricies), axis=0)\n",
    "\n",
    "def transformPoints(points):\n",
    "    matrix = torch.cuda.FloatTensor(AvgTransform)\n",
    "    column = torch.zeros((len(points), 1), device=\"cuda:0\") + 1\n",
    "    stacked = torch.cat([points, column], dim=1)\n",
    "    transformed = torch.matmul(matrix, stacked.t()).t()[:, :3]\n",
    "    return transformed\n",
    "\n",
    "def make_mesh_from_points(points, ply_mesh):\n",
    "    transformed_points = transformPoints(points)\n",
    "    \n",
    "    edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
    "    np_points = transformed_points.cpu().detach().numpy()\n",
    "    edge_attr = [np_points[a] - np_points[b] for a, b in edges]\n",
    "    mesh = {'x': tansformed_points, \n",
    "        'edge_attr':torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "        'edge_index':torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0')\n",
    "        }\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineBlock(nn.Module):\n",
    "    def __init__(self, num_in_features, num_outp_features, mid_features, kernel=3, dim=3, batchnorm1=True):\n",
    "        super(SplineBlock, self).__init__()\n",
    "        self.batchnorm1 = batchnorm1\n",
    "        self.conv1 = SplineConv(num_in_features, mid_features, dim, kernel, is_open_spline=False)\n",
    "        if self.batchnorm1:\n",
    "            self.batchnorm1 = torch.nn.BatchNorm1d(mid_features)\n",
    "        self.conv2 = SplineConv(mid_features, 2 * mid_features, dim, kernel, is_open_spline=False)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(2 * mid_features)\n",
    "        self.conv3 = SplineConv(2 * mid_features + 3, num_outp_features, dim, kernel, is_open_spline=False)\n",
    "  \n",
    "    def forward(self, res, data):\n",
    "        if self.batchnorm1:\n",
    "            res = F.elu(self.batchnorm1(self.conv1(res, data['edge_index'], data['edge_vec'])))\n",
    "        else:\n",
    "            res = F.elu(self.conv1(res, data['edge_index'], data['edge_vec']))\n",
    "        res = F.elu(self.batchnorm2(self.conv2(res, data['edge_index'], data['edge_vec'])))\n",
    "#         res = F.elu(self.conv2(res, data.edge_index, data.edge_attr))\n",
    "        res = torch.cat([res, data['point_pos']], dim=1)\n",
    "        res = self.conv3(res, data['edge_index'], data['edge_vec'])\n",
    "        return res\n",
    "\n",
    "class SplineCNN8Residuals(nn.Module):\n",
    "    def __init__(self, num_features, kernel=3, dim=3):\n",
    "        super(SplineCNN8Residuals, self).__init__()\n",
    "        self.block1 = SplineBlock(num_features, 16, 8, kernel, dim)\n",
    "        self.block2 = SplineBlock(16, 64, 32, kernel, dim)\n",
    "        self.block3 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block4 = SplineBlock(64, 8, 16, kernel, dim)\n",
    "        self.block5 = SplineBlock(11, 32, 16, kernel, dim)\n",
    "        self.block6 = SplineBlock(32, 64, 32, kernel, dim)\n",
    "        self.block7 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block8 = SplineBlock(75, 4, 16, kernel, dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        res = data['point_pos']\n",
    "        res = self.block1(res, data)\n",
    "        res = self.block2(res, data)\n",
    "        res = self.block3(res, data)\n",
    "        res4 = self.block4(res, data)\n",
    "        res = torch.cat([res4, data.x], dim=1)\n",
    "        res = self.block5(res, data)\n",
    "        res = self.block6(res, data)\n",
    "        res = self.block7(res, data)\n",
    "        res = torch.cat([res, res4, data.x], dim=1)\n",
    "        res = self.block8(res, data)\n",
    "        return res\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_directory = \"/cvlabdata2/home/artem/DeepSDF/examples/cars_cleared/\"\n",
    "DIR_for_dump_data = './data_for_this_experiments'\n",
    "checkpoint = \"latest\"\n",
    "\n",
    "model = SplineCNN8Residuals(3)\n",
    "model.load_state_dict(torch.load(\"/cvlabdata2/home/artem/DeepSDF/Expirements/Networks15/normilized_full_latest.nn\"))\n",
    "model = model.to(\"cuda:0\")\n",
    "model = model.eval()\n",
    "\n",
    "decoder = load_model(experiment_directory, checkpoint).to('cuda:0')\n",
    "\n",
    "latent_vectors = load_latent_vectors(experiment_directory, checkpoint)\n",
    "\n",
    "LATENT_TO_OPTIMIZE = latent_vectors[32]\n",
    "LATENT_KD_TREE = KDTree(np.array([lv.cpu().detach().numpy()[0] for lv in latent_vectors]))\n",
    "AvgTransform = computeAvgTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1205"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_la = latent_vectors[32]\n",
    "ply_mesh = create_mesh( decoder,\n",
    "                        initial_la,\n",
    "                        N=256,\n",
    "                        max_batch=int(2 ** 18),\n",
    "                        offset=None,\n",
    "                        scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vectors[32].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from latent to mesh/point\n",
    "with torch.no_grad():\n",
    "    ply_mesh = create_mesh( decoder,\n",
    "                            latent,\n",
    "                            N=N,\n",
    "                            max_batch=int(2 ** 18),\n",
    "                            offset=None,\n",
    "                            scale=None)\n",
    "points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                            ply_mesh['vertex']['y'][:, None], \n",
    "                                            ply_mesh['vertex']['z'][:, None])))\n",
    "\n",
    "# from mesh to pressure field\n",
    "points.requires_grad = True\n",
    "mesh = make_mesh_from_points(points, ply_mesh)\n",
    "local_preds = model(mesh)\n",
    "loss = calculate_loss(mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
    "loss.backward()\n",
    "dL_dp = points.grad.clone()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate mesh normal\n",
    "points.grad.data.zero_()\n",
    "sdf_value = decode_sdf(decoder, latent, points)\n",
    "sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda())\n",
    "\n",
    "# assemble constant \n",
    "mults = [-p1.dot(p2) for p1, p2 in zip(dL_dp, points.grad)]       \n",
    "multipliers = torch.cuda.FloatTensor(mults)\n",
    "\n",
    "\n",
    "\n",
    "# get gradient of sdf w.r.t. latent\n",
    "#optimizer.zero_grad()\n",
    "latent.grad.data.zero_()\n",
    "sdf_value = torch.squeeze(deep_sdf.utils.decode_sdf(decoder, latent, points))\n",
    "final_loss = torch.sum(sdf_value * multipliers)\n",
    "final_loss.backward()\n",
    "\n",
    "# artificial loss\n",
    "apenalty = soft_constraints(latent, latent_vectors, num_neignours_constr)\n",
    "apenalty.backward()\n",
    "\n",
    "#print(\"Latent grad penalized: \", torch.sum(latent.grad ** 2))\n",
    "\n",
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method4_to_arbitatry_loss(points, ply_mesh, model, constraint_rad=0.1, axis=0):\n",
    "    initial_dir = points.grad.clone()\n",
    "    points.grad.data.zero_()\n",
    "\n",
    "    mesh = make_mesh_from_points(points, ply_mesh)\n",
    "    #signs = compute_signs_for_loss(mesh, transformPoints(normals, AvgTransform))\n",
    "    local_preds = model(mesh)\n",
    "    loss = calculate_loss(mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
    "    loss.backward()\n",
    "\n",
    "    sign = [-p1.dot(p2) for p1, p2 in zip(initial_dir, points.grad)]\n",
    "    \n",
    "    return sign, loss, local_preds, mesh\n",
    "\n",
    "\n",
    "\n",
    "def optimize_shape_deepSDF(decoder, latent, ref_latent, initial_points=None, num_points=None, \n",
    "                           num_iters=100, point_iters=100,  punch_lr_at_reindex_by=1, num_neignours_constr=10,\n",
    "                           reindex_latent_each=50, reindex_num_iterations=500, reindex_num_samples=100,\n",
    "                           lr=0.2, decreased_by=2, adjust_lr_every=10, alpha_penalty=0.05,\n",
    "                           multiplier_func=method4_to_arbitatry_loss, verbose=None, save_to_dir=None, N=256):\n",
    "\n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every)) \\\n",
    "                        * ((punch_lr_at_reindex_by) ** (num_iterations // reindex_latent_each))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "    \n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "\n",
    "    decoder.eval()\n",
    "    latent = latent.clone()\n",
    "    latent.requires_grad = True\n",
    "    optimizer = torch.optim.SGD([latent], lr=lr)\n",
    "\n",
    "    loss_plot = []\n",
    "    latent_dist = []\n",
    "    lr_plot = []\n",
    "\n",
    "    #if initial_points is not None:\n",
    "    #    points = initial_points.clone()\n",
    "    #else:\n",
    "    #    points = get_points_from_latent(decoder, latent, N=N, point_num=num_points)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        time_start = time.time()\n",
    "\n",
    "        save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "        preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "\n",
    "        cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ply_mesh = create_mesh( decoder,\n",
    "                                    latent,\n",
    "                                    N=N,\n",
    "                                    max_batch=int(2 ** 18),\n",
    "                                    offset=None,\n",
    "                                    scale=None)\n",
    "\n",
    "        points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                                    ply_mesh['vertex']['y'][:, None], \n",
    "                                                    ply_mesh['vertex']['z'][:, None])))\n",
    "\n",
    "        points.requires_grad = True\n",
    "\n",
    "        sdf_value = decode_sdf(decoder, latent, points)\n",
    "        ## ???\n",
    "        sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda())\n",
    "\n",
    "        mults, loss_value, preds, transformed_mesh = multiplier_func(points, ply_mesh)         \n",
    "        multipliers = torch.cuda.FloatTensor(mults)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sdf_value = torch.squeeze(deep_sdf.utils.decode_sdf(decoder, latent, points))\n",
    "\n",
    "        final_loss = torch.sum(sdf_value * multipliers)\n",
    "        final_loss.backward()\n",
    "\n",
    "\n",
    "        # Soft-constraints\n",
    "        distances, indeces = LATENT_KD_TREE.query(latent.cpu().detach(), k=num_neignours_constr)\n",
    "        penalty = torch.mean(\n",
    "                    torch.stack([torch.sum( \n",
    "                                    (latent - latent_vectors[indeces[0][i]]) ** 2\n",
    "                                 )\n",
    "                                 for i in range(len(indeces[0]))]\n",
    "                               )\n",
    "                    )\n",
    "        apenalty = penalty * alpha_penalty\n",
    "        apenalty.backward()\n",
    "        #print(\"Latent grad penalized: \", torch.sum(latent.grad ** 2))\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Hard-constraints\n",
    "#             if (torch.sum(latent ** 2) > 1.2):\n",
    "#                 latent *= 1.2 / torch.sum(latent ** 2)\n",
    "\n",
    "#             loss_value, preds = loss_func(points, ply_mesh)            \n",
    "\n",
    "        tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, preds)\n",
    "        tri_mesh.export(save_path)\n",
    "        np.save(preds_save_path, preds.cpu().detach().numpy())\n",
    "\n",
    "        if save_to_dir is not None:\n",
    "            plot_points_from_torch\n",
    "\n",
    "        loss_plot.append(loss_value.cpu().detach().numpy())\n",
    "        latent_dist.append(torch.sum((latent - ref_latent) ** 2 ).cpu().detach().numpy() )\n",
    "        lr_plot.append(penalty)\n",
    "\n",
    "        time_end = time.time()\n",
    "\n",
    "        if verbose is not None and i % verbose == 0:\n",
    "            print('Iter ', i, 'Loss: ', loss_value.detach().cpu().numpy(), ' LD: ', lr_plot[-1])\n",
    "\n",
    "        np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), loss_plot)\n",
    "        np.save(os.path.join(save_to_dir, \"latent_dist.npy\"), latent_dist)\n",
    "        np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
    "        np.save(os.path.join(save_to_dir, \"latent%d.npy\" % i), latent.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "def make_full_transformation(initial_latent, ref_latent, experiment_name, \n",
    "                             decoder, model, alpha_penalty=0.05, constraint_rad=0.1, axis=0, **kwargs):\n",
    "    '''\n",
    "    kwargs:\n",
    "        num_iters=1000, \n",
    "        adjust_lr_every=10, \n",
    "        decreased_by=1.2,\n",
    "        lr=0.005,\n",
    "        \n",
    "        reindex_latent_each=100,\n",
    "        punch_lr_at_reindex_by=1,\n",
    "        reindex_num_iterations=500, \n",
    "        reindex_num_samples=100,\n",
    "        \n",
    "        verbose=10,\n",
    "    '''\n",
    "\n",
    "    #ref_points = get_points_from_latent(decoder, ref_latent, N=128)\n",
    "\n",
    "    save_to_dir = experiment_name\n",
    "    if not os.path.exists(save_to_dir):\n",
    "        os.makedirs(save_to_dir)\n",
    "\n",
    "    #np.save(os.path.join(save_to_dir, \"target_verts.npy\"), ref_points)\n",
    "\n",
    "    optimize_shape_deepSDF(decoder, initial_latent, ref_latent, initial_points=None,\n",
    "                                           alpha_penalty=alpha_penalty,\n",
    "                                           num_points=None, point_iters=2,\n",
    "                                           multiplier_func=lambda x, y: \n",
    "                                               method4_to_arbitatry_loss(x, y, model, \n",
    "                                                                         constraint_rad=constraint_rad, \n",
    "                                                                         axis=axis),\n",
    "                                           save_to_dir=save_to_dir, **kwargs)\n",
    "\n",
    "experiment_directory = \"/cvlabdata2/home/artem/DeepSDF/examples/cars_cleared/\"\n",
    "checkpoint = \"latest\"\n",
    "decoder = load_model(experiment_directory, checkpoint).to('cuda:0')\n",
    "latent_vectors = ws.load_latent_vectors(experiment_directory, checkpoint)\n",
    "model = None\n",
    "DIR_for_dump_data = './data_for_this_experiments'\n",
    "LATENT_TO_OPTIMIZE = latent_vectors[32]\n",
    "\n",
    "make_full_transformation(LATENT_TO_OPTIMIZE.detach(), LATENT_TO_OPTIMIZE.clone(), \n",
    "                                    DIR_for_dump_data, decoder, model,\n",
    "                         alpha_penalty=0.2, axis=0,\n",
    "                         constraint_rad=0.05,\n",
    "                         num_iters=30,\n",
    "                         adjust_lr_every=20,\n",
    "                         decreased_by=1.1, \n",
    "                         lr=0.2,\n",
    "                         verbose=None,\n",
    "                         N=256,\n",
    "                         num_neignours_constr=10,\n",
    "                         reindex_latent_each=10000,\n",
    "                         punch_lr_at_reindex_by=1,\n",
    "                         reindex_num_iterations=500,\n",
    "                         reindex_num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = {'point_pos': tansformed_points, \n",
    "        'edge_vec':torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "        'edge_index':torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0')\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
