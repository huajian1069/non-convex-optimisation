{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)\n",
    "\n",
    "#from neuralnet_pytorch.metrics import chamfer_loss\n",
    "\n",
    "import trimesh\n",
    "\n",
    "from visualization_utils import plot_mesh_3d\n",
    "\n",
    "import deep_sdf\n",
    "import deep_sdf.workspace as ws\n",
    "from models import *\n",
    "from datasets import *\n",
    "from custom_utils import *\n",
    "\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5a3c792349e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNNConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGMMConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet2Set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSplineConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraclus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pool_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lowCuda/lib/python3.7/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lowCuda/lib/python3.7/site-packages/torch_geometric/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lowCuda/lib/python3.7/site-packages/torch_geometric/nn/data_parallel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lowCuda/lib/python3.7/site-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0min_memory_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataListLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lowCuda/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m from torch_geometric.utils import (contains_isolated_nodes,\n\u001b[1;32m      9\u001b[0m                                    contains_self_loops, is_undirected)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_sparse'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mesh(\n",
    "    decoder, latent_vec, filename='', N=256, max_batch=32 ** 3, offset=None, scale=None\n",
    "):\n",
    "    start = time.time()\n",
    "    ply_filename = filename\n",
    "\n",
    "    decoder.eval()\n",
    "\n",
    "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "    voxel_origin = [-1, -1, -1]\n",
    "    voxel_size = 2.0 / (N - 1)\n",
    "\n",
    "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "    samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z index\n",
    "    samples[:, 2] = overall_index % N\n",
    "    samples[:, 1] = (overall_index.long() / N) % N\n",
    "    samples[:, 0] = ((overall_index.long() / N) / N) % N\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z coordinate\n",
    "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
    "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
    "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
    "\n",
    "    num_samples = N ** 3\n",
    "\n",
    "    samples.requires_grad = False\n",
    "\n",
    "    head = 0\n",
    "\n",
    "    while head < num_samples:\n",
    "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()\n",
    "\n",
    "        samples[head : min(head + max_batch, num_samples), 3] = (\n",
    "            deep_sdf.utils.decode_sdf(decoder, latent_vec, sample_subset)\n",
    "            .squeeze(1)\n",
    "            .detach()\n",
    "            .cpu()\n",
    "        )\n",
    "        head += max_batch\n",
    "\n",
    "    sdf_values = samples[:, 3]\n",
    "    sdf_values = sdf_values.reshape(N, N, N)\n",
    "\n",
    "    end = time.time()\n",
    "    #print(\"sampling takes: %f\" % (end - start))\n",
    "\n",
    "    return convert_sdf_samples_to_ply(\n",
    "        sdf_values.data.cpu(),\n",
    "        voxel_origin,\n",
    "        voxel_size,\n",
    "        ply_filename + \".ply\",\n",
    "        offset,\n",
    "        scale,\n",
    "    )\n",
    "\n",
    "def convert_sdf_samples_to_ply(\n",
    "    pytorch_3d_sdf_tensor,\n",
    "    voxel_grid_origin,\n",
    "    voxel_size,\n",
    "    ply_filename_out,\n",
    "    offset=None,\n",
    "    scale=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert sdf samples to .ply\n",
    "\n",
    "    :param pytorch_3d_sdf_tensor: a torch.FloatTensor of shape (n,n,n)\n",
    "    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n",
    "    :voxel_size: float, the size of the voxels\n",
    "    :ply_filename_out: string, path of the filename to save to\n",
    "\n",
    "    This function adapted from: https://github.com/RobotLocomotion/spartan\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    numpy_3d_sdf_tensor = pytorch_3d_sdf_tensor.numpy()\n",
    "\n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes_lewiner(\n",
    "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3\n",
    "    )\n",
    "\n",
    "    # transform from voxel coordinates to camera coordinates\n",
    "    # note x and y are flipped in the output of marching_cubes\n",
    "    mesh_points = np.zeros_like(verts)\n",
    "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
    "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
    "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
    "\n",
    "    # apply additional offset and scale\n",
    "    if scale is not None:\n",
    "        mesh_points = mesh_points / scale\n",
    "    if offset is not None:\n",
    "        mesh_points = mesh_points - offset\n",
    "\n",
    "    # try writing to the ply file\n",
    "\n",
    "    num_verts = verts.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "\n",
    "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "    norms_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "\n",
    "    for i in range(0, num_verts):\n",
    "        verts_tuple[i] = tuple(mesh_points[i, :])\n",
    "        norms_tuple[i] = tuple(normals[i, :])\n",
    "\n",
    "    faces_building = []\n",
    "    for i in range(0, num_faces):\n",
    "        faces_building.append(((faces[i, :].tolist(),)))\n",
    "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
    "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
    "    el_norms = plyfile.PlyElement.describe(norms_tuple, \"normals\")\n",
    "\n",
    "    ply_data = plyfile.PlyData([el_verts, el_faces, el_norms])\n",
    "    return ply_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_shape_deepSDF(decoder, latent, ref_latent, initial_points=None, num_points=None, \n",
    "                           num_iters=100, point_iters=100,  punch_lr_at_reindex_by=1, num_neignours_constr=10,\n",
    "                           reindex_latent_each=50, reindex_num_iterations=500, reindex_num_samples=100,\n",
    "                           lr=0.2, decreased_by=2, adjust_lr_every=10, alpha_penalty=0.05,\n",
    "                           multiplier_func=method4_to_arbitatry_loss, verbose=None, save_to_dir=None, N=256):\n",
    "\n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every)) \\\n",
    "                        * ((punch_lr_at_reindex_by) ** (num_iterations // reindex_latent_each))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "    \n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "\n",
    "    decoder.eval()\n",
    "    latent = latent.clone()\n",
    "    latent.requires_grad = True\n",
    "    optimizer = torch.optim.SGD([latent], lr=lr)\n",
    "\n",
    "    loss_plot = []\n",
    "    latent_dist = []\n",
    "    lr_plot = []\n",
    "\n",
    "    if initial_points is not None:\n",
    "        points = initial_points.clone()\n",
    "    else:\n",
    "        points = get_points_from_latent(decoder, latent, N=N, point_num=num_points)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        time_start = time.time()\n",
    "\n",
    "        save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "        preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "#             if i > 0 and i == reindex_latent_each:\n",
    "#                 new_latent = get_latent_from_mesh(decoder, latent_size=latent.size()[1], \n",
    "#                                                   num_iterations=reindex_num_iterations, \n",
    "#                                                   num_samples=reindex_num_samples)\n",
    "#                 latent = torch.Tensor(new_latent.cpu().detach().numpy()).cuda()\n",
    "#                 latent.requires_grad = True\n",
    "#                 optimizer = torch.optim.Adam([latent], lr=lr)\n",
    "\n",
    "        cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ply_mesh = create_mesh( decoder,\n",
    "                                    latent,\n",
    "                                    N=N,\n",
    "                                    max_batch=int(2 ** 18),\n",
    "                                    offset=None,\n",
    "                                    scale=None)\n",
    "\n",
    "        points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                                    ply_mesh['vertex']['y'][:, None], \n",
    "                                                    ply_mesh['vertex']['z'][:, None])))\n",
    "\n",
    "        points.requires_grad = True\n",
    "\n",
    "        sdf_value = deep_sdf.utils.decode_sdf(decoder, latent, points)\n",
    "        ## ???\n",
    "        sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda())\n",
    "\n",
    "        mults, loss_value, preds, transformed_mesh = multiplier_func(points, ply_mesh)         \n",
    "        multipliers = torch.cuda.FloatTensor(mults)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sdf_value = torch.squeeze(deep_sdf.utils.decode_sdf(decoder, latent, points))\n",
    "\n",
    "        final_loss = torch.sum(sdf_value * multipliers)\n",
    "        final_loss.backward()\n",
    "#             print( \"Latent size: \", torch.sum(latent ** 2) )\n",
    "#             print( \"Latent grad: \", torch.sum(latent.grad ** 2) )\n",
    "\n",
    "#           sdf_value.backward(multipliers)\n",
    "\n",
    "\n",
    "        # Soft-constraints\n",
    "        distances, indeces = LATENT_KD_TREE.query(latent.cpu().detach(), k=num_neignours_constr)\n",
    "        penalty = torch.mean(\n",
    "                    torch.stack([torch.sum( \n",
    "                                    (latent - latent_vectors[indeces[0][i]]) ** 2\n",
    "                                 )\n",
    "                                 for i in range(len(indeces[0]))]\n",
    "                               )\n",
    "                    )\n",
    "        apenalty = penalty * alpha_penalty\n",
    "        apenalty.backward()\n",
    "        #print(\"Latent grad penalized: \", torch.sum(latent.grad ** 2))\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Hard-constraints\n",
    "#             if (torch.sum(latent ** 2) > 1.2):\n",
    "#                 latent *= 1.2 / torch.sum(latent ** 2)\n",
    "\n",
    "#             loss_value, preds = loss_func(points, ply_mesh)            \n",
    "\n",
    "        tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, preds)\n",
    "        tri_mesh.export(save_path)\n",
    "        np.save(preds_save_path, preds.cpu().detach().numpy())\n",
    "\n",
    "        if save_to_dir is not None:\n",
    "            plot_points_from_torch\n",
    "\n",
    "        loss_plot.append(loss_value.cpu().detach().numpy())\n",
    "        latent_dist.append(torch.sum((latent - ref_latent) ** 2 ).cpu().detach().numpy() )\n",
    "        lr_plot.append(penalty)\n",
    "\n",
    "        time_end = time.time()\n",
    "\n",
    "        if verbose is not None and i % verbose == 0:\n",
    "            print('Iter ', i, 'Loss: ', loss_value.detach().cpu().numpy(), ' LD: ', lr_plot[-1])\n",
    "\n",
    "        np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), loss_plot)\n",
    "        np.save(os.path.join(save_to_dir, \"latent_dist.npy\"), latent_dist)\n",
    "        np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
    "        np.save(os.path.join(save_to_dir, \"latent%d.npy\" % i), latent.cpu().detach().numpy())\n",
    "\n",
    "def get_trimesh_from_torch_geo_with_colors(mesh, preds, vmin=-8, vmax=8):\n",
    "    norm = mpl.colors.Normalize(vmin= vmin, vmax=vmax)\n",
    "    cmap = cm.hot\n",
    "    m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    \n",
    "    verticies = mesh.x.cpu().detach()\n",
    "    faces = mesh.face.t().cpu().detach()\n",
    "    return trimesh.Trimesh(vertices=verticies, faces=faces, \n",
    "                           vertex_colors=list(map(lambda c: m.to_rgba(c),  preds[:, 0].cpu().detach())))\n",
    "    \n",
    "    \n",
    "    \n",
    "def method4_to_arbitatry_loss(points, ply_mesh, model, constraint_rad=0.1, axis=0):\n",
    "\n",
    "    initial_dir = points.grad.clone()\n",
    "    points.grad.data.zero_()\n",
    "\n",
    "    mesh = make_mesh_from_points(points, ply_mesh)\n",
    "    #signs = compute_signs_for_loss(mesh, transformPoints(normals, AvgTransform))\n",
    "    local_preds = model(mesh)\n",
    "    loss = calculate_loss(mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
    "    loss.backward()\n",
    "\n",
    "    sign = [-p1.dot(p2) for p1, p2 in zip(initial_dir, points.grad)]\n",
    "    \n",
    "    return sign, loss, local_preds, mesh\n",
    "\n",
    "def make_full_transformation(initial_latent, ref_latent, experiment_name, \n",
    "                             decoder, model, alpha_penalty=0.05, constraint_rad=0.1, axis=0, **kwargs):\n",
    "    '''\n",
    "    kwargs:\n",
    "        num_iters=1000, \n",
    "        adjust_lr_every=10, \n",
    "        decreased_by=1.2,\n",
    "        lr=0.005,\n",
    "        \n",
    "        reindex_latent_each=100,\n",
    "        punch_lr_at_reindex_by=1,\n",
    "        reindex_num_iterations=500, \n",
    "        reindex_num_samples=100,\n",
    "        \n",
    "        verbose=10,\n",
    "    '''\n",
    "\n",
    "    #ref_points = get_points_from_latent(decoder, ref_latent, N=128)\n",
    "\n",
    "    save_to_dir = experiment_name\n",
    "    if not os.path.exists(save_to_dir):\n",
    "        os.makedirs(save_to_dir)\n",
    "\n",
    "    #np.save(os.path.join(save_to_dir, \"target_verts.npy\"), ref_points)\n",
    "\n",
    "    optimize_shape_deepSDF(decoder, initial_latent, ref_latent, initial_points=None,\n",
    "                                           alpha_penalty=alpha_penalty,\n",
    "                                           num_points=None, point_iters=2,\n",
    "                                           multiplier_func=lambda x, y: \n",
    "                                               method4_to_arbitatry_loss(x, y, model, \n",
    "                                                                         constraint_rad=constraint_rad, \n",
    "                                                                         axis=axis),\n",
    "                                           save_to_dir=save_to_dir, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SplineBlock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a21ffcb5f2d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# modelOld = modelOld.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplineCNN8Residuals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cvlabdata2/home/artem/DeepSDF/Expirements/Networks15/normilized_full_latest.nn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-a21ffcb5f2d2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_features, kernel, dim)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSplineCNN8Residuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplineBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplineBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplineBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SplineBlock' is not defined"
     ]
    }
   ],
   "source": [
    "class SplineBlock(nn.Module):\n",
    "    def __init__(self, num_in_features, num_outp_features, mid_features, kernel=3, dim=3, batchnorm1=True):\n",
    "        super(SplineBlock, self).__init__()\n",
    "        self.batchnorm1 = batchnorm1\n",
    "        self.conv1 = SplineConv(num_in_features, mid_features, dim, kernel, is_open_spline=False)\n",
    "        if self.batchnorm1:\n",
    "            self.batchnorm1 = torch.nn.BatchNorm1d(mid_features)\n",
    "        self.conv2 = SplineConv(mid_features, 2 * mid_features, dim, kernel, is_open_spline=False)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(2 * mid_features)\n",
    "        self.conv3 = SplineConv(2 * mid_features + 3, num_outp_features, dim, kernel, is_open_spline=False)\n",
    "  \n",
    "    def forward(self, res, data):\n",
    "        if self.batchnorm1:\n",
    "            res = F.elu(self.batchnorm1(self.conv1(res, data.edge_index, data.edge_attr)))\n",
    "        else:\n",
    "            res = F.elu(self.conv1(res, data.edge_index, data.edge_attr))\n",
    "        res = F.elu(self.batchnorm2(self.conv2(res, data.edge_index, data.edge_attr)))\n",
    "#         res = F.elu(self.conv2(res, data.edge_index, data.edge_attr))\n",
    "        res = torch.cat([res, data.pos], dim=1)\n",
    "        res = self.conv3(res, data.edge_index, data.edge_attr)\n",
    "        return res\n",
    "\n",
    "class SplineCNN8Residuals(nn.Module):\n",
    "    def __init__(self, num_features, kernel=3, dim=3):\n",
    "        super(SplineCNN8Residuals, self).__init__()\n",
    "        self.block1 = SplineBlock(num_features, 16, 8, kernel, dim)\n",
    "        self.block2 = SplineBlock(16, 64, 32, kernel, dim)\n",
    "        self.block3 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block4 = SplineBlock(64, 8, 16, kernel, dim)\n",
    "        self.block5 = SplineBlock(11, 32, 16, kernel, dim)\n",
    "        self.block6 = SplineBlock(32, 64, 32, kernel, dim)\n",
    "        self.block7 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block8 = SplineBlock(75, 4, 16, kernel, dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        res = data.x\n",
    "        res = self.block1(res, data)\n",
    "        res = self.block2(res, data)\n",
    "        res = self.block3(res, data)\n",
    "        res4 = self.block4(res, data)\n",
    "        res = torch.cat([res4, data.x], dim=1)\n",
    "        res = self.block5(res, data)\n",
    "        res = self.block6(res, data)\n",
    "        res = self.block7(res, data)\n",
    "        res = torch.cat([res, res4, data.x], dim=1)\n",
    "        res = self.block8(res, data)\n",
    "        return res\n",
    "    \n",
    "# data_instance= make_data_instance_from_stl(\n",
    "#                '/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/outputs/fld/0003_0015.fld') # /cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0002_0005.fld\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# modelOld = SplineCNN8(3, batchnorm1=False)\n",
    "# modelOld.load_state_dict(torch.load(\"Expirements/SplineCNN8.nn\"))\n",
    "# modelOld = modelOld.to(device)\n",
    "\n",
    "model = SplineCNN8Residuals(3)\n",
    "model.load_state_dict(torch.load(\"/cvlabdata2/home/artem/DeepSDF/Expirements/Networks15/normilized_full_latest.nn\"))\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundsLoss(points, box=[(-1, 1, 0)]):\n",
    "    loss = 0\n",
    "    for l, r, i in box:\n",
    "        loss +=  torch.mean(F.relu(-points[:, i] + l))  \\\n",
    "               + torch.mean(F.relu( points[:, i] - r))\n",
    "    return loss\n",
    "\n",
    "def innerBoundsLoss(points, r=1, center=(0, 0, 0)):\n",
    "    radiuses = torch.sum( (points - torch.Tensor(center).to('cuda:0')) ** 2 , dim=1)\n",
    "    return torch.sum(F.relu(r - radiuses))\n",
    "\n",
    "def calculate_loss(mesh, local_preds, axis=0, constraint_rad=0.1):\n",
    "    loss =  (1 - axis) * compute_lift_faces_diff(mesh, local_preds, axis=0) + \\\n",
    "                  axis * compute_lift_faces_diff(mesh, local_preds, axis=1)\n",
    "    \n",
    "    loss += boundsLoss(mesh.x, box=[(-0.6, 0.6, 0)])\n",
    "    loss += innerBoundsLoss(mesh.x, r=constraint_rad**2, center=(-0.05, 0.05, 0))  \\\n",
    "          + innerBoundsLoss(mesh.x, r=(constraint_rad / 2)**2, center=(0.3, 0, 0))\n",
    "    \n",
    "\n",
    "    return loss\n",
    "\n",
    "def compute_lift_faces_diff(data_instance, answers, axis=0):\n",
    "    pressures = torch.mean(answers[data_instance.face, 0], axis=0)\n",
    "\n",
    "    # TODO: cahnge to x if needed\n",
    "    pos = data_instance.x\n",
    "    cross_prod = (pos[data_instance.face[1]] - pos[data_instance.face[0]]).cross(\n",
    "                  pos[data_instance.face[2]] - pos[data_instance.face[0]])\n",
    "    mult = -cross_prod[:, axis] / 2\n",
    "    lift = torch.mul(pressures, mult)\n",
    "    return torch.sum(lift[~torch.isnan(lift)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sdf(decoder, latent_vector, queries):\n",
    "    num_samples = queries.shape[0]\n",
    "\n",
    "    if latent_vector is None:\n",
    "        inputs = queries\n",
    "    else:\n",
    "        latent_repeat = latent_vector.expand(num_samples, -1)\n",
    "        inputs = torch.cat([latent_repeat, queries], 1)\n",
    "\n",
    "    sdf = decoder(inputs)\n",
    "\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.21317743e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -3.77357735e-02],\n",
       "       [ 0.00000000e+00,  5.21317743e-01,  0.00000000e+00,\n",
       "         2.32778265e-02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00, -5.21317743e-01,\n",
       "         3.08673156e-04],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.load(\"/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/transforms/10.npy\")\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3186e-01,  0.0000e+00,  0.0000e+00, -4.8923e-02],\n",
       "        [ 0.0000e+00,  5.3186e-01,  0.0000e+00,  1.7534e-02],\n",
       "        [ 0.0000e+00,  0.0000e+00, -5.3186e-01, -3.4937e-05],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(AvgTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAvgTransform():\n",
    "    objects = list()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(\"/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/transforms/\"):\n",
    "        objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.npy']\n",
    "    \n",
    "    matricies = []\n",
    "    for obj in objects:\n",
    "        matricies.append(np.load(obj))\n",
    "    \n",
    "    return np.mean(np.array(matricies), axis=0)\n",
    "\n",
    "AvgTransform = computeAvgTransform()\n",
    "\n",
    "def transformPoints(points, matrix):\n",
    "    matrix = torch.cuda.FloatTensor(matrix)\n",
    "    column = torch.zeros((len(points), 1), device=\"cuda:0\") + 1\n",
    "    stacked = torch.cat([points, column], dim=1)\n",
    "    transformed = torch.matmul(matrix, stacked.T).T[:, :3]\n",
    "    return transformed\n",
    "\n",
    "def make_mesh_from_points(points, ply_mesh):\n",
    "    transformed_points = transformPoints(points, AvgTransform)\n",
    "    \n",
    "    edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
    "    np_points = transformed_points.cpu().detach().numpy()\n",
    "    edge_attr = [np_points[a] - np_points[b] for a, b in edges]\n",
    "\n",
    "    data = torch_geometric.data.Data(x   = transformed_points, \n",
    "                                     pos = transformed_points, \n",
    "                                     face = torch.tensor(ply_mesh['face']['vertex_indices'], \n",
    "                                                         dtype=torch.long).to('cuda:0').t(),\n",
    "                                     edge_attr=torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "                                     edge_index=torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0'))\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
