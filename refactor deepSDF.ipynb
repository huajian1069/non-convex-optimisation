{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright 2004-present Facebook. All Rights Reserved.\n",
    "#  python optim.py -s example1/synth_test.json -e example1\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import deep_sdf\n",
    "import deep_sdf.workspace as ws\n",
    "\n",
    "import pdb\n",
    "\n",
    "from library.optimiser import *\n",
    "from library.objective_function import *\n",
    "from library.post_analysis import *\n",
    "from library.experiments import *\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every):\n",
    "    lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "def chamfer_distance(p1, p2):\n",
    "    '''\n",
    "    Calculate Chamfer Distance between two point sets\n",
    "    '''\n",
    "    p1 = p1.unsqueeze(0)\n",
    "    p2 = p2.unsqueeze(0)\n",
    "\n",
    "    p1 = p1.repeat(p2.size(1), 1, 1)\n",
    "    p1 = p1.transpose(0, 1)\n",
    "\n",
    "    p2 = p2.repeat(p1.size(0), 1, 1)\n",
    "\n",
    "    # compute distance tensor\n",
    "    dist = torch.add(p1, torch.neg(p2))\n",
    "    dist = torch.norm(dist, 2, dim=2)\n",
    "\n",
    "    dist1, _ = torch.min(dist, dim = 1)\n",
    "    dist2, _ = torch.min(dist, dim = 0)\n",
    "\n",
    "    return torch.mean(dist1) + torch.mean(dist2)\n",
    "\n",
    "class argms:\n",
    "    def __init__(self):\n",
    "        self.experiment_directory = \"example1\"\n",
    "        self.checkpoint = \"latest\"\n",
    "        self.iterations = 100\n",
    "        self.split_filename = \"example1/synth_test.json\"\n",
    "        self.logfile = None\n",
    "        self.debug = False\n",
    "        self.quiet = False\n",
    "args = argms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLatentSourceAndTarget(args, source_id, target_id):\n",
    "    # pick initialization and samples\n",
    "    # Load collection of all latent codes\n",
    "    all_codes_path = os.path.join(\n",
    "        args.experiment_directory,\n",
    "        ws.latent_codes_subdir,\n",
    "        'latest.pth')\n",
    "    all_codes = torch.load(all_codes_path)['latent_codes']['weight']\n",
    "    ## sphere\n",
    "    source_id = 999 # zywvjkvz2492e6xpq4hd1jzy2r9lht        # This will be the source shape (ie starting point)\n",
    "    latent = all_codes[source_id].unsqueeze(0).detach()#.cuda()   #Add .cuda() if you want to run on GPU\n",
    "    latent.requires_grad = True\n",
    "\n",
    "    # This is be the target shape (ie objective)\n",
    "    latent_target = all_codes[target_id].unsqueeze(0).detach()#.cuda()   #Add .cuda() if you want to run on GPU\n",
    "    return latent, latent_target\n",
    "\n",
    "def constructDecoder(args):\n",
    "    specs_filename = os.path.join(args.experiment_directory, \"specs.json\")\n",
    "    specs = json.load(open(specs_filename))\n",
    "    arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
    "    latent_size = specs[\"CodeLength\"]\n",
    "    # Load decoder: this is our black box function\n",
    "    decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "    decoder = torch.nn.DataParallel(decoder)\n",
    "    saved_model_state = torch.load(\n",
    "        os.path.join(\n",
    "            args.experiment_directory, ws.model_params_subdir, args.checkpoint + \".pth\"\n",
    "        ),\n",
    "        map_location=torch.device('cpu') # Remove this if you want to run on GPU\n",
    "    )\n",
    "    decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "    # Optionally: put decoder on GPU\n",
    "    #decoder = decoder.module.cuda()\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization:\n",
      "latent:  [[-0.34123307 -0.47586045 -0.15240912  0.02312643  0.14862083  0.3323207\n",
      "  -0.16005228 -0.12385195]]\n",
      "loss:  0.48616672\n",
      "latent grad:  [[-0.16347873 -0.13352345 -0.05753815  0.12673719  0.07140758  0.231334\n",
      "  -0.00291534 -0.07419916]]\n",
      "0 \n",
      "\n",
      "latent:  [[-0.3332331  -0.46786046 -0.14440912  0.01512643  0.14062083  0.3243207\n",
      "  -0.15205231 -0.11585195]]\n",
      "loss:  0.4712739\n",
      "latent grad:  [[-0.16055946 -0.13089393 -0.05674174  0.12418597  0.06993486  0.22692889\n",
      "  -0.00313168 -0.0727852 ]]\n",
      "1 \n",
      "\n",
      "latent:  [[-0.32523718 -0.459865   -0.13641222  0.00713108  0.13262561  0.31632507\n",
      "  -0.14404254 -0.10785633]]\n",
      "loss:  0.45521456\n",
      "latent grad:  [[-0.16372962 -0.1332162  -0.05807362  0.12634198  0.0711408   0.23114052\n",
      "  -0.00341371 -0.0741118 ]]\n",
      "2 \n",
      "\n",
      "latent:  [[-0.3172369  -0.4518658  -0.12840982 -0.00086791  0.1246268   0.30832544\n",
      "  -0.13601536 -0.09985678]]\n",
      "loss:  0.44181013\n",
      "latent grad:  [[-0.15954404 -0.12969825 -0.05668935  0.12298922  0.06929438  0.22518212\n",
      "  -0.0033709  -0.07218114]]\n",
      "3 \n",
      "\n",
      "latent:  [[-0.30924305 -0.44387367 -0.12041256 -0.00885967  0.11663505  0.30033255\n",
      "  -0.12797844 -0.09186413]]\n",
      "loss:  0.4257057\n",
      "latent grad:  [[-0.1627348  -0.13291171 -0.05794172  0.1253407   0.06924608  0.22930622\n",
      "  -0.00672321 -0.07401119]]\n",
      "4 \n",
      "\n",
      "latent:  [[-0.30124578 -0.43587685 -0.11241058 -0.01685418  0.1086475   0.29233694\n",
      "  -0.12013092 -0.08386645]]\n",
      "loss:  0.41151524\n",
      "latent grad:  [[-0.16512173 -0.13405496 -0.06041944  0.12558335  0.06758847  0.23092216\n",
      "  -0.01257165 -0.07499799]]\n",
      "5 \n",
      "\n",
      "latent:  [[-0.29324102 -0.42787385 -0.10439122 -0.02485122  0.10067207  0.28433698\n",
      "  -0.11275175 -0.0758608 ]]\n",
      "loss:  0.39883703\n",
      "latent grad:  [[-0.17730257 -0.1435806  -0.06573831  0.13398221  0.07105795  0.24706103\n",
      "  -0.01688731 -0.08056108]]\n",
      "6 \n",
      "\n",
      "latent:  [[-0.2852065  -0.41984257 -0.09633324 -0.03287335  0.09268495  0.27631003\n",
      "  -0.10540172 -0.06782497]]\n",
      "loss:  0.38413495\n",
      "latent grad:  [[-0.1825192  -0.14855438 -0.06643268  0.13914974  0.07495185  0.25564492\n",
      "  -0.01364845 -0.08304451]]\n",
      "7 \n",
      "\n",
      "latent:  [[-0.2771407  -0.41177934 -0.08824379 -0.04092669  0.08466933  0.2682519\n",
      "  -0.09780549 -0.05975718]]\n",
      "loss:  0.37082678\n",
      "latent grad:  [[-0.18111324 -0.14986934 -0.06175719  0.14208895  0.08005416  0.25803927\n",
      "  -0.00211298 -0.08328038]]\n",
      "8 \n",
      "\n",
      "latent:  [[-0.2690545  -0.40368932 -0.08015791 -0.04901059  0.07660888  0.26016733\n",
      "  -0.09077487 -0.05166469]]\n",
      "loss:  0.35857224\n",
      "latent grad:  [[-0.17667796 -0.1461767  -0.06002391  0.13882342  0.07871298  0.2519107\n",
      "  -0.00055742 -0.08104864]]\n",
      "9 \n",
      "\n",
      "latent:  [[-0.2609627  -0.39558864 -0.07208685 -0.05710874  0.06852064  0.2520721\n",
      "  -0.08442097 -0.04356405]]\n",
      "loss:  0.34577844\n",
      "latent grad:  [[-1.6795504e-01 -1.3900614e-01 -5.6917820e-02  1.3206863e-01\n",
      "   7.4962027e-02  2.3954514e-01 -1.8784803e-04 -7.7044800e-02]]\n",
      "10 \n",
      "\n",
      "latent:  [[-0.25288823 -0.38750097 -0.06405094 -0.06519696  0.06043089  0.24398993\n",
      "  -0.07869978 -0.03547864]]\n",
      "loss:  0.33234358\n",
      "latent grad:  [[-0.16450225 -0.13597491 -0.05579359  0.12935534  0.07373001  0.23465674\n",
      "   0.00067793 -0.07520188]]\n",
      "11 \n",
      "\n",
      "latent:  [[-0.24483706 -0.37943366 -0.05605228 -0.07326786  0.05234745  0.23592754\n",
      "  -0.07365477 -0.02741634]]\n",
      "loss:  0.3216985\n",
      "latent grad:  [[-0.1562516  -0.12909953 -0.05300558  0.12286387  0.07001541  0.22290869\n",
      "   0.00066566 -0.07146847]]\n",
      "12 \n",
      "\n",
      "latent:  [[-0.23682848 -0.3714067  -0.04810763 -0.08130112  0.04429266  0.22790477\n",
      "  -0.06920394 -0.01939622]]\n",
      "loss:  0.30964115\n",
      "latent grad:  [[-0.1514416  -0.12483461 -0.05150689  0.1189132   0.06766935  0.21584347\n",
      "   0.00076663 -0.06918889]]\n",
      "13 \n",
      "\n",
      "latent:  [[-0.2288695  -0.36342862 -0.04022076 -0.08928815  0.03627732  0.21992962\n",
      "  -0.06529538 -0.01142592]]\n",
      "loss:  0.29841566\n",
      "latent grad:  [[-0.14497276 -0.11974306 -0.04901949  0.11408399  0.06497733  0.20687604\n",
      "   0.00119812 -0.06635068]]\n",
      "14 \n",
      "\n",
      "latent:  [[-0.22097231 -0.35551077 -0.03240522 -0.09721725  0.02831388  0.21201403\n",
      "  -0.06193563 -0.00351676]]\n",
      "loss:  0.289023\n",
      "latent grad:  [[-0.13903153 -0.11462936 -0.04716935  0.10918619  0.06229237  0.198177\n",
      "   0.00114214 -0.06339695]]\n",
      "15 \n",
      "\n",
      "latent:  [[-0.21314672 -0.3476641  -0.02466757 -0.10507699  0.02041398  0.20416874\n",
      "  -0.05906037  0.00431959]]\n",
      "loss:  0.27795267\n",
      "latent grad:  [[-0.1318751  -0.10857642 -0.04484744  0.10340099  0.05915452  0.1878037\n",
      "   0.00117603 -0.0598813 ]]\n",
      "16 \n",
      "\n",
      "latent:  [[-0.20540662 -0.33990327 -0.01701946 -0.11285228  0.01259236  0.1964083\n",
      "  -0.05662709  0.01206737]]\n",
      "loss:  0.2711798\n",
      "latent grad:  [[-0.08990356 -0.07403039 -0.0304571   0.07064234  0.0407709   0.12817484\n",
      "   0.00179121 -0.04057622]]\n",
      "17 \n",
      "\n",
      "latent:  [[-0.19790863 -0.33238497 -0.00961672 -0.12038669  0.00500411  0.1888893\n",
      "  -0.05468741  0.01956839]]\n",
      "loss:  0.2649272\n",
      "latent grad:  [[-0.07865838 -0.06389535 -0.02720924  0.06126222  0.03556898  0.11171246\n",
      "   0.00203645 -0.03488924]]\n",
      "18 \n",
      "\n",
      "latent:  [[-0.1906735  -0.32513502 -0.00247131 -0.12765571 -0.00232679  0.18163416\n",
      "  -0.05323316  0.02679635]]\n",
      "loss:  0.26020348\n",
      "latent grad:  [[-0.03823377 -0.03070805 -0.01346645  0.02945097  0.01709911  0.05403444\n",
      "   0.00091268 -0.01674783]]\n",
      "19 \n",
      "\n",
      "latent:  [[-0.18387538 -0.3183277   0.00424703 -0.13448292 -0.00921748  0.1748183\n",
      "  -0.05204881  0.03357999]]\n",
      "loss:  0.26047316\n",
      "latent grad:  [[-0.02096846 -0.01680956 -0.00741985  0.01616231  0.00947595  0.02972601\n",
      "   0.00081109 -0.00919563]]\n",
      "20 \n",
      "\n",
      "latent:  [[-0.17756611 -0.31201276  0.01048528 -0.14081773 -0.0156155   0.1684928\n",
      "  -0.05109508  0.0398716 ]]\n",
      "loss:  0.25847384\n",
      "latent grad:  [[-0.01619669 -0.01301465 -0.00565552  0.0125758   0.0074175   0.02308902\n",
      "   0.00091673 -0.00714076]]\n",
      "21 \n",
      "\n",
      "latent:  [[-0.1717258  -0.3061692   0.01626091 -0.14668126 -0.02154152  0.16263707\n",
      "  -0.05036843  0.04569276]]\n",
      "loss:  0.25980735\n",
      "latent grad:  [[-0.00622702 -0.00482454 -0.00220552  0.00483771  0.00304155  0.00897782\n",
      "   0.00107701 -0.00263192]]\n",
      "22 \n",
      "\n",
      "latent:  [[-0.1663698  -0.30081236  0.02155853 -0.15205841 -0.02698016  0.15726636\n",
      "  -0.04987474  0.05102857]]\n",
      "loss:  0.2578731\n",
      "latent grad:  [[ 0.00094778  0.00104183  0.00027616 -0.00073396 -0.00013163 -0.00117184\n",
      "   0.00105217  0.0005814 ]]\n",
      "23 \n",
      "\n",
      "latent:  [[-0.16149786 -0.29594168  0.02637829 -0.15694961 -0.03193142  0.15238027\n",
      "  -0.04959083  0.05588006]]\n",
      "loss:  0.2593438\n",
      "latent grad:  [[ 0.0062464   0.00549465  0.00198794 -0.00495022 -0.00245617 -0.00879466\n",
      "   0.00111705  0.00309463]]\n",
      "24 \n",
      "\n",
      "latent:  [[-0.15709983 -0.2915477   0.03073236 -0.16136438 -0.03640557  0.14796911\n",
      "  -0.04950997  0.06025596]]\n",
      "loss:  0.25817212\n",
      "latent grad:  [[ 0.01226011  0.01047455  0.00401645 -0.00968028 -0.00508227 -0.0173775\n",
      "   0.00122172  0.00590205]]\n",
      "25 \n",
      "\n",
      "latent:  [[-0.1531725  -0.2876274   0.03462463 -0.16530563 -0.0404061   0.14402989\n",
      "  -0.04963273  0.06415859]]\n",
      "loss:  0.25886142\n",
      "latent grad:  [[ 0.02152238  0.01805247  0.00719399 -0.01691408 -0.00916455 -0.03055298\n",
      "   0.00125339  0.01015175]]\n",
      "26 \n",
      "\n",
      "latent:  [[-0.14973587 -0.2842005   0.03803553 -0.16875322 -0.04391254  0.14058277\n",
      "  -0.04994814  0.06756762]]\n",
      "loss:  0.25970918\n",
      "latent grad:  [[ 0.026138    0.02173632  0.00886088 -0.02041921 -0.01120566 -0.03700034\n",
      "   0.00119089  0.01214102]]\n",
      "27 \n",
      "\n",
      "latent:  [[-0.14677866 -0.28125462  0.04097455 -0.1717194  -0.04693605  0.1376159\n",
      "  -0.05043098  0.07049623]]\n",
      "loss:  0.26143944\n",
      "latent grad:  [[ 0.03031541  0.02498579  0.01048815 -0.02344294 -0.01293084 -0.04264173\n",
      "   0.00134747  0.01378705]]\n",
      "28 \n",
      "\n",
      "latent:  [[-0.14428826 -0.2787756   0.04345039 -0.17421885 -0.04949101  0.13511533\n",
      "  -0.05109428  0.07296093]]\n",
      "loss:  0.2609763\n",
      "latent grad:  [[ 0.03173184  0.02617146  0.01101209 -0.02449517 -0.0135179  -0.04460078\n",
      "   0.00157791  0.01441421]]\n",
      "29 \n",
      "\n",
      "latent:  [[-0.14223479 -0.27673376  0.04549205 -0.17628187 -0.05160795  0.13305095\n",
      "  -0.05196261  0.0749916 ]]\n",
      "loss:  0.26047087\n",
      "latent grad:  [[ 0.03429164  0.02808225  0.01205288 -0.02629791 -0.01462284 -0.0480089\n",
      "   0.00149663  0.01533653]]\n",
      "30 \n",
      "\n",
      "latent:  [[-0.14059913 -0.27510837  0.04711553 -0.17792921 -0.05330626  0.13140264\n",
      "  -0.05300658  0.07661082]]\n",
      "loss:  0.2600839\n",
      "latent grad:  [[ 0.03728509  0.03043881  0.01317927 -0.02850433 -0.01587949 -0.05210505\n",
      "   0.001578    0.01656858]]\n",
      "31 \n",
      "\n",
      "latent:  [[-0.1393671  -0.27388453  0.04833343 -0.17917591 -0.05460095  0.13015568\n",
      "  -0.05422674  0.07783423]]\n",
      "loss:  0.26056835\n",
      "latent grad:  [[ 0.03952663  0.03181763  0.01432637 -0.02980357 -0.01672792 -0.05471564\n",
      "   0.00141708  0.01699185]]\n",
      "32 \n",
      "\n",
      "latent:  [[-0.13852073 -0.27304056  0.04915658 -0.18004368 -0.05551203  0.12928951\n",
      "  -0.05558243  0.0786883 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.2604891\n",
      "latent grad:  [[ 0.04181341  0.03289808  0.01574708 -0.03084557 -0.0175534  -0.05701143\n",
      "   0.00098496  0.01702858]]\n",
      "33 \n",
      "\n",
      "latent:  [[-0.1380441  -0.2725542   0.04958918 -0.18055451 -0.05605801  0.12878393\n",
      "  -0.0569892   0.07920307]]\n",
      "loss:  0.26129502\n",
      "latent grad:  [[ 0.04391561  0.03400627  0.01696656 -0.03190156 -0.01830688 -0.05925058\n",
      "   0.0007372   0.01723613]]\n",
      "34 \n",
      "\n",
      "latent:  [[-0.1379215  -0.27240548  0.04963903 -0.18072821 -0.0562568   0.12862037\n",
      "  -0.05840074  0.07940324]]\n",
      "loss:  0.2614028\n",
      "latent grad:  [[ 0.04475055  0.03417282  0.01766839 -0.03207445 -0.01858371 -0.05981687\n",
      "   0.00039827  0.01694653]]\n",
      "35 \n",
      "\n",
      "latent:  [[-0.13812964 -0.2725681   0.04932372 -0.18059094 -0.0561325   0.12877353\n",
      "  -0.05975751  0.07931909]]\n",
      "loss:  0.26128995\n",
      "latent grad:  [[ 0.04466931  0.03395235  0.01773339 -0.03190605 -0.018556   -0.05956826\n",
      "   0.00020468  0.01675194]]\n",
      "36 \n",
      "\n",
      "latent:  [[-0.13864076 -0.27301472  0.04867227 -0.18016964 -0.05571203  0.12921621\n",
      "  -0.06103005  0.07897679]]\n",
      "loss:  0.2604859\n",
      "latent grad:  [[ 0.04280401  0.03296732  0.01661196 -0.03101626 -0.01790619 -0.05765328\n",
      "   0.0003575   0.01664661]]\n",
      "37 \n",
      "\n",
      "latent:  [[-0.13941672 -0.27371362  0.04773543 -0.17949565 -0.05503031  0.12991515\n",
      "  -0.06225416  0.07839879]]\n",
      "loss:  0.26037216\n",
      "latent grad:  [[ 0.04038107  0.03174972  0.01513926 -0.02987901 -0.01705914 -0.05519865\n",
      "   0.00065951  0.01656166]]\n",
      "38 \n",
      "\n",
      "latent:  [[-0.1404186  -0.27463374  0.04656678 -0.1785999  -0.05412251  0.13083713\n",
      "  -0.06349062  0.07760529]]\n",
      "loss:  0.25992697\n",
      "latent grad:  [[ 0.0380974   0.03039936  0.01392596 -0.02860163 -0.0162106  -0.05260681\n",
      "   0.00083621  0.01618192]]\n",
      "39 \n",
      "\n",
      "latent:  [[-0.14161177 -0.27574545  0.04520999 -0.17751205 -0.05302089  0.13195105\n",
      "  -0.06477246  0.07661949]]\n",
      "loss:  0.2599818\n",
      "latent grad:  [[ 0.03649392  0.02955837  0.01295721 -0.02784356 -0.01567612 -0.05096095\n",
      "   0.00091526  0.01607142]]\n",
      "40 \n",
      "\n",
      "latent:  [[-0.14296949 -0.27702627  0.0437     -0.17625432 -0.05174966  0.13323334\n",
      "  -0.06611197  0.07545824]]\n",
      "loss:  0.2605759\n",
      "latent grad:  [[ 0.03383284  0.02767007  0.01181692 -0.02604895 -0.01460802 -0.04752921\n",
      "   0.00101171  0.01519318]]\n",
      "41 \n",
      "\n",
      "latent:  [[-0.14445935 -0.27844596  0.04207256 -0.17485705 -0.0503402   0.13465296\n",
      "  -0.06752386  0.07414958]]\n",
      "loss:  0.2611903\n",
      "latent grad:  [[ 0.03184989  0.02622832  0.01096289 -0.02470832 -0.01379125 -0.04497634\n",
      "   0.00101799  0.01454973]]\n",
      "42 \n",
      "\n",
      "latent:  [[-0.14605667 -0.2799809   0.04035448 -0.17334373 -0.04881698  0.13618606\n",
      "  -0.06900457  0.07271536]]\n",
      "loss:  0.2610842\n",
      "latent grad:  [[ 0.03088798  0.02549316  0.01054506 -0.02406421 -0.0134082  -0.04374225\n",
      "   0.000914    0.01423245]]\n",
      "43 \n",
      "\n",
      "latent:  [[-0.14774644 -0.28161588  0.03856097 -0.17172912 -0.04719495  0.13781781\n",
      "  -0.07052947  0.07117018]]\n",
      "loss:  0.2612043\n",
      "latent grad:  [[ 0.02923276  0.02426385  0.00984801 -0.02293225 -0.01275613 -0.04158422\n",
      "   0.00084263  0.01365322]]\n",
      "44 \n",
      "\n",
      "latent:  [[-0.1495096  -0.28333232  0.03671222 -0.17003159 -0.04549259  0.13952954\n",
      "  -0.07208218  0.0695319 ]]\n",
      "loss:  0.260192\n",
      "latent grad:  [[ 0.02688942  0.02242879  0.0089355  -0.02124417 -0.01180242 -0.03842911\n",
      "   0.00070534  0.01273256]]\n",
      "45 \n",
      "\n",
      "latent:  [[-0.15132317 -0.28510734  0.03483161 -0.16827367 -0.0437323   0.14129858\n",
      "  -0.07363443  0.06782274]]\n",
      "loss:  0.25932205\n",
      "latent grad:  [[ 0.02427366  0.02025208  0.00804707 -0.01919753 -0.01067352 -0.03469369\n",
      "   0.0005822   0.01149525]]\n",
      "46 \n",
      "\n",
      "latent:  [[-0.15316382 -0.28691658  0.03294026 -0.16647975 -0.04193794  0.14310077\n",
      "  -0.07516281  0.06606872]]\n",
      "loss:  0.2587245\n",
      "latent grad:  [[ 0.02207385  0.0184611   0.0072756  -0.01750476 -0.0097431  -0.03158641\n",
      "   0.00049327  0.0104869 ]]\n",
      "47 \n",
      "\n",
      "latent:  [[-0.15501323 -0.2887412   0.03105513 -0.16466881 -0.04012796  0.1449173\n",
      "  -0.07665244  0.06428985]]\n",
      "loss:  0.25880215\n",
      "latent grad:  [[ 0.01927999  0.01614644  0.00631664 -0.01532248 -0.0085172  -0.02760114\n",
      "   0.00038276  0.00917452]]\n",
      "48 \n",
      "\n",
      "latent:  [[-0.15684965 -0.2905586   0.02919626 -0.16286348 -0.03832493  0.14672571\n",
      "  -0.07808503  0.06251007]]\n",
      "loss:  0.25826004\n",
      "latent grad:  [[ 0.01453016  0.01228166  0.00466027 -0.01164494 -0.00645087 -0.02087877\n",
      "   0.00031874  0.00701496]]\n",
      "49 \n",
      "\n",
      "latent:  [[-0.158637   -0.29233247  0.02739845 -0.1611004  -0.03656546  0.1484895\n",
      "  -0.07945309  0.0607667 ]]\n",
      "loss:  0.25817528\n",
      "latent grad:  [[ 0.01026493  0.0088166   0.00317665 -0.00834206 -0.00459054 -0.01485149\n",
      "   0.00029327  0.00508726]]\n",
      "50 \n",
      "\n",
      "latent:  [[-0.15977612 -0.29346615  0.02625955 -0.1599733  -0.03544164  0.14961563\n",
      "  -0.08032279  0.05964908]]\n",
      "loss:  0.25837186\n",
      "latent grad:  [[ 0.00832108  0.00719523  0.00252907 -0.00680233 -0.00373788 -0.012056\n",
      "   0.00023578  0.00415287]]\n",
      "51 \n",
      "\n",
      "latent:  [[-0.16085722 -0.2945449   0.02518474 -0.1589006  -0.03437293  0.15068606\n",
      "  -0.08114622  0.05858294]]\n",
      "loss:  0.25868776\n",
      "latent grad:  [[ 0.00700294  0.00606427  0.00212247 -0.00572391 -0.00315334 -0.010116\n",
      "   0.00019544  0.00347472]]\n",
      "52 \n",
      "\n",
      "latent:  [[-0.16187853 -0.29556632  0.02417439 -0.1578848  -0.03336147  0.15169851\n",
      "  -0.08192207  0.05757157]]\n",
      "loss:  0.25910547\n",
      "latent grad:  [[ 0.00656067  0.00562667  0.00204327 -0.00530394 -0.0029618  -0.00939348\n",
      "   0.00013796  0.00316314]]\n",
      "53 \n",
      "\n",
      "latent:  [[-0.16284327 -0.29653293  0.02322371 -0.15692349 -0.03240427  0.15265568\n",
      "  -0.08264662  0.05661356]]\n",
      "loss:  0.25900382\n",
      "latent grad:  [[ 5.5917068e-03  4.7769770e-03  1.7530633e-03 -4.5008627e-03\n",
      "  -2.5241009e-03 -7.9519060e-03  9.2272669e-05  2.6465179e-03]]\n",
      "54 \n",
      "\n",
      "latent:  [[-0.16375135 -0.29744408  0.02233175 -0.1560173  -0.03150184  0.15355703\n",
      "  -0.08331804  0.05571025]]\n",
      "loss:  0.2587988\n",
      "latent grad:  [[ 4.7206921e-03  4.0589743e-03  1.4612648e-03 -3.8170095e-03\n",
      "  -2.1363855e-03 -6.7087803e-03  9.7972290e-05  2.2460497e-03]]\n",
      "55 \n",
      "\n",
      "latent:  [[-0.16460313 -0.2983      0.02149775 -0.15516609 -0.03065409  0.15440284\n",
      "  -0.08394209  0.0548615 ]]\n",
      "loss:  0.25823742\n",
      "latent grad:  [[ 3.3786371e-03  2.9247529e-03  1.0351418e-03 -2.7346520e-03\n",
      "  -1.5350205e-03 -4.7522150e-03  8.5884472e-05  1.5837552e-03]]\n",
      "56 \n",
      "\n",
      "latent:  [[-0.16539614 -0.29909787  0.02072334 -0.15437274 -0.02986386  0.15519032\n",
      "  -0.08452138  0.0540706 ]]\n",
      "loss:  0.25766197\n",
      "latent grad:  [[ 0.00211522  0.00188878  0.00061836 -0.00173373 -0.00096046 -0.00293634\n",
      "   0.00013527  0.00100407]]\n",
      "57 \n",
      "\n",
      "latent:  [[-0.16612847 -0.29983574  0.02000995 -0.15363938 -0.0291335   0.1559174\n",
      "  -0.08506742  0.05333962]]\n",
      "loss:  0.25769484\n",
      "latent grad:  [[ 0.00198309  0.00182372  0.0005443  -0.00166538 -0.00090453 -0.00279775\n",
      "   0.00018194  0.00100735]]\n",
      "58 \n",
      "\n",
      "latent:  [[-0.16680497 -0.3005187   0.01935317 -0.15296099 -0.02845823  0.1565891\n",
      "  -0.08559041  0.05266296]]\n",
      "loss:  0.2578605\n",
      "latent grad:  [[ 0.00115408  0.00117527  0.00024314 -0.00103955 -0.00052389 -0.0016525\n",
      "   0.00024695  0.00068995]]\n",
      "59 \n",
      "\n",
      "latent:  [[-0.16742586 -0.30114713  0.01875292 -0.15233725 -0.02783815  0.15720573\n",
      "  -0.08610246  0.05203974]]\n",
      "loss:  0.25775984\n",
      "latent grad:  [[ 4.0570067e-04  5.7844073e-04 -2.7846385e-05 -4.7223788e-04\n",
      "  -1.9268869e-04 -6.1197951e-04  2.5836931e-04  3.8009865e-04]]\n",
      "60 \n",
      "\n",
      "latent:  [[-0.16799177 -0.30172172  0.01820865 -0.15176754 -0.02727274  0.15776794\n",
      "  -0.0866066   0.05146911]]\n",
      "loss:  0.2581426\n",
      "latent grad:  [[-6.0804159e-06  2.6634143e-04 -1.8862532e-04 -1.6962615e-04\n",
      "  -9.4706093e-06 -5.3328473e-05  2.8069393e-04  2.2348891e-04]]\n",
      "61 \n",
      "\n",
      "latent:  [[-0.16850527 -0.30224508  0.01771803 -0.15124923 -0.02675954  0.15827833\n",
      "  -0.08710725  0.05094833]]\n",
      "loss:  0.25807193\n",
      "latent grad:  [[-0.00106955 -0.00060974 -0.00053845  0.00067369  0.00046684  0.00146924\n",
      "   0.00030658 -0.00026212]]\n",
      "62 \n",
      "\n",
      "latent:  [[-0.16896464 -0.3027154   0.01728226 -0.15078427 -0.02630046  0.15873508\n",
      "  -0.08760905  0.05047934]]\n",
      "loss:  0.2582899\n",
      "latent grad:  [[-0.00130483 -0.00077799 -0.00063011  0.00084132  0.00057309  0.00178103\n",
      "   0.00034042 -0.00033447]]\n",
      "63 \n",
      "\n",
      "latent:  [[-0.16937336 -0.30313623  0.01689801 -0.15036912 -0.02589208  0.1591417\n",
      "  -0.0881175   0.05005839]]\n",
      "loss:  0.25855434\n",
      "latent grad:  [[-0.00227242 -0.00154715 -0.00097773  0.00158037  0.00099105  0.00313305\n",
      "   0.00035501 -0.0007489 ]]\n",
      "64 \n",
      "\n",
      "latent:  [[-0.16973002 -0.30350626  0.01656676 -0.15000518 -0.02553577  0.15949681\n",
      "  -0.08863464  0.04968678]]\n",
      "loss:  0.2588453\n",
      "latent grad:  [[-0.00289494 -0.00204815 -0.00119427  0.00206224  0.00126654  0.00401032\n",
      "   0.00037289 -0.00102373]]\n",
      "65 \n",
      "\n",
      "latent:  [[-0.1700354  -0.3038262   0.01628765 -0.14969172 -0.02523081  0.15980117\n",
      "  -0.08916289  0.04936382]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.25898927\n",
      "latent grad:  [[-0.00331099 -0.0023856  -0.00133724  0.00238602  0.00145611  0.00460019\n",
      "   0.00039158 -0.00120755]]\n",
      "66 \n",
      "\n",
      "latent:  [[-0.17029151 -0.30409804  0.01605857 -0.14942682 -0.02497533  0.1600567\n",
      "  -0.08970461  0.04908768]]\n",
      "loss:  0.2591815\n",
      "latent grad:  [[-0.00362268 -0.00264025 -0.00144263  0.00263042  0.0015936   0.00504354\n",
      "   0.00039645 -0.00134934]]\n",
      "67 \n",
      "\n",
      "latent:  [[-0.17050076 -0.30432406  0.01587699 -0.14920814 -0.02476692  0.16026577\n",
      "  -0.09025974  0.04885614]]\n",
      "loss:  0.25936636\n",
      "latent grad:  [[-0.00399709 -0.0029519  -0.00156489  0.00293009  0.00175757  0.00558337\n",
      "   0.00039555 -0.00153084]]\n",
      "68 \n",
      "\n",
      "latent:  [[-0.1706649  -0.30450594  0.01574094 -0.14903404 -0.0246038   0.1604301\n",
      "  -0.0908273   0.04866777]]\n",
      "loss:  0.25963962\n",
      "latent grad:  [[-0.00408676 -0.00303441 -0.00158834  0.00300935  0.00180249  0.00572037\n",
      "   0.00040031 -0.00157888]]\n",
      "69 \n",
      "\n",
      "latent:  [[-0.1707874  -0.30464697  0.01564681 -0.1489012  -0.02448262  0.16055302\n",
      "  -0.09140734  0.04851939]]\n",
      "loss:  0.2596513\n",
      "latent grad:  [[-0.00438607 -0.00328079 -0.00169507  0.00324235  0.00194717  0.00613932\n",
      "   0.00042358 -0.00170081]]\n",
      "70 \n",
      "\n",
      "latent:  [[-0.17086996 -0.3047488   0.0155929  -0.14880791 -0.02440183  0.16063628\n",
      "  -0.09200293  0.04840919]]\n",
      "loss:  0.25974092\n",
      "latent grad:  [[-0.00461059 -0.0034717  -0.00176709  0.00342688  0.00206272  0.00646538\n",
      "   0.00045132 -0.00179949]]\n",
      "71 \n",
      "\n",
      "latent:  [[-0.17091466 -0.3048134   0.01557702 -0.14875226 -0.02435961  0.16068186\n",
      "  -0.09261766  0.04833522]]\n",
      "loss:  0.25974655\n",
      "latent grad:  [[-0.00460976 -0.00348741 -0.00175362  0.00344254  0.00207086  0.00648325\n",
      "   0.0004534  -0.00181596]]\n",
      "72 \n",
      "\n",
      "latent:  [[-0.17092483 -0.30484393  0.01559559 -0.14873104 -0.0243527   0.16069299\n",
      "  -0.09325056  0.04829452]]\n",
      "loss:  0.25974807\n",
      "latent grad:  [[-0.00453735 -0.00343499 -0.00172331  0.00339278  0.00203906  0.0063877\n",
      "   0.00044905 -0.00179214]]\n",
      "73 \n",
      "\n",
      "latent:  [[-0.17090395 -0.30484378  0.01564506 -0.14874083 -0.02437752  0.16067313\n",
      "  -0.09389966  0.0482838 ]]\n",
      "loss:  0.25974607\n",
      "latent grad:  [[-0.00454259 -0.00347843 -0.00169331  0.00343289  0.00205005  0.00643838\n",
      "   0.00043238 -0.00184028]]\n",
      "74 \n",
      "\n",
      "latent:  [[-0.1708547  -0.30481526  0.01572216 -0.14877926 -0.02443149  0.16062474\n",
      "  -0.09456109  0.04830116]]\n",
      "loss:  0.2597406\n",
      "latent grad:  [[-0.00450926 -0.00344965 -0.00168322  0.00340497  0.00203549  0.00638593\n",
      "   0.00043789 -0.00181887]]\n",
      "75 \n",
      "\n",
      "latent:  [[-0.17077976 -0.3047611   0.01582434 -0.1488436  -0.02451185  0.16055053\n",
      "  -0.09523506  0.04834382]]\n",
      "loss:  0.25965232\n",
      "latent grad:  [[-0.00431373 -0.00329358 -0.00162083  0.00325161  0.00195892  0.00610757\n",
      "   0.00043585 -0.00172603]]\n",
      "76 \n",
      "\n",
      "latent:  [[-0.17068267 -0.30468482  0.01594824 -0.1489303  -0.02461516  0.16045408\n",
      "  -0.09592052  0.04840821]]\n",
      "loss:  0.25964382\n",
      "latent grad:  [[-0.0040675  -0.00309339 -0.00153838  0.00305947  0.00185638  0.00575604\n",
      "   0.0004439  -0.00160812]]\n",
      "77 \n",
      "\n",
      "latent:  [[-0.17056698 -0.30458996  0.01609042 -0.14903572 -0.02473783  0.16033897\n",
      "  -0.09661819  0.04849068]]\n",
      "loss:  0.25937706\n",
      "latent grad:  [[-0.00391903 -0.00298021 -0.00148517  0.00294921  0.00180048  0.0055499\n",
      "   0.00045113 -0.00154132]]\n",
      "78 \n",
      "\n",
      "latent:  [[-0.1704353  -0.30447906  0.01624831 -0.14915732 -0.02487737  0.16020776\n",
      "  -0.09732863  0.04858867]]\n",
      "loss:  0.25936309\n",
      "latent grad:  [[-0.00395477 -0.00292877 -0.00156079  0.00290481  0.00179757  0.00550465\n",
      "   0.00050485 -0.00145298]]\n",
      "79 \n",
      "\n",
      "latent:  [[-0.17028871 -0.30435392  0.01642209 -0.14929333 -0.02503229  0.16006204\n",
      "  -0.09806047  0.04869954]]\n",
      "loss:  0.25926507\n",
      "latent grad:  [[-0.00379542 -0.00268902 -0.0015894   0.00268228  0.00169955  0.00514891\n",
      "   0.000575   -0.0012423 ]]\n",
      "80 \n",
      "\n",
      "latent:  [[-0.17012957 -0.30421776  0.01661104 -0.14944057 -0.02519978  0.15990476\n",
      "  -0.09882452  0.04881898]]\n",
      "loss:  0.25908676\n",
      "latent grad:  [[-0.00368488 -0.00258213 -0.00156572  0.00258334  0.00165776  0.00497632\n",
      "   0.00060287 -0.0011679 ]]\n",
      "81 \n",
      "\n",
      "latent:  [[-0.16995966 -0.30407238  0.01681342 -0.14959723 -0.02537812  0.1597377\n",
      "  -0.09962322  0.04894515]]\n",
      "loss:  0.2589877\n",
      "latent grad:  [[-0.00350863 -0.00240925 -0.00152853  0.00241834  0.00157223  0.00468774\n",
      "   0.00062102 -0.00104415]]\n",
      "82 \n",
      "\n",
      "latent:  [[-0.16978109 -0.30392     0.01702742 -0.14976105 -0.02556508  0.1595631\n",
      "  -0.10045712  0.0490756 ]]\n",
      "loss:  0.2588671\n",
      "latent grad:  [[-0.00325203 -0.0021129  -0.00150372  0.00214836  0.00145599  0.00422665\n",
      "   0.00071722 -0.0008101 ]]\n",
      "83 \n",
      "\n",
      "latent:  [[-0.16959636 -0.30376375  0.01725161 -0.14992903 -0.02575809  0.1593838\n",
      "  -0.10134067  0.04920637]]\n",
      "loss:  0.25883493\n",
      "latent grad:  [[-0.00295281 -0.00178736 -0.00147441  0.00183698  0.00132463  0.00369021\n",
      "   0.00079353 -0.00054139]]\n",
      "84 \n",
      "\n",
      "latent:  [[-0.16940804 -0.3036067   0.01748461 -0.15009801 -0.02595457  0.15920286\n",
      "  -0.10228357  0.04933329]]\n",
      "loss:  0.25864714\n",
      "latent grad:  [[-0.00259965 -0.00139418 -0.00143671  0.00146684  0.00114735  0.00305967\n",
      "   0.00086564 -0.00023936]]\n",
      "85 \n",
      "\n",
      "latent:  [[-0.16921888 -0.30345228  0.01772499 -0.15026459 -0.02615139  0.15902351\n",
      "  -0.10329391  0.04945199]]\n",
      "loss:  0.25854185\n",
      "latent grad:  [[-2.3827183e-03 -1.1745271e-03 -1.4018259e-03  1.2562905e-03\n",
      "   1.0548680e-03  2.6884351e-03  9.1521506e-04 -6.2184008e-05]]\n",
      "86 \n",
      "\n",
      "latent:  [[-0.16903044 -0.30330214  0.01797148 -0.15042709 -0.02634708  0.15884742\n",
      "  -0.10437508  0.04956046]]\n",
      "loss:  0.2583149\n",
      "latent grad:  [[-0.00199942 -0.00081059 -0.00131501  0.00090479  0.0008735   0.00206948\n",
      "   0.00095378  0.00019443]]\n",
      "87 \n",
      "\n",
      "latent:  [[-0.16884533 -0.30315903  0.01822188 -0.15058269 -0.02653882  0.15867738\n",
      "  -0.10552819  0.04965555]]\n",
      "loss:  0.25828487\n",
      "latent grad:  [[-0.00185113 -0.0004996  -0.0014113   0.00061618  0.00076594  0.00163004\n",
      "   0.00108579  0.00051259]]\n",
      "88 \n",
      "\n",
      "latent:  [[-0.16866423 -0.303025    0.01847796 -0.15072934 -0.02672525  0.15851504\n",
      "  -0.10677134  0.0497334 ]]\n",
      "loss:  0.2582109\n",
      "latent grad:  [[-0.00197818 -0.00035974 -0.00163814  0.00050285  0.00077324  0.00152753\n",
      "   0.00127548  0.000769  ]]\n",
      "89 \n",
      "\n",
      "latent:  [[-0.16848578 -0.30290046  0.0187441  -0.15086687 -0.02690708  0.15836014\n",
      "  -0.10813158  0.04979145]]\n",
      "loss:  0.25813678\n",
      "latent grad:  [[-0.00203369 -0.0002493  -0.00177208  0.00041221  0.00076534  0.00142521\n",
      "   0.00139856  0.00093997]]\n",
      "90 \n",
      "\n",
      "latent:  [[-0.16830923 -0.3027855   0.01902234 -0.15099528 -0.02708465  0.15821248\n",
      "  -0.10962126  0.04982871]]\n",
      "loss:  0.25810093\n",
      "latent grad:  [[-1.9854964e-03 -5.2418651e-05 -1.8718367e-03  2.3740761e-04\n",
      "   7.0798269e-04  1.1723364e-03  1.5167000e-03  1.1631246e-03]]\n",
      "91 \n",
      "\n",
      "latent:  [[-0.16813469 -0.30268094  0.01931385 -0.1511138  -0.02725746  0.15807268\n",
      "  -0.1112507   0.04984341]]\n",
      "loss:  0.2580206\n",
      "latent grad:  [[-1.7809693e-03  2.7828646e-04 -1.9292270e-03 -6.6773588e-05\n",
      "   5.9249677e-04  6.8308512e-04  1.6572209e-03  1.4787591e-03]]\n",
      "92 \n",
      "\n",
      "latent:  [[-0.16796342 -0.30258885  0.0196188  -0.15122041 -0.02742405  0.15794255\n",
      "  -0.11303328  0.0498324 ]]\n",
      "loss:  0.25816584\n",
      "latent grad:  [[-0.00151475  0.00063757 -0.00194709 -0.00040283  0.00042966  0.00013173\n",
      "   0.00173494  0.00178114]]\n",
      "93 \n",
      "\n",
      "latent:  [[-0.16779703 -0.30251133  0.01993651 -0.151313   -0.02758224  0.15782407\n",
      "  -0.11496954  0.04979298]]\n",
      "loss:  0.258058\n",
      "latent grad:  [[-0.00136981  0.0008843  -0.00197905 -0.00061586  0.00032052 -0.0002077\n",
      "   0.0018309   0.001987  ]]\n",
      "94 \n",
      "\n",
      "latent:  [[-0.16763611 -0.30244935  0.02026667 -0.1513908  -0.02773096  0.15771796\n",
      "  -0.11706327  0.04972427]]\n",
      "loss:  0.258029\n",
      "latent grad:  [[-0.00168067  0.00102659 -0.00238034 -0.00072382  0.00034046 -0.00023216\n",
      "   0.00207428  0.00234605]]\n",
      "95 \n",
      "\n",
      "latent:  [[-0.16747773 -0.30240276  0.020617   -0.15145412 -0.02787148  0.15762317\n",
      "  -0.11934476  0.04962286]]\n",
      "loss:  0.2579127\n",
      "latent grad:  [[-3.3999539e-03  1.4203092e-03 -4.4325697e-03 -1.0787114e-03\n",
      "   6.3653535e-04 -7.4054944e-05  3.1036937e-03  4.0368531e-03]]\n",
      "96 \n",
      "\n",
      "latent:  [[-0.16730846 -0.30237386  0.0210305  -0.1515008  -0.02800982  0.1575378\n",
      "  -0.12198216  0.04946324]]\n",
      "loss:  0.25778043\n",
      "latent grad:  [[-0.00846345  0.00250847 -0.01046364 -0.0020818   0.00147375  0.00042808\n",
      "   0.00592657  0.00895503]]\n",
      "97 \n",
      "\n",
      "latent:  [[-0.16709039 -0.3023712   0.02163318 -0.15152244 -0.02816099  0.15745823\n",
      "  -0.12541357  0.0491676 ]]\n",
      "loss:  0.25767928\n",
      "latent grad:  [[-0.02274482  0.0056711  -0.02738731 -0.00488536  0.00364043  0.00198161\n",
      "   0.01384582  0.02255065]]\n",
      "98 \n",
      "\n",
      "latent:  [[-0.16671784 -0.30242223  0.0227731  -0.15149342 -0.02836232  0.15737543\n",
      "  -0.13050364  0.04851889]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.2545965\n",
      "latent grad:  [[-0.09966753  0.02435115 -0.12051886 -0.02227359  0.0149278   0.00657228\n",
      "   0.05675548  0.10023019]]\n",
      "99 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    # 0 Initialization\n",
    "    N_MARCHING_CUBE = 64\n",
    "    lr= 8e-3\n",
    "    l2reg= True\n",
    "    regl2 = 1e-3\n",
    "    decreased_by = 1.5\n",
    "    adjust_lr_every = 50\n",
    "    \n",
    "    # 1 prepare data\n",
    "    ## sphere\n",
    "    source_id = 999 # zywvjkvz2492e6xpq4hd1jzy2r9lht        # This will be the source shape (ie starting point)\n",
    "    ## torus\n",
    "    target_id = 2 # 0bucd9ryckhaqtqvbiagilujeqzek4  \n",
    "    latent, latent_target = getLatentSourceAndTarget(args, source_id, target_id)\n",
    "    \n",
    "    # 2 prepare model\n",
    "    decoder = constructDecoder(args)\n",
    "    # 3 prepare optimiser\n",
    "    optimizer = torch.optim.Adam([latent], lr=lr)\n",
    "\n",
    "    losses = []\n",
    "    lambdas = []\n",
    "    \n",
    "\n",
    "    objectiveDe = decoder_obj(latent_target, decoder)\n",
    "\n",
    "    # Use Adam optimizer, with source as starting point, and a loss defined on meshes\n",
    "    # latent is the input of our function\n",
    "    print(\"Starting optimization:\")\n",
    "    for e in range(int(args.iterations)):\n",
    "        print(\"latent: \", latent.detach().numpy())\n",
    "        \n",
    "        loss = objectiveDe.func(latent)\n",
    "        losses.append(loss.detach().cpu().numpy()) \n",
    "        print(\"loss: \", loss.detach().numpy())\n",
    "        \n",
    "        grad = objectiveDe.dfunc(latent)\n",
    "        print(\"latent grad: \", grad.detach().numpy())\n",
    "\n",
    "        adjust_learning_rate(lr, optimizer, e, decreased_by, adjust_lr_every)\n",
    "        optimizer.step()\n",
    "        print(e, \"th iteration\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization:\n",
      "Loss at iter 0 : 0.48616671562194824 , latent norm:  tensor(0.7349, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.00032093250774778426\n",
      "\n",
      "\n",
      "Loss at iter 1 : 0.47127389907836914 , latent norm:  tensor(0.7159, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0004450293490663171\n",
      "\n",
      "\n",
      "Loss at iter 2 : 0.45521456003189087 , latent norm:  tensor(0.6971, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0003503200423438102\n",
      "\n",
      "\n",
      "Loss at iter 3 : 0.44181013107299805 , latent norm:  tensor(0.6785, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.00052491674432531\n",
      "\n",
      "\n",
      "Loss at iter 4 : 0.4257057011127472 , latent norm:  tensor(0.6602, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.00047321445890702307\n",
      "\n",
      "\n",
      "Loss at iter 5 : 0.4115152359008789 , latent norm:  tensor(0.6422, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0005928690661676228\n",
      "\n",
      "\n",
      "Loss at iter 6 : 0.39883702993392944 , latent norm:  tensor(0.6245, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0005959018599241972\n",
      "\n",
      "\n",
      "Loss at iter 7 : 0.3841349482536316 , latent norm:  tensor(0.6071, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0005234084092080593\n",
      "\n",
      "\n",
      "Loss at iter 8 : 0.370826780796051 , latent norm:  tensor(0.5900, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0005313650472089648\n",
      "\n",
      "\n",
      "Loss at iter 9 : 0.35857224464416504 , latent norm:  tensor(0.5733, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.000503839401062578\n",
      "\n",
      "\n",
      "Loss at iter 10 : 0.3457784354686737 , latent norm:  tensor(0.5571, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0005860175006091595\n",
      "\n",
      "\n",
      "Loss at iter 11 : 0.33234357833862305 , latent norm:  tensor(0.5414, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0005201985477469862\n",
      "\n",
      "\n",
      "Loss at iter 12 : 0.32169848680496216 , latent norm:  tensor(0.5263, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0006400357815437019\n",
      "\n",
      "\n",
      "Loss at iter 13 : 0.30964115262031555 , latent norm:  tensor(0.5119, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0006156791932880878\n",
      "\n",
      "\n",
      "Loss at iter 14 : 0.2984156608581543 , latent norm:  tensor(0.4981, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0006256511551328003\n",
      "\n",
      "\n",
      "Loss at iter 15 : 0.2890230119228363 , latent norm:  tensor(0.4851, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0006488993531093001\n",
      "\n",
      "\n",
      "Loss at iter 16 : 0.2779526710510254 , latent norm:  tensor(0.4728, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.0006015747785568237\n",
      "\n",
      "\n",
      "Loss at iter 17 : 0.27117979526519775 , latent norm:  tensor(0.4613, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.00048660743050277233\n",
      "\n",
      "\n",
      "Loss at iter 18 : 0.2649272084236145 , latent norm:  tensor(0.4509, grad_fn=<NormBackward0>)\n",
      "loss backward: -0.00027767999563366175\n",
      "\n",
      "\n",
      "Loss at iter 19 : 0.26020348072052 , latent norm:  tensor(0.4415, grad_fn=<NormBackward0>)\n",
      "loss backward: -9.768325253389776e-05\n",
      "\n",
      "\n",
      "Loss at iter 20 : 0.2604731619358063 , latent norm:  tensor(0.4333, grad_fn=<NormBackward0>)\n",
      "loss backward: -7.052948785712942e-05\n",
      "\n",
      "\n",
      "Loss at iter 21 : 0.25847384333610535 , latent norm:  tensor(0.4262, grad_fn=<NormBackward0>)\n",
      "loss backward: -2.738928742473945e-05\n",
      "\n",
      "\n",
      "Loss at iter 22 : 0.2598073184490204 , latent norm:  tensor(0.4202, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.577451257617213e-05\n",
      "\n",
      "\n",
      "Loss at iter 23 : 0.25787314772605896 , latent norm:  tensor(0.4151, grad_fn=<NormBackward0>)\n",
      "loss backward: 2.3607492039445788e-05\n",
      "\n",
      "\n",
      "Loss at iter 24 : 0.2593437135219574 , latent norm:  tensor(0.4109, grad_fn=<NormBackward0>)\n",
      "loss backward: 2.690615292522125e-05\n",
      "\n",
      "\n",
      "Loss at iter 25 : 0.2581721544265747 , latent norm:  tensor(0.4074, grad_fn=<NormBackward0>)\n",
      "loss backward: 6.970468530198559e-05\n",
      "\n",
      "\n",
      "Loss at iter 26 : 0.2588612735271454 , latent norm:  tensor(0.4046, grad_fn=<NormBackward0>)\n",
      "loss backward: 7.522618398070335e-05\n",
      "\n",
      "\n",
      "Loss at iter 27 : 0.25970888137817383 , latent norm:  tensor(0.4023, grad_fn=<NormBackward0>)\n",
      "loss backward: 5.257432349026203e-05\n",
      "\n",
      "\n",
      "Loss at iter 28 : 0.26143911480903625 , latent norm:  tensor(0.4006, grad_fn=<NormBackward0>)\n",
      "loss backward: 9.558149758959189e-05\n",
      "\n",
      "\n",
      "Loss at iter 29 : 0.2609761357307434 , latent norm:  tensor(0.3993, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00013416889123618603\n",
      "\n",
      "\n",
      "Loss at iter 30 : 0.26047059893608093 , latent norm:  tensor(0.3983, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00014156529505271465\n",
      "\n",
      "\n",
      "Loss at iter 31 : 0.26008346676826477 , latent norm:  tensor(0.3977, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.0001351633545709774\n",
      "\n",
      "\n",
      "Loss at iter 32 : 0.2605680525302887 , latent norm:  tensor(0.3973, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.000124799320474267\n",
      "\n",
      "\n",
      "Loss at iter 33 : 0.2604888379573822 , latent norm:  tensor(0.3971, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00011898799129994586\n",
      "\n",
      "\n",
      "Loss at iter 34 : 0.2612946629524231 , latent norm:  tensor(0.3971, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.0001152080440078862\n",
      "\n",
      "\n",
      "Loss at iter 35 : 0.261402428150177 , latent norm:  tensor(0.3973, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00011368761624908075\n",
      "\n",
      "\n",
      "Loss at iter 36 : 0.2612895965576172 , latent norm:  tensor(0.3976, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00011448081204434857\n",
      "\n",
      "\n",
      "Loss at iter 37 : 0.2604854702949524 , latent norm:  tensor(0.3980, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00011853854084620252\n",
      "\n",
      "\n",
      "Loss at iter 38 : 0.2603716254234314 , latent norm:  tensor(0.3985, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00012444266758393496\n",
      "\n",
      "\n",
      "Loss at iter 39 : 0.2599264979362488 , latent norm:  tensor(0.3992, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00013057986507192254\n",
      "\n",
      "\n",
      "Loss at iter 40 : 0.2599813640117645 , latent norm:  tensor(0.4000, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00013719128037337214\n",
      "\n",
      "\n",
      "Loss at iter 41 : 0.26057547330856323 , latent norm:  tensor(0.4009, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00013854456483386457\n",
      "\n",
      "\n",
      "Loss at iter 42 : 0.26118990778923035 , latent norm:  tensor(0.4019, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00013414319255389273\n",
      "\n",
      "\n",
      "Loss at iter 43 : 0.2610834240913391 , latent norm:  tensor(0.4030, grad_fn=<NormBackward0>)\n",
      "loss backward: 0.00011493699275888503\n",
      "\n",
      "\n",
      "Loss at iter 44 : 0.2612033486366272 , latent norm:  tensor(0.4043, grad_fn=<NormBackward0>)\n",
      "loss backward: 8.464929851470515e-05\n",
      "\n",
      "\n",
      "Loss at iter 45 : 0.26019132137298584 , latent norm:  tensor(0.4056, grad_fn=<NormBackward0>)\n",
      "loss backward: 5.328111001290381e-05\n",
      "\n",
      "\n",
      "Loss at iter 46 : 0.2593209147453308 , latent norm:  tensor(0.4070, grad_fn=<NormBackward0>)\n",
      "loss backward: 4.427343810675666e-05\n",
      "\n",
      "\n",
      "Loss at iter 47 : 0.25872349739074707 , latent norm:  tensor(0.4085, grad_fn=<NormBackward0>)\n",
      "loss backward: 6.169492553453892e-05\n",
      "\n",
      "\n",
      "Loss at iter 48 : 0.25880077481269836 , latent norm:  tensor(0.4101, grad_fn=<NormBackward0>)\n",
      "loss backward: 7.56967201596126e-05\n",
      "\n",
      "\n",
      "Loss at iter 49 : 0.25826022028923035 , latent norm:  tensor(0.4117, grad_fn=<NormBackward0>)\n",
      "loss backward: 7.881801866460592e-05\n",
      "\n",
      "\n",
      "Loss at iter 50 : 0.25817540287971497 , latent norm:  tensor(0.4133, grad_fn=<NormBackward0>)\n",
      "loss backward: 5.139856511959806e-05\n",
      "\n",
      "\n",
      "Loss at iter 51 : 0.25837182998657227 , latent norm:  tensor(0.4144, grad_fn=<NormBackward0>)\n",
      "loss backward: 3.467938950052485e-05\n",
      "\n",
      "\n",
      "Loss at iter 52 : 0.2586873769760132 , latent norm:  tensor(0.4154, grad_fn=<NormBackward0>)\n",
      "loss backward: 3.011771332239732e-05\n",
      "\n",
      "\n",
      "Loss at iter 53 : 0.25910499691963196 , latent norm:  tensor(0.4163, grad_fn=<NormBackward0>)\n",
      "loss backward: 2.2896436348673888e-05\n",
      "\n",
      "\n",
      "Loss at iter 54 : 0.2590028941631317 , latent norm:  tensor(0.4173, grad_fn=<NormBackward0>)\n",
      "loss backward: 2.0534142095129937e-05\n",
      "\n",
      "\n",
      "Loss at iter 55 : 0.2587982416152954 , latent norm:  tensor(0.4182, grad_fn=<NormBackward0>)\n",
      "loss backward: 2.018989107455127e-05\n",
      "\n",
      "\n",
      "Loss at iter 56 : 0.2582367956638336 , latent norm:  tensor(0.4190, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.853607318480499e-05\n",
      "\n",
      "\n",
      "Loss at iter 57 : 0.25766098499298096 , latent norm:  tensor(0.4198, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.6475973097840324e-05\n",
      "\n",
      "\n",
      "Loss at iter 58 : 0.2576944828033447 , latent norm:  tensor(0.4206, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.793883893697057e-05\n",
      "\n",
      "\n",
      "Loss at iter 59 : 0.2578703463077545 , latent norm:  tensor(0.4213, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.926283584907651e-05\n",
      "\n",
      "\n",
      "Loss at iter 60 : 0.25776177644729614 , latent norm:  tensor(0.4220, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.2140319995523896e-05\n",
      "\n",
      "\n",
      "Loss at iter 61 : 0.25814488530158997 , latent norm:  tensor(0.4226, grad_fn=<NormBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss backward: 1.1138835361634847e-05\n",
      "\n",
      "\n",
      "Loss at iter 62 : 0.25807440280914307 , latent norm:  tensor(0.4232, grad_fn=<NormBackward0>)\n",
      "loss backward: 7.734292921668384e-06\n",
      "\n",
      "\n",
      "Loss at iter 63 : 0.258292019367218 , latent norm:  tensor(0.4237, grad_fn=<NormBackward0>)\n",
      "loss backward: 3.0643043373856926e-06\n",
      "\n",
      "\n",
      "Loss at iter 64 : 0.2585563063621521 , latent norm:  tensor(0.4242, grad_fn=<NormBackward0>)\n",
      "loss backward: -2.5317297058791155e-06\n",
      "\n",
      "\n",
      "Loss at iter 65 : 0.25884777307510376 , latent norm:  tensor(0.4246, grad_fn=<NormBackward0>)\n",
      "loss backward: -4.389380592328962e-06\n",
      "\n",
      "\n",
      "Loss at iter 66 : 0.2589910924434662 , latent norm:  tensor(0.4251, grad_fn=<NormBackward0>)\n",
      "loss backward: -5.21024094268796e-06\n",
      "\n",
      "\n",
      "Loss at iter 67 : 0.25918376445770264 , latent norm:  tensor(0.4254, grad_fn=<NormBackward0>)\n",
      "loss backward: -6.157760253699962e-06\n",
      "\n",
      "\n",
      "Loss at iter 68 : 0.2593681216239929 , latent norm:  tensor(0.4258, grad_fn=<NormBackward0>)\n",
      "loss backward: -9.01718158274889e-06\n",
      "\n",
      "\n",
      "Loss at iter 69 : 0.2596413195133209 , latent norm:  tensor(0.4260, grad_fn=<NormBackward0>)\n",
      "loss backward: -9.70842575043207e-06\n",
      "\n",
      "\n",
      "Loss at iter 70 : 0.25973257422447205 , latent norm:  tensor(0.4263, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.3321523510967381e-05\n",
      "\n",
      "\n",
      "Loss at iter 71 : 0.2597428560256958 , latent norm:  tensor(0.4265, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.511374102847185e-05\n",
      "\n",
      "\n",
      "Loss at iter 72 : 0.2597483992576599 , latent norm:  tensor(0.4267, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.5136803085624706e-05\n",
      "\n",
      "\n",
      "Loss at iter 73 : 0.2597498595714569 , latent norm:  tensor(0.4269, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.4896580069034826e-05\n",
      "\n",
      "\n",
      "Loss at iter 74 : 0.2597479224205017 , latent norm:  tensor(0.4270, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.5101484677870758e-05\n",
      "\n",
      "\n",
      "Loss at iter 75 : 0.25974273681640625 , latent norm:  tensor(0.4272, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.5094497030077036e-05\n",
      "\n",
      "\n",
      "Loss at iter 76 : 0.2597341537475586 , latent norm:  tensor(0.4273, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.3419990864349529e-05\n",
      "\n",
      "\n",
      "Loss at iter 77 : 0.25964581966400146 , latent norm:  tensor(0.4274, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.1112209904240444e-05\n",
      "\n",
      "\n",
      "Loss at iter 78 : 0.25947317481040955 , latent norm:  tensor(0.4274, grad_fn=<NormBackward0>)\n",
      "loss backward: -1.0290760656062048e-05\n",
      "\n",
      "\n",
      "Loss at iter 79 : 0.2593652307987213 , latent norm:  tensor(0.4275, grad_fn=<NormBackward0>)\n",
      "loss backward: -8.82757558429148e-06\n",
      "\n",
      "\n",
      "Loss at iter 80 : 0.2592674791812897 , latent norm:  tensor(0.4276, grad_fn=<NormBackward0>)\n",
      "loss backward: -9.012343070935458e-06\n",
      "\n",
      "\n",
      "Loss at iter 81 : 0.2590898275375366 , latent norm:  tensor(0.4276, grad_fn=<NormBackward0>)\n",
      "loss backward: -8.20774948806502e-06\n",
      "\n",
      "\n",
      "Loss at iter 82 : 0.25899091362953186 , latent norm:  tensor(0.4277, grad_fn=<NormBackward0>)\n",
      "loss backward: -6.278668024606304e-06\n",
      "\n",
      "\n",
      "Loss at iter 83 : 0.25887149572372437 , latent norm:  tensor(0.4278, grad_fn=<NormBackward0>)\n",
      "loss backward: -6.389012014551554e-06\n",
      "\n",
      "\n",
      "Loss at iter 84 : 0.2588394284248352 , latent norm:  tensor(0.4278, grad_fn=<NormBackward0>)\n",
      "loss backward: -5.533558578463271e-06\n",
      "\n",
      "\n",
      "Loss at iter 85 : 0.2587299942970276 , latent norm:  tensor(0.4279, grad_fn=<NormBackward0>)\n",
      "loss backward: -4.319771505834069e-06\n",
      "\n",
      "\n",
      "Loss at iter 86 : 0.258624404668808 , latent norm:  tensor(0.4280, grad_fn=<NormBackward0>)\n",
      "loss backward: -3.4904537642432842e-06\n",
      "\n",
      "\n",
      "Loss at iter 87 : 0.25831925868988037 , latent norm:  tensor(0.4282, grad_fn=<NormBackward0>)\n",
      "loss backward: -2.386032065260224e-07\n",
      "\n",
      "\n",
      "Loss at iter 88 : 0.25828856229782104 , latent norm:  tensor(0.4283, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.8492208937459509e-06\n",
      "\n",
      "\n",
      "Loss at iter 89 : 0.2582145631313324 , latent norm:  tensor(0.4286, grad_fn=<NormBackward0>)\n",
      "loss backward: 4.377620371087687e-06\n",
      "\n",
      "\n",
      "Loss at iter 90 : 0.25814032554626465 , latent norm:  tensor(0.4288, grad_fn=<NormBackward0>)\n",
      "loss backward: 5.5115006034611724e-06\n",
      "\n",
      "\n",
      "Loss at iter 91 : 0.2581033408641815 , latent norm:  tensor(0.4291, grad_fn=<NormBackward0>)\n",
      "loss backward: 7.267670298460871e-06\n",
      "\n",
      "\n",
      "Loss at iter 92 : 0.2580219507217407 , latent norm:  tensor(0.4294, grad_fn=<NormBackward0>)\n",
      "loss backward: 8.649599294585641e-06\n",
      "\n",
      "\n",
      "Loss at iter 93 : 0.25816604495048523 , latent norm:  tensor(0.4298, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.0255846973450389e-05\n",
      "\n",
      "\n",
      "Loss at iter 94 : 0.2580574154853821 , latent norm:  tensor(0.4303, grad_fn=<NormBackward0>)\n",
      "loss backward: 9.672779015090782e-06\n",
      "\n",
      "\n",
      "Loss at iter 95 : 0.2580231726169586 , latent norm:  tensor(0.4308, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.1564943633857183e-05\n",
      "\n",
      "\n",
      "Loss at iter 96 : 0.2579015791416168 , latent norm:  tensor(0.4315, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.2664077985391486e-05\n",
      "\n",
      "\n",
      "Loss at iter 97 : 0.25766029953956604 , latent norm:  tensor(0.4323, grad_fn=<NormBackward0>)\n",
      "loss backward: 1.6900923583307303e-05\n",
      "\n",
      "\n",
      "Loss at iter 98 : 0.256121426820755 , latent norm:  tensor(0.4335, grad_fn=<NormBackward0>)\n",
      "loss backward: 4.4159496610518545e-05\n",
      "\n",
      "\n",
      "Loss at iter 99 : 0.24406372010707855 , latent norm:  tensor(0.4350, grad_fn=<NormBackward0>)\n",
      "loss backward: 9.075464913621545e-05\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verts_target, faces_target = deep_sdf.mesh.create_mesh_optim(\n",
    "    decoder, latent_target, N=N_MARCHING_CUBE, max_batch=int(2 ** 18)\n",
    ")\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    torch.manual_seed(0)\n",
    "    # Initialization\n",
    "    N_MARCHING_CUBE = 64\n",
    "    lr= 8e-3\n",
    "    l2reg= True\n",
    "    regl2 = 1e-3\n",
    "    decreased_by = 1.5\n",
    "    adjust_lr_every = 50\n",
    "    \n",
    "\n",
    "    \n",
    "    # pick initialization and samples\n",
    "    # Load collection of all latent codes\n",
    "    all_codes_path = os.path.join(\n",
    "        args.experiment_directory,\n",
    "        ws.latent_codes_subdir,\n",
    "        'latest.pth')\n",
    "    all_codes = torch.load(all_codes_path)['latent_codes']['weight']\n",
    "    ## sphere\n",
    "    source_id = 999 # zywvjkvz2492e6xpq4hd1jzy2r9lht        # This will be the source shape (ie starting point)\n",
    "    latent = all_codes[source_id].unsqueeze(0).detach()#.cuda()   #Add .cuda() if you want to run on GPU\n",
    "    latent.requires_grad = True\n",
    "\n",
    "    ## torus\n",
    "    target_id = 2 # 0bucd9ryckhaqtqvbiagilujeqzek4          # This is be the target shape (ie objective)\n",
    "    latent_target = all_codes[target_id].unsqueeze(0).detach()#.cuda()   #Add .cuda() if you want to run on GPU\n",
    "\n",
    "     \n",
    "    \n",
    "    specs_filename = os.path.join(args.experiment_directory, \"specs.json\")\n",
    "    specs = json.load(open(specs_filename))\n",
    "    arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
    "    latent_size = specs[\"CodeLength\"]\n",
    "    # Load decoder: this is our black box function\n",
    "    decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "    decoder = torch.nn.DataParallel(decoder)\n",
    "    saved_model_state = torch.load(\n",
    "        os.path.join(\n",
    "            args.experiment_directory, ws.model_params_subdir, args.checkpoint + \".pth\"\n",
    "        ),\n",
    "        map_location=torch.device('cpu') # Remove this if you want to run on GPU\n",
    "    )\n",
    "    decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "    # Optionally: put decoder on GPU\n",
    "    #decoder = decoder.module.cuda()\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam([latent], lr=lr)\n",
    "\n",
    "    losses2 = []\n",
    "    lambdas = []\n",
    "    \n",
    "    objective = decoder_obj(latent_target, decoder)\n",
    "\n",
    "    # Use Adam optimizer, with source as starting point, and a loss defined on meshes\n",
    "    # latent is the input of our function\n",
    "    print(\"Starting optimization:\")\n",
    "    for e in range(int(args.iterations)):\n",
    "\n",
    "        if latent.grad is not None:\n",
    "            latent.grad.detach_()\n",
    "            latent.grad.zero_()\n",
    "\n",
    "        verts, faces = deep_sdf.mesh.create_mesh_optim(decoder, latent, N=N_MARCHING_CUBE, max_batch=int(2 ** 18))\n",
    "\n",
    "        \n",
    "        # subsample vertices for gradients computations\n",
    "        verts = verts[torch.randperm(verts.shape[0])]\n",
    "        verts = verts[0:20000, :]\n",
    "        # forward pass within loss layer\n",
    "        xyz_upstream = torch.tensor(verts.astype(float), requires_grad = True, dtype=torch.float32)#, device=torch.device('cuda:0')) # For GPU,\n",
    "        # Get a point cloud sampling of the target shape\n",
    "        verts_target_sample = verts_target[torch.randperm(verts_target.shape[0])]\n",
    "        verts_target_sample = verts_target_sample[0:20000, :]\n",
    "        xyz_target = torch.tensor(verts_target_sample.astype(float), requires_grad = False, dtype=torch.float32) # For GPU, add: , device=torch.device('cuda:0'))\n",
    "        # At this point we have 2 outputs for decoder: the target xyz_target, and the current value xyz_upstream\n",
    "        # The following lines compute a loss and backpropagate\n",
    "        # compute loss function: Chamfer between current guess (xyz_upstream) and objective (xyz_target)\n",
    "        loss = chamfer_distance(xyz_upstream, xyz_target)\n",
    "        print(\"Loss at iter\", e, \":\", loss.item(), \", latent norm: \", torch.norm(latent))\n",
    "        \n",
    "        \n",
    "        losses2.append(loss.detach().cpu().numpy())                                  ## Loss value\n",
    "        lambdas.append(torch.norm(latent_target-latent).detach().cpu().numpy())     ## Distance in the domain\n",
    "        decoder.eval()\n",
    "        loss.backward()\n",
    "        dL_dx_i = xyz_upstream.grad\n",
    "        \n",
    "        # use vertices to compute full backward pass\n",
    "        xyz = torch.tensor(verts.astype(float), requires_grad = True, dtype=torch.float32)#, device=torch.device('cuda:0')) # For GPU,\n",
    "        latent_inputs = latent.expand(xyz.shape[0], -1)\n",
    "        inputs = torch.cat([latent_inputs, xyz], 1)#.cuda()      #Add .cuda() if you want to run on GPU\n",
    "        #first compute normals\n",
    "        pred_sdf = decoder(inputs)\n",
    "        loss_normals = torch.sum(pred_sdf)\n",
    "        loss_normals.backward(retain_graph = True)\n",
    "        normals = xyz.grad/torch.norm(xyz.grad, 2, 1).unsqueeze(-1)\n",
    "        \n",
    "        # now assemble inflow derivative\n",
    "        latent.grad.detach_()\n",
    "        latent.grad.zero_()\n",
    "        dL_ds_i_fast = -torch.matmul(dL_dx_i.unsqueeze(1), normals.unsqueeze(-1)).squeeze(-1)\n",
    "        loss_backward = torch.sum(dL_ds_i_fast * pred_sdf)\n",
    "        if e % 20 == 0 and e > 0:\n",
    "            regl2 = regl2/2\n",
    "        if l2reg:\n",
    "            loss_backward += regl2* torch.mean(latent.pow(2))\n",
    "        # Backpropagate\n",
    "        loss_backward.backward()\n",
    "\n",
    "        \n",
    "       # print(\"time to backward:\", end-start)\n",
    "        # update latent\n",
    "        # Explicit gradient is accessible via latent.grad\n",
    "        \n",
    "        adjust_learning_rate(lr, optimizer, e, decreased_by, adjust_lr_every)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # 1. objective function value\n",
    "        print(\"loss backward:\", loss_backward.item())\n",
    "        # 2. its derivative function value on current arguments \n",
    "        print(\"\\n\")\n",
    "        #print(latent.grad)\n",
    "        #print(\"shape of verts_target, faces_target: \", verts_target.shape, faces_target.shape, xyz_target.shape)\n",
    "        #raise Exception(\"Stop\");\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2a5e5b90>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2b17b850>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(losses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cma_es(adjust_optimizer):\n",
    "    def __init__(self, dim=2):\n",
    "        self.dim = dim\n",
    "        paras = {'x0': torch.zeros((dim,)),\n",
    "                 'std': torch.ones((dim,)) * 3, \n",
    "                 'tol': 1e-5, \n",
    "                 'adjust_func': do_nothing(), \n",
    "                 'record': False, \n",
    "                 'verbose': False}\n",
    "        self.set_parameters(paras)\n",
    "    def set_parameters(self, paras):\n",
    "        self.paras = paras\n",
    "        self.x0 = paras['x0'] \n",
    "        self.std = paras['std']\n",
    "        self.tol = paras['tol']\n",
    "        self.adjust_func = paras['adjust_func']\n",
    "        self.max_iter = 400 if 'max_iter' not in paras.keys() else paras['max_iter']\n",
    "        # set none to use default value \n",
    "        self.cluster_size = None if 'cluster_size' not in paras.keys() else paras['cluster_size']\n",
    "        self.survival_size = None if 'survival_size' not in paras.keys() else paras['survival_size']\n",
    "        self.record = True if 'record' not in paras.keys() else paras['record']\n",
    "        self.verbose = True if 'verbose' not in paras.keys() else paras['verbose']\n",
    "    def optimise(self, obj):\n",
    "        '''\n",
    "        @param obj: objective function class instance\n",
    "        return arg: found minimum arguments\n",
    "               val: found minimum value\n",
    "               stats: collection of recorded statistics for post-analysis\n",
    "        '''                  \n",
    "        def update_mean(x):\n",
    "            return (weights @ x).reshape(dim, 1)\n",
    "        def update_ps(ps, sigma, C, mean, mean_old):\n",
    "            return (1 - cs) * ps + torch.sqrt(cs * (2 - cs) * mueff) * invsqrtC @ (mean - mean_old) / sigma \n",
    "        def update_pc(pc, sigma, ps, mean, mean_old):\n",
    "            hsig = (torch.norm(ps) / torch.sqrt(1 - (1 - cs)**(2 * iter_/lambda_)) / chiN < 1.4 + 2/(dim + 1)).int()\n",
    "            return (1 - cc) * pc + hsig * torch.sqrt(cc * (2 - cc) * mueff) * (mean - mean_old) / sigma\n",
    "        def update_C(C, pc, x, mean_old, sigma):\n",
    "            hsig = (torch.norm(ps) / torch.sqrt(1 - (1 - cs)**(2 * iter_/lambda_)) / chiN < (1.4 + 2/(dim + 1))).int()\n",
    "            artmp = (1 / sigma) * (x - mean_old.reshape(1, dim))\n",
    "            return (1 - c1 - cmu) * C + c1 * (pc * pc.T + (1 - hsig) * cc * (2 - cc) * C) + cmu * artmp.T @ torch.diag(weights) @ artmp\n",
    "        def update_sigma(sigma, ps):\n",
    "            return sigma * torch.exp((cs / damps) * (torch.norm(ps)/ chiN - 1))\n",
    "        def is_not_moving(arg, val, pre_arg, pre_val, tol):\n",
    "            dis_arg = torch.norm(arg - pre_arg, dim=1).mean()\n",
    "            dis_val = torch.abs(val - pre_val).mean()\n",
    "            return (dis_arg < tol and dis_val < tol) \n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"\\n\\n*******starting optimisation from intitial mean: \", self.x0.squeeze().detach().numpy())\n",
    "        # User defined input parameters \n",
    "        dim = self.dim\n",
    "        sigma = 0.3\n",
    "        D = self.std / sigma\n",
    "        mean = self.x0.reshape(dim, 1)\n",
    "        # the size of solutions group\n",
    "        lambda_ = 4 + int(3 * np.log(dim)) if self.cluster_size == None else self.cluster_size  \n",
    "        # only best \"mu\" solutions are used to generate iterations\n",
    "        mu = int(lambda_ / 2) if self.survival_size == None else self.survival_size\n",
    "        # used to combine best \"mu\" solutions                                               \n",
    "        weights = np.log(mu + 1/2) - torch.log(torch.arange(mu, dtype=torch.float) + 1) \n",
    "        weights = (weights / torch.sum(weights)).float()    \n",
    "        mueff = 1 / torch.sum(weights**2) \n",
    "\n",
    "        # Strategy parameter setting: Adaptation\n",
    "        # time constant for cumulation for C\n",
    "        cc = (4 + mueff / dim) / (dim + 4 + 2 * mueff / dim)  \n",
    "        # t-const for cumulation for sigma control\n",
    "        cs = (mueff + 2) / (dim + mueff + 5)  \n",
    "        # learning rate for rank-one update of C\n",
    "        c1 = 2 / ((dim + 1.3)**2 + mueff)    \n",
    "        # and for rank-mu update\n",
    "        cmu = min(1 - c1, 2 * (mueff - 2 + 1 / mueff) / ((dim + 2)**2 + mueff))  \n",
    "        # damping for sigma, usually close to 1  \n",
    "        damps = 1 + 2 * max(0, np.sqrt((mueff - 1)/( dim + 1)) - 1) + cs                                                                 \n",
    "\n",
    "        # Initialize dynamic (internal) strategy parameters and constants\n",
    "        # evolution paths for C and sigma\n",
    "        pc = torch.zeros((dim, 1))     \n",
    "        ps = torch.zeros((dim, 1)) \n",
    "        # B defines the coordinate system\n",
    "        B = torch.eye(int(dim))       \n",
    "        # covariance matrix C\n",
    "        C = B * torch.diag(D**2) * B.T \n",
    "        # C^-1/2 \n",
    "        invsqrtC = B * torch.diag(D**-1) * B.T   \n",
    "        # expectation of ||N(0,I)|| == norm(randn(N,1)) \n",
    "        chiN = dim**0.5 * (1 - 1/(4 * dim) + 1 / (21 * dim**2))  \n",
    "\n",
    "        # --------------------  Initialization --------------------------------  \n",
    "        x, x_old, f = torch.zeros((lambda_, dim)), torch.zeros((lambda_, dim)), torch.zeros((lambda_,))\n",
    "        stats = {}\n",
    "        inner_stats = {}\n",
    "        stats['inner'] = []\n",
    "        stats['val'], stats['arg'] = [], []\n",
    "        stats['x_adjust'] = []\n",
    "        iter_eval, stats['evals_per_iter'] = torch.zeros((lambda_, )), []\n",
    "        inner_stats = [{}] * lambda_\n",
    "        stats['mean'], stats['std'] = [], []\n",
    "        stats['status'] = None\n",
    "        iter_, eval_ = 0, 0\n",
    "        # initial data in record\n",
    "        for i in range(lambda_):\n",
    "            x[i,:] = (mean + torch.randn(dim, 1)).squeeze()\n",
    "            f[i] = obj.func(x[i])\n",
    "        idx = torch.argsort(f.detach())\n",
    "        x_ascending = x[idx]\n",
    "        if self.record:\n",
    "            stats['inner'].append(inner_stats.detach().numpy())\n",
    "            stats['arg'].append(x_ascending.detach().numpy())\n",
    "            stats['val'].append(f[idx].detach().numpy())\n",
    "            stats['mean'].append(mean.detach().numpy())\n",
    "            stats['std'].append(sigma * B @ torch.diag(D))\n",
    "            stats['evals_per_iter'].append(torch.ones((lambda_,)).detach().numpy())\n",
    "            stats['x_adjust'].append(np.vstack((x.T.clone().detach().numpy(), x.T.clone().detach().numpy())))\n",
    "        arg = x_ascending\n",
    "        val = f[idx]\n",
    "        pre_arg = x_ascending\n",
    "        pre_val = f[idx]\n",
    "        best_val = 1e4\n",
    "        best_arg = None\n",
    "        \n",
    "        # optimise by iterations\n",
    "        try:\n",
    "            while iter_ < self.max_iter:\n",
    "                iter_ += 1\n",
    "                # generate candidate solutions with some stochastic elements\n",
    "                for i in range(lambda_):\n",
    "                    x[i] = (mean + sigma * B @ torch.diag(D) @ torch.randn(dim, 1)).squeeze()\n",
    "                    x_old[i] = x[i]\n",
    "                    x[i], f[i], inner_stats[i] = self.adjust_func.adjust(x[i].clone().detach().requires_grad_(True), obj)\n",
    "                    eval_ += inner_stats[i]['evals']\n",
    "                    iter_eval[i] = inner_stats[i]['evals']\n",
    "                # sort the value and positions of solutions \n",
    "                idx = torch.argsort(f.detach())\n",
    "                x_ascending = x[idx]\n",
    "\n",
    "                # update the parameter for next iteration\n",
    "                mean_old = mean\n",
    "                mean = update_mean(x_ascending[:mu])\n",
    "                ps =   update_ps(ps, sigma, C, mean, mean_old)\n",
    "                pc =   update_pc(pc, sigma, ps, mean, mean_old)\n",
    "                sigma = update_sigma(sigma, ps)\n",
    "                C =    update_C(C, pc, x_ascending[:mu], mean_old, sigma)\n",
    "                C = torch.triu(C) + torch.triu(C, 1).T\n",
    "                D, B = torch.eig(C, eigenvectors=True)\n",
    "                D = torch.sqrt(D[:,0])\n",
    "                invsqrtC = B @ torch.diag(D**-1) @ B\n",
    "\n",
    "                # record data during process for post analysis\n",
    "                if self.record:\n",
    "                    stats['inner'].append(inner_stats.clone().detach().numpy())\n",
    "                    stats['arg'].append(x_ascending.detach().numpy())\n",
    "                    stats['val'].append(f[idx].detach().numpy())\n",
    "                    stats['mean'].append(mean.detach().numpy())\n",
    "                    stats['std'].append((sigma * B @ np.diag(D)).detach().numpy())\n",
    "                    stats['evals_per_iter'].append(iter_eval.clone().detach().numpy())\n",
    "                    stats['x_adjust'].append(np.vstack((x_old.T.clone().detach().numpy(), x.T.clone().detach().numpy())))\n",
    "                # stopping condition    \n",
    "                arg = x_ascending\n",
    "                val = f[idx]\n",
    "                if best_val > val[0]:\n",
    "                    best_val = val[0]\n",
    "                    best_arg = arg[0]              \n",
    "                # check the stop condition\n",
    "                if torch.max(D) > (torch.min(D) * 1e6):\n",
    "                    stats['status'] = 'diverge'\n",
    "                    print('diverge, concentrate in low dimension manifold')\n",
    "                    break\n",
    "                if is_not_moving(arg, val, pre_arg, pre_val, self.tol) :\n",
    "                    break\n",
    "                pre_arg = arg\n",
    "                pre_val = val\n",
    "        except np.linalg.LinAlgError as err:\n",
    "            stats['status'] = 'diverge'\n",
    "            print('diverge, raise LinAlgError!')\n",
    "        finally:\n",
    "            if self.verbose:\n",
    "                print('eigenvalue of variance = {}'.format(D))\n",
    "                print('total iterations = {}, total evaluatios = {}'.format(iter_, eval_))\n",
    "                print('found minimum position = {}, found minimum = {}'.format(best_arg.detach().numpy(), best_val.detach().numpy()))\n",
    "\n",
    "        # carry statistics info before quit\n",
    "        if self.record:\n",
    "            stats['arg'] = np.array(stats['arg'])\n",
    "            stats['val'] = np.array(stats['val'])\n",
    "            stats['mean'] = np.array(stats['mean'])\n",
    "            stats['std'] = np.array(stats['std'])\n",
    "            stats['evals_per_iter'] = np.array(stats['evals_per_iter'])\n",
    "            stats['x_adjust'] = np.array(stats['x_adjust'])\n",
    "        stats['evals'] = eval_\n",
    "        return best_arg, best_val, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder_obj(objective_func):\n",
    "    def __init__(self, latent_target, decoder):\n",
    "        self.N_MARCHING_CUBE = 64\n",
    "        self.l2reg= True\n",
    "        self.regl2 = 1e-3\n",
    "        self.iter = 0\n",
    "        self.quick = False\n",
    "        \n",
    "        self.latent_target = latent_target\n",
    "        self.decoder = decoder\n",
    "        self.optimum = 0\n",
    "        self.optimal = latent_target\n",
    "        \n",
    "        # Get a mesh representation of the target shape\n",
    "        self.verts_target, faces_target = deep_sdf.mesh.create_mesh_optim(\n",
    "            decoder, latent_target, N=self.N_MARCHING_CUBE, max_batch=int(2 ** 18)\n",
    "        )\n",
    "    \n",
    "        \n",
    "    def func(self, latent):\n",
    "        # from latent to xyz\n",
    "        verts, faces = deep_sdf.mesh.create_mesh_optim(self.decoder, latent, N=self.N_MARCHING_CUBE, max_batch=int(2 ** 18))\n",
    "        verts = verts[torch.randperm(verts.shape[0])]\n",
    "        verts = verts[0:20000, :]\n",
    "        self.xyz_upstream = torch.tensor(verts.astype(float), requires_grad = True, dtype=torch.float32)#, device=torch.device('cuda:0')) # For GPU,\n",
    "       \n",
    "        # from latent_traget to xyz_target\n",
    "        verts_target_sample = self.verts_target[torch.randperm(self.verts_target.shape[0])]\n",
    "        verts_target_sample = verts_target_sample[0:20000, :]\n",
    "        xyz_target = torch.tensor(verts_target_sample.astype(float), requires_grad = False, dtype=torch.float32) # For GPU, add: , device=torch.device('cuda:0'))\n",
    "\n",
    "        # compare difference\n",
    "        loss = chamfer_distance(self.xyz_upstream, xyz_target)\n",
    "        self.last_loss = loss;\n",
    "        self.last_latent = latent;\n",
    "        return loss\n",
    "    \n",
    "    def dfunc(self, latent):\n",
    "        \n",
    "        if latent.grad is not None:\n",
    "            latent.grad.detach_()\n",
    "            latent.grad.zero_()\n",
    "        \n",
    "        # step 1\n",
    "        if self.quick and torch.norm(latent - self.last_latent):\n",
    "            loss = self.last_loss\n",
    "        else:\n",
    "            loss = self.func(latent)\n",
    "        decoder.eval()\n",
    "        loss.backward()\n",
    "        dL_dx_i = self.xyz_upstream.grad\n",
    "        \n",
    "        # step 2\n",
    "        # use vertices to compute full backward pass\n",
    "        xyz = self.xyz_upstream.clone().detach()\n",
    "        xyz.requires_grad = True\n",
    "        latent_inputs = latent.expand(xyz.shape[0], -1)\n",
    "        inputs = torch.cat([latent_inputs, xyz], 1)#.cuda()      #Add .cuda() if you want to run on GPU\n",
    "        #first compute normals\n",
    "        pred_sdf = self.decoder(inputs)\n",
    "        loss_normals = torch.sum(pred_sdf)\n",
    "        loss_normals.backward(retain_graph = True)\n",
    "        normals = xyz.grad/torch.norm(xyz.grad, 2, 1).unsqueeze(-1)\n",
    "                \n",
    "        # step 3\n",
    "        # now assemble inflow derivative\n",
    "        latent.grad.detach_()\n",
    "        latent.grad.zero_()\n",
    "        dL_ds_i_fast = -torch.matmul(dL_dx_i.unsqueeze(1), normals.unsqueeze(-1)).squeeze(-1)\n",
    "        loss_backward = torch.sum(dL_ds_i_fast * pred_sdf)\n",
    "        if l2reg and self.iter % 20 == 0 and self.iter > 0:\n",
    "            self.regl2 = self.regl2/2\n",
    "        if l2reg:\n",
    "            loss_backward += self.regl2 * torch.mean(latent.pow(2))\n",
    "        # Backpropagate\n",
    "        loss_backward.backward()\n",
    "        \n",
    "        return latent.grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adam(adjust_optimizer):\n",
    "    def __init__(self, alpha=0.01, verbose=False, dim=2):\n",
    "        self.alpha = 0.01\n",
    "        self.beta_1 = 0.9\n",
    "        self.beta_2 = 0.999\n",
    "        self.epsilon = 1e-11\n",
    "        self.max_iter = 10000\n",
    "        self.tol = 1e-3\n",
    "        self.verbose = verbose\n",
    "        self.record = False\n",
    "        self.x0 = torch.zeros((dim,))\n",
    "        \n",
    "    def set_parameters(self, paras):\n",
    "        self.paras = paras\n",
    "        self.x0 = paras['x0']\n",
    "        self.alpha = paras['alpha']\n",
    "        self.beta_1 = paras['beta_1']\n",
    "        self.beta_2 = paras['beta_2']\n",
    "        self.epsilon = paras['epsilon']\n",
    "        self.max_iter = paras['max_iter']\n",
    "        self.tol = paras['tol']\n",
    "        self.verbose = True if 'verbose' not in paras.keys() else paras['verbose']\n",
    "        self.record = False if 'record' not in paras.keys() else paras['record']\n",
    "        \n",
    "    def optimise(self, obj):\n",
    "        m_t = 0 \n",
    "        v_t = 0 \n",
    "        eval_cnt = 0\n",
    "        x = self.x0\n",
    "        stats = {}\n",
    "        stats['status'] = None\n",
    "        stats['gradient_before_after'] = []\n",
    "        stats['arg'] = []\n",
    "        stats['val'] = []\n",
    "        if self.record:\n",
    "            stats['arg'].append(x.clone().detach().numpy())\n",
    "            stats['val'].append(obj.func(x).detach().numpy())\n",
    "            stats['gradient_before_after'].append([obj.dfunc(x).detach().numpy(), obj.dfunc(x).detach().numpy()])\n",
    "        if self.verbose:\n",
    "            print(\"\\n\\n*******starting optimisation from intitial point: \", self.x0.squeeze().detach().numpy())\n",
    "        while eval_cnt < self.max_iter:\t\t\t\t\t#till it gets converged\n",
    "            eval_cnt += 1\n",
    "            x = x.clone().detach().requires_grad_(True)\n",
    "            loss = obj.func(x)\n",
    "            g_t = obj.dfunc(x)\t\t#computes the gradient of the stochastic function\n",
    "            m_t = self.beta_1*m_t + (1-self.beta_1)*g_t\t#updates the moving averages of the gradient\n",
    "            v_t = self.beta_2*v_t + (1-self.beta_2)*(g_t*g_t)\t#updates the moving averages of the squared gradient\n",
    "            m_cap = m_t/(1-(self.beta_1**eval_cnt))\t\t#calculates the bias-corrected estimates\n",
    "            v_cap = v_t/(1-(self.beta_2**eval_cnt))\t\t#calculates the bias-corrected estimates\n",
    "            x_prev = x.clone()\t\t\t\t\t\t\t\t\n",
    "            est_df = (m_cap)/(torch.sqrt(v_cap)+self.epsilon)\n",
    "            with torch.no_grad():\n",
    "                x -= self.alpha * est_df \t#updates the parameters\n",
    "            if self.verbose:\n",
    "                print(\"iter: \", eval_cnt)\n",
    "                print(\"loss: \", loss.detach().numpy())\n",
    "                print(\"gradient: \", g_t.detach().numpy())\n",
    "                print(\"latent: \", x.detach().numpy())\n",
    "                print(\"\\n\")\n",
    "            if self.record:\n",
    "                stats['arg'].append(x.clone().detach().numpy())\n",
    "                stats['val'].append(obj.func(x).detach().numpy())\n",
    "                stats['gradient_before_after'].append([g_t.detach().numpy(), est_df.detach().numpy()])\n",
    "            if(torch.norm(x-x_prev) < self.tol):\t\t#checks if it is converged or not\n",
    "                break\n",
    "        if self.verbose:\n",
    "            print('total evaluatios = {}'.format(eval_cnt))\n",
    "            print('gradient at stop position = {},\\nmodified graident = {}'.format(g_t, est_df))\n",
    "            print('found minimum position = {}, found minimum = {}'.format(x.detach().numpy(), obj.func(x).detach().numpy()))\n",
    "        stats['arg'] = np.array(stats['arg'])\n",
    "        stats['val'] = np.array(stats['val'])\n",
    "        stats['gradient_before_after'] = np.array(stats['gradient_before_after'])\n",
    "        stats['evals'] = eval_cnt\n",
    "        return x, obj.func(x), stats\n",
    "    \n",
    "class line_search(adjust_optimizer):\n",
    "    def __init__(self, alpha=1, beta=0.1):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_iter = 100\n",
    "        self.tol = 1e-2\n",
    "        self.verbose = False\n",
    "        self.record = False\n",
    "     \n",
    "    def set_parameters(self, paras):\n",
    "        self.paras = paras\n",
    "        self.x0 = paras['x0']\n",
    "        self.alpha = paras['alpha']\n",
    "        self.beta = paras['beta']\n",
    "        self.max_iter = paras['max_iter']\n",
    "        self.tol = paras['tol']\n",
    "        self.verbose = True if 'verbose' not in paras.keys() else paras['verbose']\n",
    "        self.record = True if 'record' not in paras.keys() else paras['record']\n",
    "    def optimise(self, obj):\n",
    "        '''\n",
    "        @param x0: initial point position\n",
    "        @param alpha: initial step size\n",
    "        @param beta: control the armijo condition\n",
    "        @return x: point position after moving to local minimum\n",
    "        '''\n",
    "        x = self.x0\n",
    "        alpha_ = self.alpha\n",
    "        tao = 0.5\n",
    "        fx = obj.func(x)\n",
    "        p = - obj.dfunc(x)\n",
    "        fnx = obj.func(x + alpha_ * p)\n",
    "        eval_cnt = 3\n",
    "        stats = {}\n",
    "        stats['status'] = None\n",
    "        stats['gradient'] = []\n",
    "        stats['arg'] = []\n",
    "        stats['val'] = []\n",
    "        if self.record:\n",
    "            stats['arg'].append(x.clone().detach().numpy())\n",
    "            stats['val'].append(fx.detach().numpy())\n",
    "            stats['gradient'].append(-p.detach().numpy())\n",
    "        if self.verbose:\n",
    "            print(\"\\n*******starting optimisation from intitial point: \", self.x0.squeeze().detach().numpy())\n",
    "        for k in range(self.max_iter):\n",
    "            while fnx > fx + alpha_ * self.beta * (-p @ p):\n",
    "                alpha_ *= tao\n",
    "                fnx = obj.func(x + alpha_ * p)\n",
    "                eval_cnt += 1\n",
    "            with torch.no_grad():\n",
    "                x += alpha_ * p\n",
    "            fx = fnx\n",
    "            x = x.clone().detach().requires_grad_(True)\n",
    "            p = -obj.dfunc(x)\n",
    "            fnx = obj.func(x + alpha_ * p)\n",
    "            eval_cnt += 2\n",
    "            if self.record:\n",
    "                stats['arg'].append(x.clone().detach().numpy())\n",
    "                #print(eval_cnt, stats['arg'])\n",
    "                stats['val'].append(fx.detach().numpy())\n",
    "                stats['gradient'].append(-p.detach().numpy())\n",
    "            if torch.norm(p) < self.tol:\n",
    "                break\n",
    "        stats['evals'] = eval_cnt\n",
    "        if self.verbose:\n",
    "            print('total evaluatios = {}'.format(eval_cnt))\n",
    "            print('gradient at stop position = {}'.format(-p.detach().numpy()))\n",
    "            print('found minimum position = {}, found minimum = {}'.format(x.detach().numpy(), fx.detach().numpy()))\n",
    "        stats['arg'] = np.array(stats['arg'])\n",
    "        stats['val'] = np.array(stats['val'])\n",
    "        stats['gradient'] = np.array(stats['gradient'])\n",
    "        return x, fnx, stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*******starting optimisation from intitial point:  [-0.16573758 -0.303306    0.026367   -0.15115654 -0.02860292  0.15756649\n",
      " -0.1368305   0.04584491]\n",
      "iter:  1\n",
      "loss:  0.24256815\n",
      "gradient:  [[ 0.23324756 -0.00914744  0.25230905  0.01283198 -0.08097865 -0.07835684\n",
      "  -0.13298956 -0.18212958]]\n",
      "latent:  [[-0.16673759 -0.30230603  0.025367   -0.15215655 -0.02760292  0.15856649\n",
      "  -0.13583049  0.04684491]]\n",
      "\n",
      "\n",
      "iter:  2\n",
      "loss:  0.24795644\n",
      "gradient:  [[ 0.07475271  0.01635668  0.06909052 -0.00869123 -0.03409294 -0.0393898\n",
      "  -0.03206065 -0.04221123]]\n",
      "latent:  [[-0.16760285 -0.30262864  0.02452414 -0.1522938  -0.02669654  0.15949945\n",
      "  -0.13500464  0.04766574]]\n",
      "\n",
      "\n",
      "iter:  3\n",
      "loss:  0.25203586\n",
      "gradient:  [[-0.03562179  0.0236766  -0.05234402 -0.01934196 -0.0044179  -0.01323456\n",
      "   0.02481575  0.05092768]]\n",
      "latent:  [[-0.1681727  -0.30328438  0.02401074 -0.15186143 -0.02596468  0.16030796\n",
      "  -0.13449065  0.04810984]]\n",
      "\n",
      "\n",
      "iter:  4\n",
      "loss:  0.2538634\n",
      "gradient:  [[-0.02742548  0.01633123 -0.0386137  -0.01292874 -0.00217845 -0.00720788\n",
      "   0.01911026  0.03621595]]\n",
      "latent:  [[-0.16857256 -0.30403337  0.0236779  -0.15127853 -0.02535097  0.16101518\n",
      "  -0.1341528   0.04836051]]\n",
      "\n",
      "\n",
      "iter:  5\n",
      "loss:  0.25480378\n",
      "gradient:  [[-0.07832909  0.02053631 -0.09551443 -0.01841716  0.01082444  0.00388568\n",
      "   0.04515645  0.08008402]]\n",
      "latent:  [[-0.16873094 -0.30485675  0.02359529 -0.15056689 -0.02490286  0.16158853\n",
      "  -0.13404839  0.0483511 ]]\n",
      "\n",
      "\n",
      "iter:  6\n",
      "loss:  0.25537297\n",
      "gradient:  [[-0.09589937  0.02217229 -0.11451572 -0.01982445  0.01458884  0.00854121\n",
      "   0.05442569  0.09405886]]\n",
      "latent:  [[-0.16867864 -0.3057306   0.02372366 -0.14977303 -0.02460676  0.16203047\n",
      "  -0.13414517  0.04813222]]\n",
      "\n",
      "\n",
      "iter:  7\n",
      "loss:  0.2547503\n",
      "gradient:  [[-0.06497285  0.0182372  -0.07953299 -0.01580355  0.00811614  0.00256951\n",
      "   0.03836557  0.06697543]]\n",
      "latent:  [[-0.1685187  -0.30662712  0.02395905 -0.14894004 -0.02439491  0.16240168\n",
      "  -0.13434765  0.04780817]]\n",
      "\n",
      "\n",
      "iter:  8\n",
      "loss:  0.25454742\n",
      "gradient:  [[-0.03866332  0.01613356 -0.04979595 -0.01270768  0.00073305 -0.00269922\n",
      "   0.02449379  0.04348829]]\n",
      "latent:  [[-0.1683123  -0.30753267  0.02424092 -0.14809348 -0.0242122   0.16274376\n",
      "  -0.13459854  0.04743915]]\n",
      "\n",
      "\n",
      "iter:  9\n",
      "loss:  0.253594\n",
      "gradient:  [[-0.04557995  0.02038137 -0.05792034 -0.0145683  -0.00153462 -0.00234638\n",
      "   0.02936875  0.04959302]]\n",
      "latent:  [[-0.16805473 -0.30845976  0.02457396 -0.14722608 -0.02404168  0.16306019\n",
      "  -0.13490437  0.04702118]]\n",
      "\n",
      "\n",
      "iter:  10\n",
      "loss:  0.2520502\n",
      "gradient:  [[-0.04199668  0.02330999 -0.05949923 -0.01944077 -0.00287928 -0.01142517\n",
      "   0.0261531   0.05660924]]\n",
      "latent:  [[-0.16775796 -0.30941015  0.02495332 -0.14632456 -0.02387406  0.16340184\n",
      "  -0.13524954  0.04655039]]\n",
      "\n",
      "\n",
      "iter:  11\n",
      "loss:  0.25048587\n",
      "gradient:  [[-0.0121938   0.02567693 -0.02634851 -0.01700669 -0.01414988 -0.01762665\n",
      "   0.01540511  0.02930084]]\n",
      "latent:  [[-0.16747221 -0.31038275  0.02533046 -0.14540444 -0.02365066  0.1637951\n",
      "  -0.1356017   0.04607644]]\n",
      "\n",
      "\n",
      "iter:  12\n",
      "loss:  0.24798754\n",
      "gradient:  [[ 0.03731972  0.02589656  0.02876376 -0.01197823 -0.0284733  -0.02659566\n",
      "  -0.00384313 -0.0150571 ]]\n",
      "latent:  [[-0.16727804 -0.31137305  0.02562676 -0.14449114 -0.02331509  0.16426896\n",
      "  -0.13590726  0.04567909]]\n",
      "\n",
      "\n",
      "iter:  13\n",
      "loss:  0.24559315\n",
      "gradient:  [[ 0.05368522  0.02154968  0.04277664 -0.01324711 -0.02813981 -0.03653286\n",
      "  -0.01698565 -0.02063484]]\n",
      "latent:  [[-0.16719183 -0.31236786  0.02583033 -0.1435768  -0.02288838  0.16484037\n",
      "  -0.1361329   0.04536043]]\n",
      "\n",
      "\n",
      "iter:  14\n",
      "loss:  0.24447349\n",
      "gradient:  [[ 0.08782011  0.00969058  0.08592317 -0.00677085 -0.04171705 -0.04721442\n",
      "  -0.04955894 -0.05368406]]\n",
      "latent:  [[-0.1672527  -0.31332207  0.02588861 -0.14269845 -0.02234561  0.16551198\n",
      "  -0.13619237  0.04517677]]\n",
      "\n",
      "\n",
      "iter:  15\n",
      "loss:  0.24397156\n",
      "gradient:  [[ 0.12125473 -0.00107202  0.12881364  0.00115917 -0.05236623 -0.05301908\n",
      "  -0.07631371 -0.08821072]]\n",
      "latent:  [[-0.16747965 -0.3141785   0.02576866 -0.14191377 -0.02169126  0.16626906\n",
      "  -0.13604838  0.04517303]]\n",
      "\n",
      "\n",
      "iter:  16\n",
      "loss:  0.24430312\n",
      "gradient:  [[ 0.08436687  0.00639799  0.08726632 -0.0029677  -0.04348936 -0.04185253\n",
      "  -0.05115527 -0.05868296]]\n",
      "latent:  [[-0.1677984  -0.31499383  0.02555041 -0.14117779 -0.0209668   0.16707547\n",
      "  -0.13579619  0.04527062]]\n",
      "\n",
      "\n",
      "iter:  17\n",
      "loss:  0.24481939\n",
      "gradient:  [[ 0.04985563  0.01655821  0.04622478 -0.00781277 -0.03168237 -0.02988779\n",
      "  -0.02051612 -0.02858862]]\n",
      "latent:  [[-0.16815497 -0.31582305  0.02529424 -0.14044845 -0.02020987  0.16789845\n",
      "  -0.13551788  0.04540801]]\n",
      "\n",
      "\n",
      "iter:  18\n",
      "loss:  0.24614687\n",
      "gradient:  [[ 0.02904706  0.02043182  0.02274132 -0.0093161  -0.02495349 -0.02163535\n",
      "  -0.00538726 -0.01217237]]\n",
      "latent:  [[-0.16851889 -0.31667924  0.02503247 -0.1397142  -0.01944161  0.16871539\n",
      "  -0.13525179  0.04555384]]\n",
      "\n",
      "\n",
      "iter:  19\n",
      "loss:  0.24779652\n",
      "gradient:  [[-0.02774386  0.02724511 -0.04041881 -0.01528933 -0.01044924 -0.00809003\n",
      "   0.02833496  0.03649792]]\n",
      "latent:  [[-0.16880898 -0.3175786   0.0248486  -0.13894016 -0.01870631  0.16948636\n",
      "  -0.135083    0.04562175]]\n",
      "\n",
      "\n",
      "iter:  20\n",
      "loss:  0.24843553\n",
      "gradient:  [[-0.05315618  0.02785775 -0.06877185 -0.0175753  -0.00182012 -0.00246248\n",
      "   0.04167952  0.05983406]]\n",
      "latent:  [[-0.16899398 -0.318515    0.02477323 -0.1381213  -0.01803079  0.17019653\n",
      "  -0.1350355   0.04557912]]\n",
      "\n",
      "\n",
      "iter:  21\n",
      "loss:  0.24821874\n",
      "gradient:  [[-0.06849802  0.02851394 -0.08471081 -0.01830912  0.0008354   0.00231598\n",
      "   0.04783849  0.07064493]]\n",
      "latent:  [[-0.16906223 -0.3194835   0.02481481 -0.13726157 -0.01741936  0.17083389\n",
      "  -0.13510959  0.04542176]]\n",
      "\n",
      "\n",
      "iter:  22\n",
      "loss:  0.24823445\n",
      "gradient:  [[-0.07908721  0.02925849 -0.09578799 -0.01881219  0.00152959  0.00623288\n",
      "   0.05019994  0.07656579]]\n",
      "latent:  [[-0.16901223 -0.32048023  0.02497236 -0.13636537 -0.01686879  0.17138973\n",
      "  -0.13529514  0.04515579]]\n",
      "\n",
      "\n",
      "iter:  23\n",
      "loss:  0.24711339\n",
      "gradient:  [[-0.05753308  0.02604408 -0.07063542 -0.01558528 -0.00435831  0.00208191\n",
      "   0.03753242  0.05625203]]\n",
      "latent:  [[-0.16888678 -0.3214926   0.02520251 -0.13545214 -0.01635068  0.17188776\n",
      "  -0.13555099  0.04482449]]\n",
      "\n",
      "\n",
      "iter:  24\n",
      "loss:  0.24593918\n",
      "gradient:  [[-0.02958765  0.01715939 -0.03143445 -0.0082568  -0.02043472 -0.004337\n",
      "   0.01148833  0.02359543]]\n",
      "latent:  [[-0.16873114 -0.32249078  0.02545139 -0.13456334 -0.01580415  0.17235796\n",
      "  -0.13581133  0.04448424]]\n",
      "\n",
      "\n",
      "iter:  25\n",
      "loss:  0.24415669\n",
      "gradient:  [[ 4.11425950e-03  1.84065234e-02  3.83139632e-05 -7.86413252e-03\n",
      "  -2.19232589e-02 -1.28670465e-02  3.31338961e-03  1.93063053e-03]]\n",
      "latent:  [[-0.16859524 -0.32348093  0.02567804 -0.13369855 -0.01522691  0.1728348\n",
      "  -0.13605651  0.04417105]]\n",
      "\n",
      "\n",
      "iter:  26\n",
      "loss:  0.24310142\n",
      "gradient:  [[ 0.05341013  0.01274673  0.05012009 -0.00518326 -0.02659179 -0.0294227\n",
      "  -0.01788095 -0.02948069]]\n",
      "latent:  [[-0.1685491  -0.3244426   0.02581839 -0.13287275 -0.01460726  0.17337355\n",
      "  -0.1362352   0.04393713]]\n",
      "\n",
      "\n",
      "iter:  27\n",
      "loss:  0.24185242\n",
      "gradient:  [[ 0.0953528   0.00294071  0.09998536  0.00234055 -0.03846327 -0.03666364\n",
      "  -0.04939792 -0.07033386]]\n",
      "latent:  [[-0.16864231 -0.3253339   0.02581576 -0.13213913 -0.01391709  0.17398751\n",
      "  -0.13627416  0.04384732]]\n",
      "\n",
      "\n",
      "iter:  28\n",
      "loss:  0.24198532\n",
      "gradient:  [[ 0.07675869  0.00835277  0.07922692 -0.00067825 -0.03469642 -0.03278908\n",
      "  -0.03343837 -0.05373712]]\n",
      "latent:  [[-0.16883273 -0.32618782  0.0257132  -0.13146536 -0.01317602  0.1746559\n",
      "  -0.13622798  0.04385687]]\n",
      "\n",
      "\n",
      "iter:  29\n",
      "loss:  0.24303949\n",
      "gradient:  [[ 0.09989092  0.0047316   0.10645461  0.00312309 -0.03736977 -0.03838878\n",
      "  -0.03934729 -0.07179648]]\n",
      "latent:  [[-0.16913785 -0.32699054  0.02548992 -0.13087715 -0.01238419  0.17538635\n",
      "  -0.13609111  0.04398469]]\n",
      "\n",
      "\n",
      "iter:  30\n",
      "loss:  0.24474475\n",
      "gradient:  [[ 0.01598663  0.02046587  0.00770275 -0.00993586 -0.01452161 -0.02095115\n",
      "   0.01468154  0.00600637]]\n",
      "latent:  [[-0.1694378  -0.32781762  0.02527682 -0.13026665 -0.01161228  0.17612289\n",
      "  -0.13600263  0.04409102]]\n",
      "\n",
      "\n",
      "iter:  31\n",
      "loss:  0.24590111\n",
      "gradient:  [[-0.01079611  0.0237639  -0.01875194 -0.00988262 -0.01090799 -0.00894484\n",
      "   0.02921196  0.02117918]]\n",
      "latent:  [[-0.16969582 -0.32867846  0.02510672 -0.12963614 -0.01087006  0.17682609\n",
      "  -0.13599452  0.04415171]]\n",
      "\n",
      "\n",
      "iter:  32\n",
      "loss:  0.24713309\n",
      "gradient:  [[-0.05098011  0.029487   -0.06487665 -0.01482205 -0.00111411  0.002242\n",
      "   0.04977099  0.05433123]]\n",
      "latent:  [[-0.16985728 -0.32958752  0.02503615 -0.12895535 -0.0101897   0.17745821\n",
      "  -0.13610855  0.04411402]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  33\n",
      "loss:  0.24682093\n",
      "gradient:  [[-0.05971706  0.03097997 -0.07524385 -0.01564015  0.0022214   0.0060487\n",
      "   0.05531158  0.06142123]]\n",
      "latent:  [[-0.16991857 -0.33054197  0.02506863 -0.1282254  -0.00957848  0.17801054\n",
      "  -0.13634259  0.0439763 ]]\n",
      "\n",
      "\n",
      "iter:  34\n",
      "loss:  0.24687517\n",
      "gradient:  [[-0.03232984  0.02622656 -0.04183782 -0.01109752 -0.00686633  0.00058636\n",
      "   0.03768955  0.03455868]]\n",
      "latent:  [[-0.1699282  -0.3315206   0.02515184 -0.12747997 -0.00899575  0.17851137\n",
      "  -0.13664383  0.04379258]]\n",
      "\n",
      "\n",
      "iter:  35\n",
      "loss:  0.24592373\n",
      "gradient:  [[ 0.00830987  0.01858891  0.00338887 -0.00596392 -0.01230514 -0.00935584\n",
      "   0.01614118  0.0015521 ]]\n",
      "latent:  [[-0.16994894 -0.33249372  0.02522321 -0.12675558 -0.00841872  0.17900312\n",
      "  -0.13695677  0.04362258]]\n",
      "\n",
      "\n",
      "iter:  36\n",
      "loss:  0.2449544\n",
      "gradient:  [[-0.0155703   0.02669572 -0.02768072 -0.01168405 -0.00517609 -0.00565881\n",
      "   0.03525259  0.02595286]]\n",
      "latent:  [[-0.16994512 -0.33349025  0.02532444 -0.12601043 -0.00787313  0.17947292\n",
      "  -0.13732459  0.04342303]]\n",
      "\n",
      "\n",
      "iter:  37\n",
      "loss:  0.24400218\n",
      "gradient:  [[-0.01540978  0.0260535  -0.0284875  -0.0124965  -0.0056072  -0.00633741\n",
      "   0.03082554  0.02570081]]\n",
      "latent:  [[-0.16991895 -0.3345049   0.02545422 -0.1252413  -0.0073543   0.17992558\n",
      "  -0.13773222  0.0431967 ]]\n",
      "\n",
      "\n",
      "iter:  38\n",
      "loss:  0.24289934\n",
      "gradient:  [[-0.01986657  0.02597591 -0.03159551 -0.01132265 -0.00755632 -0.00351554\n",
      "   0.03005715  0.02489119]]\n",
      "latent:  [[-0.1698656  -0.33553496  0.02561437 -0.12445815 -0.00685207  0.18035173\n",
      "  -0.13817441  0.04294707]]\n",
      "\n",
      "\n",
      "iter:  39\n",
      "loss:  0.24071623\n",
      "gradient:  [[-0.03739291  0.02895264 -0.0540694  -0.01516799 -0.00238615 -0.00080407\n",
      "   0.03728336  0.04265595]]\n",
      "latent:  [[-0.16976115 -0.3365876   0.02583188 -0.12363826 -0.00638522  0.18074293\n",
      "  -0.13866411  0.04264561]]\n",
      "\n",
      "\n",
      "iter:  40\n",
      "loss:  0.23875995\n",
      "gradient:  [[-0.0687143   0.0348021  -0.08973597 -0.01977054  0.00140478  0.00465862\n",
      "   0.05262996  0.06910133]]\n",
      "latent:  [[-0.16956455 -0.337676    0.02614613 -0.12276048 -0.00596611  0.18107966\n",
      "  -0.13922861  0.04225434]]\n",
      "\n",
      "\n",
      "iter:  41\n",
      "loss:  0.23579746\n",
      "gradient:  [[-0.0313009   0.0296348  -0.0496569  -0.01836918 -0.00885259 -0.00937982\n",
      "   0.02639338  0.04201282]]\n",
      "latent:  [[-0.16933888 -0.33878016  0.02649724 -0.12184026 -0.0055485   0.1814245\n",
      "  -0.13980426  0.04182617]]\n",
      "\n",
      "\n",
      "iter:  42\n",
      "loss:  0.23347718\n",
      "gradient:  [[ 0.10431232  0.01350736  0.10709228 -0.00685848 -0.05776753 -0.05829767\n",
      "  -0.05274723 -0.06231332]]\n",
      "latent:  [[-0.16929398 -0.3398427   0.02666712 -0.12095274 -0.00496506  0.18194725\n",
      "  -0.14018998  0.0415523 ]]\n",
      "\n",
      "\n",
      "iter:  43\n",
      "loss:  0.23231772\n",
      "gradient:  [[ 0.1573817   0.00579198  0.1674776  -0.00171111 -0.07166215 -0.07407468\n",
      "  -0.08312993 -0.10450941]]\n",
      "latent:  [[-0.16947736 -0.3408356   0.02660113 -0.1201321  -0.00421666  0.1826497\n",
      "  -0.14033063  0.04149217]]\n",
      "\n",
      "\n",
      "iter:  44\n",
      "loss:  0.23262557\n",
      "gradient:  [[ 0.11529147  0.01300627  0.11922106 -0.00594027 -0.05838802 -0.06160926\n",
      "  -0.05273804 -0.06925246]]\n",
      "latent:  [[-0.16979869 -0.3417961   0.02639383 -0.11934072 -0.00336433  0.18346825\n",
      "  -0.14033382  0.04155665]]\n",
      "\n",
      "\n",
      "iter:  45\n",
      "loss:  0.23337336\n",
      "gradient:  [[ 0.00685608  0.02450751 -0.0067449  -0.01548631 -0.02043169 -0.02485413\n",
      "   0.00888873  0.0163659 ]]\n",
      "latent:  [[-0.17010048 -0.34277147  0.02621382 -0.11851167 -0.00252159  0.1842929\n",
      "  -0.14035757  0.04158701]]\n",
      "\n",
      "\n",
      "iter:  46\n",
      "loss:  0.23424119\n",
      "gradient:  [[-0.0975077   0.04190485 -0.12603462 -0.02598455  0.00662573  0.00952062\n",
      "   0.07024926  0.09663869]]\n",
      "latent:  [[-0.17023452 -0.34381282  0.02621081 -0.11759379 -0.00177928  0.1850085\n",
      "  -0.14054032  0.04145039]]\n",
      "\n",
      "\n",
      "iter:  47\n",
      "loss:  0.23411351\n",
      "gradient:  [[-0.09998648  0.03892729 -0.12852982 -0.0247137   0.00928765  0.0126636\n",
      "   0.06730141  0.09620955]]\n",
      "latent:  [[-0.17021702 -0.34490156  0.02636483 -0.11660742 -0.00113852  0.18561296\n",
      "  -0.14085488  0.04116983]]\n",
      "\n",
      "\n",
      "iter:  48\n",
      "loss:  0.23280367\n",
      "gradient:  [[-0.04305463  0.02910869 -0.06489118 -0.02059916 -0.00541007 -0.00900075\n",
      "   0.03226201  0.05563298]]\n",
      "latent:  [[-0.17014186 -0.34600222  0.0265833  -0.1155825  -0.00053661  0.186194\n",
      "  -0.14121269  0.04082458]]\n",
      "\n",
      "\n",
      "iter:  49\n",
      "loss:  0.23139836\n",
      "gradient:  [[ 0.02552798  0.02024608  0.01459864 -0.01319677 -0.02601287 -0.03024004\n",
      "  -0.00392132  0.00061412]]\n",
      "latent:  [[-1.7010911e-01 -3.4708372e-01  2.6763793e-02 -1.1456389e-01\n",
      "   9.9878351e-05  1.8682346e-01 -1.4152887e-01  4.0509731e-02]]\n",
      "\n",
      "\n",
      "iter:  50\n",
      "loss:  0.23027709\n",
      "gradient:  [[ 0.10631243  0.00989197  0.10849641 -0.00454989 -0.05228056 -0.05354121\n",
      "  -0.05042326 -0.0668814 ]]\n",
      "latent:  [[-0.17022593 -0.34810865  0.026792   -0.11360584  0.00084281  0.18756081\n",
      "  -0.14169681  0.04033919]]\n",
      "\n",
      "\n",
      "iter:  51\n",
      "loss:  0.22969493\n",
      "gradient:  [[ 0.10754208  0.0077609   0.1090773  -0.00435757 -0.04992463 -0.05419916\n",
      "  -0.0508794  -0.0664351 ]]\n",
      "latent:  [[-0.17047569 -0.3490737   0.02668469 -0.11270394  0.0016704   0.18839134\n",
      "  -0.14173126  0.04029704]]\n",
      "\n",
      "\n",
      "iter:  52\n",
      "loss:  0.23032989\n",
      "gradient:  [[ 0.01630208  0.02074548  0.00280043 -0.01563188 -0.02535496 -0.0272794\n",
      "  -0.00493319  0.0068564 ]]\n",
      "latent:  [[-0.17072481 -0.35003614  0.02658375 -0.11178007  0.00250458  0.18923198\n",
      "  -0.1417512   0.04024718]]\n",
      "\n",
      "\n",
      "iter:  53\n",
      "loss:  0.23076093\n",
      "gradient:  [[ 0.0486927   0.01442649  0.04114855 -0.01349568 -0.04133051 -0.03952467\n",
      "  -0.03657209 -0.02069465]]\n",
      "latent:  [[-0.17101713 -0.350972    0.02644148 -0.11084941  0.0033895   0.19011538\n",
      "  -0.14168474  0.0402371 ]]\n",
      "\n",
      "\n",
      "iter:  54\n",
      "loss:  0.23157759\n",
      "gradient:  [[ 0.02249005  0.02123578  0.01338606 -0.01596349 -0.04067879 -0.029511\n",
      "  -0.0241376  -0.00544882]]\n",
      "latent:  [[-0.1713136  -0.35191047  0.0262956  -0.10989799  0.00431702  0.19100943\n",
      "  -0.14156848  0.04023729]]\n",
      "\n",
      "\n",
      "iter:  55\n",
      "loss:  0.23215505\n",
      "gradient:  [[ 0.01000246  0.01706897 -0.00067573 -0.0134701  -0.02754606 -0.02082105\n",
      "  -0.01495071  0.00238581]]\n",
      "latent:  [[-0.17159681 -0.3528354   0.02616396 -0.10894299  0.00524629  0.19188794\n",
      "  -0.141428    0.04023333]]\n",
      "\n",
      "\n",
      "iter:  56\n",
      "loss:  0.23283724\n",
      "gradient:  [[-0.08671929  0.02971676 -0.11112943 -0.02123098  0.00231709  0.01198783\n",
      "   0.04548824  0.07835539]]\n",
      "latent:  [[-0.17172974 -0.35379505  0.02618501 -0.10794097  0.00608215  0.19264376\n",
      "  -0.14140812  0.04009529]]\n",
      "\n",
      "\n",
      "iter:  57\n",
      "loss:  0.2337785\n",
      "gradient:  [[-0.15430218  0.03593848 -0.189519   -0.02597314  0.02953587  0.0367736\n",
      "   0.08655847  0.13121514]]\n",
      "latent:  [[-0.1716374  -0.35480556  0.02643018 -0.10687537  0.00673264  0.19319612\n",
      "  -0.14158767  0.03975801]]\n",
      "\n",
      "\n",
      "iter:  58\n",
      "loss:  0.23265302\n",
      "gradient:  [[-0.09594192  0.03027873 -0.12188497 -0.02238987  0.00505899  0.01420469\n",
      "   0.04913897  0.08617117]]\n",
      "latent:  [[-0.1714261  -0.35584164  0.02679313 -0.1057727   0.00730552  0.1936482\n",
      "  -0.14186044  0.03931582]]\n",
      "\n",
      "\n",
      "iter:  59\n",
      "loss:  0.23102404\n",
      "gradient:  [[ 0.00744005  0.01626941 -0.00356056 -0.0141465  -0.02864172 -0.02063318\n",
      "  -0.01648944  0.00425731]]\n",
      "latent:  [[-0.17124438 -0.35684976  0.02712685 -0.10468148  0.00792027  0.19412732\n",
      "  -0.14207003  0.0389074 ]]\n",
      "\n",
      "\n",
      "iter:  60\n",
      "loss:  0.23045695\n",
      "gradient:  [[ 0.07765839  0.00707219  0.07724768 -0.00796786 -0.05387337 -0.04303847\n",
      "  -0.06030371 -0.05363115]]\n",
      "latent:  [[-0.17118596 -0.35779548  0.02733505 -0.10363773  0.00864476  0.19469987\n",
      "  -0.14212036  0.03862813]]\n",
      "\n",
      "\n",
      "iter:  61\n",
      "loss:  0.23048922\n",
      "gradient:  [[ 0.06227847  0.01038913  0.05847688 -0.00930003 -0.04547536 -0.03692745\n",
      "  -0.04505009 -0.0407896 ]]\n",
      "latent:  [[-0.1712176  -0.3586987   0.02745292 -0.1026283   0.00944169  0.19533701\n",
      "  -0.14206347  0.03844362]]\n",
      "\n",
      "\n",
      "iter:  62\n",
      "loss:  0.22996175\n",
      "gradient:  [[ 0.03994928  0.01016664  0.03264511 -0.01076405 -0.03657589 -0.02856217\n",
      "  -0.0370586  -0.0241266 ]]\n",
      "latent:  [[-0.17130068 -0.35956272  0.02752023 -0.10164052  0.01027792  0.19600695\n",
      "  -0.14192791  0.03831687]]\n",
      "\n",
      "\n",
      "iter:  63\n",
      "loss:  0.2302915\n",
      "gradient:  [[ 0.03058334  0.01058756  0.02252974 -0.01050329 -0.03182104 -0.02391029\n",
      "  -0.03055555 -0.01780896]]\n",
      "latent:  [[-0.17141789 -0.36039323  0.02755379 -0.10067372  0.01113573  0.19669233\n",
      "  -0.14173567  0.03823204]]\n",
      "\n",
      "\n",
      "iter:  64\n",
      "loss:  0.23028426\n",
      "gradient:  [[-0.06388474  0.0144266  -0.08575711 -0.01345846  0.01291183  0.01538572\n",
      "   0.0280962   0.05347371]]\n",
      "latent:  [[-0.17143579 -0.36120978  0.02768845 -0.09970741  0.01186947  0.19726048\n",
      "  -0.14162627  0.03806513]]\n",
      "\n",
      "\n",
      "iter:  65\n",
      "loss:  0.23004614\n",
      "gradient:  [[-0.10282269  0.01355029 -0.13080129 -0.01368712  0.03556715  0.03401307\n",
      "   0.05072973  0.0816178 ]]\n",
      "latent:  [[-0.17131163 -0.36201027  0.02796564 -0.09874011  0.01240863  0.19765516\n",
      "  -0.14164409  0.03777891]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  66\n",
      "loss:  0.22901219\n",
      "gradient:  [[-0.08343032  0.01496841 -0.11022459 -0.01509475  0.0260974   0.02336837\n",
      "   0.04087307  0.07016131]]\n",
      "latent:  [[-0.1710867  -0.36280248  0.02834551 -0.09776343  0.01280732  0.19793196\n",
      "  -0.14175367  0.03740464]]\n",
      "\n",
      "\n",
      "iter:  67\n",
      "loss:  0.2287821\n",
      "gradient:  [[-0.02737921  0.01259822 -0.04886099 -0.01491172  0.00395569 -0.00186392\n",
      "   0.00789392  0.03176077]]\n",
      "latent:  [[-0.17084545 -0.36357728  0.02874787 -0.09677949  0.01315552  0.19818938\n",
      "  -0.14187123  0.03701248]]\n",
      "\n",
      "\n",
      "iter:  68\n",
      "loss:  0.22803783\n",
      "gradient:  [[ 0.0052368   0.01161649 -0.01275148 -0.01445351 -0.00941928 -0.01628172\n",
      "  -0.01188383  0.00869287]]\n",
      "latent:  [[-0.1706339  -0.3643323   0.02912813 -0.09579185  0.01350303  0.1984783\n",
      "  -0.14195019  0.03664216]]\n",
      "\n",
      "\n",
      "iter:  69\n",
      "loss:  0.22710891\n",
      "gradient:  [[ 0.00548556  0.01693676 -0.0137031  -0.01688028 -0.0126031  -0.01812277\n",
      "  -0.00858089  0.00979929]]\n",
      "latent:  [[-0.1704497  -0.3650926   0.02948958 -0.09478656  0.01386079  0.19880217\n",
      "  -0.1420017   0.03628971]]\n",
      "\n",
      "\n",
      "iter:  70\n",
      "loss:  0.22625202\n",
      "gradient:  [[ 0.06538686  0.01246524  0.05445317 -0.01360168 -0.0345608  -0.04169355\n",
      "  -0.04021955 -0.03393975]]\n",
      "latent:  [[-0.17037469 -0.3658386   0.0297495  -0.09378515  0.01429961  0.19923437\n",
      "  -0.14195397  0.03602922]]\n",
      "\n",
      "\n",
      "iter:  71\n",
      "loss:  0.2255064\n",
      "gradient:  [[ 0.05738609  0.01055234  0.04248432 -0.01624379 -0.02861423 -0.0426695\n",
      "  -0.04172868 -0.02257104]]\n",
      "latent:  [[-0.17038704 -0.36656332  0.02993232 -0.0927714   0.01479224  0.19976528\n",
      "  -0.14181332  0.03583232]]\n",
      "\n",
      "\n",
      "iter:  72\n",
      "loss:  0.22582015\n",
      "gradient:  [[ 0.04353376  0.01207382  0.02569613 -0.01771804 -0.02198693 -0.03883505\n",
      "  -0.03169502 -0.0096211 ]]\n",
      "latent:  [[-0.1704592  -0.36727583  0.03006608 -0.09173823  0.01531218  0.20037195\n",
      "  -0.14161189  0.0356706 ]]\n",
      "\n",
      "\n",
      "iter:  73\n",
      "loss:  0.22598913\n",
      "gradient:  [[ 0.05734415  0.01189196  0.04292836 -0.01639932 -0.03016417 -0.04351423\n",
      "  -0.03910086 -0.022045  ]]\n",
      "latent:  [[-0.17060484 -0.36797673  0.03013358 -0.0906956   0.015883    0.20105949\n",
      "  -0.14133848  0.03556275]]\n",
      "\n",
      "\n",
      "iter:  74\n",
      "loss:  0.22687674\n",
      "gradient:  [[ 0.04284795  0.01608268  0.02882181 -0.01613771 -0.0293243  -0.03584887\n",
      "  -0.02690223 -0.01504876]]\n",
      "latent:  [[-0.17079696 -0.368686    0.03015856 -0.0896462   0.01649694  0.20179625\n",
      "  -0.14102788  0.03549155]]\n",
      "\n",
      "\n",
      "iter:  75\n",
      "loss:  0.2274099\n",
      "gradient:  [[-0.01807396  0.01990495 -0.04054866 -0.02001695 -0.00854995 -0.01353459\n",
      "   0.0032405   0.03081891]]\n",
      "latent:  [[-0.17094532 -0.3694197   0.03023226 -0.08856885  0.01708241  0.20250851\n",
      "  -0.1407541   0.03537261]]\n",
      "\n",
      "\n",
      "iter:  76\n",
      "loss:  0.22847262\n",
      "gradient:  [[-0.06989993  0.02341184 -0.10049894 -0.02309061  0.01371762  0.00539503\n",
      "   0.03513812  0.0724279 ]]\n",
      "latent:  [[-0.17097959 -0.37019035  0.03042443 -0.08745074  0.01756469  0.20313552\n",
      "  -0.1405909   0.03513841]]\n",
      "\n",
      "\n",
      "iter:  77\n",
      "loss:  0.22865777\n",
      "gradient:  [[-0.07754589  0.02403005 -0.10887149 -0.02335728  0.01600245  0.0086521\n",
      "   0.03952209  0.07781215]]\n",
      "latent:  [[-0.17090043 -0.37099665  0.03073222 -0.08629608  0.01794517  0.20367385\n",
      "  -0.14053813  0.03479255]]\n",
      "\n",
      "\n",
      "iter:  78\n",
      "loss:  0.22767104\n",
      "gradient:  [[-0.03227249  0.02402984 -0.05613979 -0.02093617 -0.00518237 -0.00832667\n",
      "   0.01692394  0.04169786]]\n",
      "latent:  [[-0.17078282 -0.37183478  0.03108044 -0.08512247  0.01830795  0.20418988\n",
      "  -0.14053093  0.03440703]]\n",
      "\n",
      "\n",
      "iter:  79\n",
      "loss:  0.22729135\n",
      "gradient:  [[ 0.021205    0.01768522  0.00125944 -0.02067061 -0.02147249 -0.03447294\n",
      "  -0.01697952  0.00976424]]\n",
      "latent:  [[-0.17070673 -0.37267455  0.03139433 -0.08393397  0.01871068  0.20477094\n",
      "  -0.14048348  0.03404058]]\n",
      "\n",
      "\n",
      "iter:  80\n",
      "loss:  0.22711396\n",
      "gradient:  [[ 0.02011893  0.01793503 -0.0032832  -0.02332198 -0.01943474 -0.03834852\n",
      "  -0.02036192  0.01489681]]\n",
      "latent:  [[-0.17066687 -0.37351704  0.03168283 -0.08271913  0.01914279  0.20542195\n",
      "  -0.14039126  0.03368226]]\n",
      "\n",
      "\n",
      "iter:  81\n",
      "loss:  0.22688241\n",
      "gradient:  [[ 0.0636299   0.01364271  0.0507081  -0.01915429 -0.03931826 -0.05300744\n",
      "  -0.04664285 -0.02135728]]\n",
      "latent:  [[-0.17072284 -0.37434325  0.0318789  -0.08150322  0.01966697  0.20617738\n",
      "  -0.14019562  0.0333962 ]]\n",
      "\n",
      "\n",
      "iter:  82\n",
      "loss:  0.22685838\n",
      "gradient:  [[ 0.06166404  0.01426107  0.04908866 -0.01932292 -0.03934103 -0.0521477\n",
      "  -0.04503684 -0.01988262]]\n",
      "latent:  [[-0.17086244 -0.3751577   0.03199331 -0.0802858   0.02027293  0.20702124\n",
      "  -0.139911    0.03317308]]\n",
      "\n",
      "\n",
      "iter:  83\n",
      "loss:  0.22756794\n",
      "gradient:  [[ 0.00168538  0.01640676 -0.02146694 -0.02331025 -0.00976027 -0.03145577\n",
      "  -0.00637203  0.03222952]]\n",
      "latent:  [[-0.17099132 -0.37597132  0.03212448 -0.07904688  0.02085548  0.2078844\n",
      "  -0.13963777  0.03291322]]\n",
      "\n",
      "\n",
      "iter:  84\n",
      "loss:  0.22753534\n",
      "gradient:  [[ 0.00698016  0.01553523 -0.01283852 -0.02096542 -0.01128848 -0.03105234\n",
      "  -0.00404968  0.02661815]]\n",
      "latent:  [[-0.17111824 -0.37678042  0.03225986 -0.07780145  0.02142223  0.2087637\n",
      "  -0.13938044  0.0326299 ]]\n",
      "\n",
      "\n",
      "iter:  85\n",
      "loss:  0.22803903\n",
      "gradient:  [[-0.07451407  0.02280597 -0.10745198 -0.02450049  0.02805055  0.00123191\n",
      "   0.0581501   0.0924812 ]]\n",
      "latent:  [[-0.17112339 -0.3776174   0.03251918 -0.07653307  0.02183372  0.20955586\n",
      "  -0.13929158  0.03221167]]\n",
      "\n",
      "\n",
      "iter:  86\n",
      "loss:  0.22735786\n",
      "gradient:  [[-0.01194637  0.01444378 -0.03379975 -0.02091734  0.00388947 -0.02386804\n",
      "   0.01675224  0.04744785]]\n",
      "latent:  [[-0.17111047 -0.37844273  0.03279741 -0.07526296  0.02219252  0.21035004\n",
      "  -0.13925211  0.03174932]]\n",
      "\n",
      "\n",
      "iter:  87\n",
      "loss:  0.22695026\n",
      "gradient:  [[ 0.01835245  0.0126378   0.00107978 -0.01980043 -0.00968368 -0.03576038\n",
      "  -0.00291456  0.02442463]]\n",
      "latent:  [[-0.17112592 -0.37924957  0.03304793 -0.0739975   0.02255161  0.21118198\n",
      "  -0.13920921  0.03128705]]\n",
      "\n",
      "\n",
      "iter:  88\n",
      "loss:  0.22731405\n",
      "gradient:  [[ 0.04369119  0.01370043  0.03049408 -0.01850781 -0.02567915 -0.04449281\n",
      "  -0.02156596 -0.0003551 ]]\n",
      "latent:  [[-0.17120473 -0.38004476  0.03323468 -0.07274325  0.02296653  0.21207252\n",
      "  -0.13911723  0.03086916]]\n",
      "\n",
      "\n",
      "iter:  89\n",
      "loss:  0.22726192\n",
      "gradient:  [[ 0.03781966  0.01662961  0.02269987 -0.01904625 -0.02659026 -0.04175562\n",
      "  -0.02021499  0.00033894]]\n",
      "latent:  [[-0.17133231 -0.38084286  0.03337384 -0.07149646  0.02343492  0.21300703\n",
      "  -0.13898398  0.03049022]]\n",
      "\n",
      "\n",
      "iter:  90\n",
      "loss:  0.22723277\n",
      "gradient:  [[ 0.01541858  0.01895546 -0.0031976  -0.01972752 -0.01829497 -0.03230418\n",
      "  -0.00651998  0.01550291]]\n",
      "latent:  [[-0.17147088 -0.38165417  0.03350404 -0.07025303  0.02392327  0.21395358\n",
      "  -0.13884713  0.03011884]]\n",
      "\n",
      "\n",
      "iter:  91\n",
      "loss:  0.22739224\n",
      "gradient:  [[-0.01241136  0.0193419  -0.0345903  -0.02006885 -0.0036434  -0.02066539\n",
      "   0.01336493  0.03766559]]\n",
      "latent:  [[-0.17157757 -0.38247916  0.03366767 -0.06901115  0.02437839  0.21487622\n",
      "  -0.13875681  0.02971414]]\n",
      "\n",
      "\n",
      "iter:  92\n",
      "loss:  0.22754851\n",
      "gradient:  [[-0.02545433  0.01708519 -0.04731319 -0.01875751  0.00641377 -0.01401853\n",
      "   0.0261335   0.04952183]]\n",
      "latent:  [[-0.17163552 -0.3833064   0.03387847 -0.06777783  0.02476704  0.21575671\n",
      "  -0.13874094  0.02925817]]\n",
      "\n",
      "\n",
      "iter:  93\n",
      "loss:  0.22709554\n",
      "gradient:  [[-0.01071232  0.01585421 -0.02870965 -0.01698478 -0.00162307 -0.01806645\n",
      "   0.0157896   0.03532029]]\n",
      "latent:  [[-0.17167166 -0.38413027  0.03410753 -0.06656181  0.02512469  0.21661206\n",
      "  -0.13876645  0.02878106]]\n",
      "\n",
      "\n",
      "iter:  94\n",
      "loss:  0.22689462\n",
      "gradient:  [[ 0.02630331  0.01005292  0.01494247 -0.01454067 -0.01513695 -0.03242867\n",
      "  -0.00955499  0.00806632]]\n",
      "latent:  [[-0.17174457 -0.38492432  0.03429469 -0.06537478  0.02550307  0.2174888\n",
      "  -0.13876528  0.02833429]]\n",
      "\n",
      "\n",
      "iter:  95\n",
      "loss:  0.22724742\n",
      "gradient:  [[ 0.01650642  0.00872668  0.00474737 -0.01433162 -0.00782585 -0.02806119\n",
      "  -0.00074954  0.01802079]]\n",
      "latent:  [[-0.17183591 -0.38568532  0.03445764 -0.06421497  0.02587405  0.21837163\n",
      "  -0.13876231  0.0278965 ]]\n",
      "\n",
      "\n",
      "iter:  96\n",
      "loss:  0.22767782\n",
      "gradient:  [[ 0.01184187  0.00773324  0.00073486 -0.0134833  -0.00499765 -0.02489313\n",
      "   0.00282028  0.02083912]]\n",
      "latent:  [[-0.17193687 -0.38641182  0.03460411 -0.06308439  0.02622813  0.21925038\n",
      "  -0.13876686  0.02746148]]\n",
      "\n",
      "\n",
      "iter:  97\n",
      "loss:  0.22771046\n",
      "gradient:  [[ 0.00294194  0.00552919 -0.00753208 -0.01221223  0.00189758 -0.01984995\n",
      "   0.01072812  0.02820731]]\n",
      "latent:  [[-0.17203279 -0.38709652  0.03474694 -0.0619873   0.0265415   0.22010991\n",
      "  -0.13879864  0.02701521]]\n",
      "\n",
      "\n",
      "iter:  98\n",
      "loss:  0.2279074\n",
      "gradient:  [[ 0.00243426  0.00405203 -0.00636278 -0.01105139  0.00318629 -0.01802947\n",
      "   0.01219311  0.02814896]]\n",
      "latent:  [[-0.17212339 -0.38773626  0.03488492 -0.06092706  0.02681315  0.22094652\n",
      "  -0.13885899  0.02655869]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  99\n",
      "loss:  0.22815445\n",
      "gradient:  [[-0.02147033  0.00587276 -0.03407558 -0.01221112  0.01566565 -0.00893831\n",
      "   0.03055935  0.04863702]]\n",
      "latent:  [[-0.17217161 -0.38834444  0.03505668 -0.05989313  0.02699992  0.2217332\n",
      "  -0.13899279  0.02605529]]\n",
      "\n",
      "\n",
      "iter:  100\n",
      "loss:  0.22814742\n",
      "gradient:  [[-0.01413757  0.00758977 -0.02641983 -0.01247861  0.00817761 -0.01188352\n",
      "   0.02207174  0.03999974]]\n",
      "latent:  [[-0.17219292 -0.38893268  0.03524863 -0.05888123  0.02713808  0.22248451\n",
      "  -0.13917115  0.02552521]]\n",
      "\n",
      "\n",
      "total evaluatios = 100\n",
      "gradient at stop position = tensor([[-0.0141,  0.0076, -0.0264, -0.0125,  0.0082, -0.0119,  0.0221,  0.0400]]),\n",
      "modified graident = tensor([[ 0.0213,  0.5882, -0.1919, -1.0119, -0.1382, -0.7513,  0.1784,  0.5301]])\n",
      "found minimum position = [[-0.17219292 -0.38893268  0.03524863 -0.05888123  0.02713808  0.22248451\n",
      "  -0.13917115  0.02552521]], found minimum = 0.22865165770053864\n",
      "Result:  local minimum\n",
      "found minimum: 0.22865164279937744, minimum position: [[-0.17219292 -0.38893268  0.03524863 -0.05888123  0.02713808  0.22248451\n",
      "  -0.13917115  0.02552521]], evals: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('local minimum', tensor(0.2287, grad_fn=<AddBackward0>), 100)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init and setup one experiment\n",
    "exp = single_experiment()\n",
    "# One experiment: setup objective function\n",
    "objectiveDe = decoder_obj(latent_target, decoder)\n",
    "exp.set_objective(objectiveDe)\n",
    "opt = adam(dim=8)\n",
    "optParas = {\n",
    "         'x0': latent,\n",
    "         'alpha': 0.001,\n",
    "         'beta_1': 0.9, \n",
    "         'beta_2': 0.999, \n",
    "         'epsilon': 1e-11, \n",
    "         'max_iter': 100,\n",
    "         'tol': 1e-6,              \n",
    "         'verbose': True,\n",
    "         'record': False }\n",
    "opt.set_parameters(optParas)\n",
    "exp.set_optimizer(opt)\n",
    "exp.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init and setup one experiment\n",
    "exp = single_experiment()\n",
    "# One experiment: setup objective function\n",
    "objectiveDe = decoder_obj(latent_target, decoder)\n",
    "exp.set_objective(objectiveDe)\n",
    "opt = adam(dim=8)\n",
    "optParas = {\n",
    "         'x0': latent,\n",
    "         'alpha': 0.001,\n",
    "         'beta_1': 0.9, \n",
    "         'beta_2': 0.999, \n",
    "         'epsilon': 1e-11, \n",
    "         'max_iter': 100,\n",
    "         'tol': 1e-6,              \n",
    "         'verbose': True,\n",
    "         'record': False }\n",
    "opt.set_parameters(optParas)\n",
    "exp.set_optimizer(opt)\n",
    "exp.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*******starting optimisation from intitial mean:  [-0.16573758 -0.303306    0.026367   -0.15115654 -0.02860292  0.15756649\n",
      " -0.1368305   0.04584491]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Surface level must be within volume data range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-be316c8775e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptParas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Non-convex/library/experiments.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moptimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_optimal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_optimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-bc48b6cdb482>\u001b[0m in \u001b[0;36moptimise\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx_ascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-f5a0090b05f9>\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(self, latent)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# from latent to xyz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_sdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_mesh_optim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_MARCHING_CUBE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mverts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mverts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Non-convex/deep_sdf/mesh.py\u001b[0m in \u001b[0;36mcreate_mesh_optim\u001b[0;34m(decoder, latent_vec, N, max_batch, offset, scale)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mvoxel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Non-convex/deep_sdf/mesh.py\u001b[0m in \u001b[0;36mconvert_sdf_samples_to_mesh\u001b[0;34m(pytorch_3d_sdf_tensor, voxel_grid_origin, voxel_size, offset, scale)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     verts, faces, normals, values = skimage.measure.marching_cubes_lewiner(\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mnumpy_3d_sdf_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvoxel_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ada/lib/python3.7/site-packages/skimage/measure/_marching_cubes_lewiner.py\u001b[0m in \u001b[0;36mmarching_cubes_lewiner\u001b[0;34m(volume, level, spacing, gradient_direction, step_size, allow_degenerate, use_classic)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Surface level must be within volume data range.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;31m# spacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspacing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Surface level must be within volume data range."
     ]
    }
   ],
   "source": [
    "# init and setup one experiment\n",
    "exp = single_experiment()\n",
    "# One experiment: setup objective function\n",
    "objectiveDe = decoder_obj(latent_target, decoder)\n",
    "exp.set_objective(objectiveDe)\n",
    "opt = cma_es(dim=8)\n",
    "optParas ={'x0': latent,\n",
    "           'std': torch.ones((8,)) * 0.0003, \n",
    "           'tol': 1e-3, \n",
    "           'adjust_func': do_nothing(), \n",
    "           'record': False, \n",
    "           'verbose': True}\n",
    "opt.set_parameters(optParas)\n",
    "exp.set_optimizer(opt)\n",
    "exp.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-ada] *",
   "language": "python",
   "name": "conda-env-miniconda3-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
