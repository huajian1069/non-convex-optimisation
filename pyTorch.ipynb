{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from library.objective_function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.experiments import *\n",
    "from library.objective_function import *\n",
    "from library.optimiser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*******starting optimisation from intitial point:  tensor([164.2300,  23.5230], grad_fn=<SqueezeBackward0>)\n",
      "total evaluatios = 185\n",
      "gradient at stop position = tensor([-6.4603e-05, -6.4827e-04]),\n",
      "modified graident = tensor([ 6.2634e-05, -1.9428e-07])\n",
      "found minimum position = tensor([164.0000,  24.0000], requires_grad=True), found minimum = 20.0\n",
      "Result:  local minimum\n",
      "found minimum: 20.0, minimum position: [163.99998   23.999987], evals: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huajian/miniconda3/envs/ada/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('local minimum', tensor(20., grad_fn=<AddBackward0>), 185)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init and setup one experiment\n",
    "exp = single_experiment()\n",
    "# One experiment: setup objective function\n",
    "ak = ackley()\n",
    "exp.set_objective(ak)\n",
    "ad = adam()\n",
    "optParas = {\n",
    "         'x0': torch.tensor([164.23, 23.523], requires_grad=True),\n",
    "         'alpha': 0.1,\n",
    "         'beta_1': 0.9, \n",
    "         'beta_2': 0.999, \n",
    "         'epsilon': 1e-11, \n",
    "         'max_iter': 2000,\n",
    "         'tol': 1e-6,              \n",
    "         'verbose': True,\n",
    "         'record': False }\n",
    "ad.set_parameters(optParas)\n",
    "exp.set_optimizer(ad)\n",
    "exp.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class line_search(adjust_optimizer):\n",
    "    def __init__(self, alpha=1, beta=0.1):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.max_iter = 100\n",
    "        self.tol = 1e-2\n",
    "        self.verbose = False\n",
    "        self.record = False\n",
    "     \n",
    "    def set_parameters(self, paras):\n",
    "        self.paras = paras\n",
    "        self.x0 = paras['x0']\n",
    "        self.alpha = paras['alpha']\n",
    "        self.beta = paras['beta']\n",
    "        self.max_iter = paras['max_iter']\n",
    "        self.tol = paras['tol']\n",
    "        self.verbose = True if 'verbose' not in paras.keys() else paras['verbose']\n",
    "        self.record = True if 'record' not in paras.keys() else paras['record']\n",
    "    def optimise(self, obj):\n",
    "        '''\n",
    "        @param x0: initial point position\n",
    "        @param alpha: initial step size\n",
    "        @param beta: control the armijo condition\n",
    "        @return x: point position after moving to local minimum\n",
    "        '''\n",
    "        x = self.x0\n",
    "        alpha_ = self.alpha\n",
    "        tao = 0.5\n",
    "        fx = obj.func(x)\n",
    "        p = - obj.dfunc(x)\n",
    "        fnx = obj.func(x + alpha_ * p)\n",
    "        eval_cnt = 3\n",
    "        stats = {}\n",
    "        stats['status'] = None\n",
    "        stats['gradient'] = []\n",
    "        stats['arg'] = []\n",
    "        stats['val'] = []\n",
    "        if self.record:\n",
    "            stats['arg'].append(x.clone())\n",
    "            stats['val'].append(fx)\n",
    "            stats['gradient'].append(-p)\n",
    "        if self.verbose:\n",
    "            print(\"\\n*******starting optimisation from intitial point: \", self.x0.squeeze())\n",
    "        for k in range(self.max_iter):\n",
    "            while fnx > fx + alpha_ * self.beta * (-p @ p):\n",
    "                alpha_ *= tao\n",
    "                fnx = obj.func(x + alpha_ * p)\n",
    "                eval_cnt += 1\n",
    "            with torch.no_grad():\n",
    "                x += alpha_ * p\n",
    "            fx = fnx\n",
    "            x = x.clone()\n",
    "            x = torch.tensor(x, requires_grad=True)\n",
    "            p = -obj.dfunc(x)\n",
    "            print(p, obj.dfuncR(x))\n",
    "            fnx = obj.func(x + alpha_ * p)\n",
    "            eval_cnt += 2\n",
    "            if self.record:\n",
    "                stats['arg'].append(x.clone())\n",
    "                #print(eval_cnt, stats['arg'])\n",
    "                stats['val'].append(fx)\n",
    "                stats['gradient'].append(-p)\n",
    "            if torch.norm(p) < self.tol:\n",
    "                break\n",
    "        stats['evals'] = eval_cnt\n",
    "        if self.verbose:\n",
    "            print('total evaluatios = {}'.format(eval_cnt))\n",
    "            print('gradient at stop position = {}'.format(-p))\n",
    "            print('found minimum position = {}, found minimum = {}'.format(x, fx))\n",
    "        stats['arg'] = np.array(stats['arg'])\n",
    "        stats['val'] = np.array(stats['val'])\n",
    "        stats['gradient'] = np.array(stats['gradient'])\n",
    "        return x, fnx, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = __import__(\"library.optimiser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*******starting optimisation from intitial point:  tensor([16.2300, 23.0230], grad_fn=<SqueezeBackward0>)\n",
      "tensor([4.8368, 1.3211]) tensor([-4.8368, -1.3211], grad_fn=<AddBackward0>)\n",
      "tensor([-2.0730, -0.6880]) tensor([2.0730, 0.6880], grad_fn=<AddBackward0>)\n",
      "tensor([1.3317, 0.4499]) tensor([-1.3317, -0.4499], grad_fn=<AddBackward0>)\n",
      "tensor([-0.8813, -0.2996]) tensor([0.8813, 0.2996], grad_fn=<AddBackward0>)\n",
      "tensor([0.5912, 0.2014]) tensor([-0.5912, -0.2014], grad_fn=<AddBackward0>)\n",
      "tensor([-0.3982, -0.1357]) tensor([0.3982, 0.1357], grad_fn=<AddBackward0>)\n",
      "tensor([0.2690, 0.0917]) tensor([-0.2690, -0.0917], grad_fn=<AddBackward0>)\n",
      "tensor([-0.1817, -0.0620]) tensor([0.1817, 0.0620], grad_fn=<AddBackward0>)\n",
      "tensor([0.1229, 0.0418]) tensor([-0.1229, -0.0418], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0831, -0.0282]) tensor([0.0831, 0.0282], grad_fn=<AddBackward0>)\n",
      "tensor([0.0562, 0.0192]) tensor([-0.0562, -0.0192], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0380, -0.0130]) tensor([0.0380, 0.0130], grad_fn=<AddBackward0>)\n",
      "tensor([0.0258, 0.0088]) tensor([-0.0258, -0.0088], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0175, -0.0058]) tensor([0.0175, 0.0058], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0028, -0.0009]) tensor([0.0028, 0.0009], grad_fn=<AddBackward0>)\n",
      "tensor([-0.0005, -0.0002]) tensor([0.0005, 0.0002], grad_fn=<AddBackward0>)\n",
      "total evaluatios = 41\n",
      "gradient at stop position = tensor([0.0005, 0.0002])\n",
      "found minimum position = tensor([15.9994, 22.9992], requires_grad=True), found minimum = 19.61959457397461\n",
      "Result:  local minimum\n",
      "found minimum: 19.61959457397461, minimum position: [15.999435 22.99918 ], evals: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huajian/miniconda3/envs/ada/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('local minimum', tensor(19.6196, grad_fn=<AddBackward0>), 41)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init and setup one experiment\n",
    "exp = single_experiment()\n",
    "# One experiment: setup objective function\n",
    "ak = ackley()\n",
    "exp.set_objective(ak)\n",
    "ln = line_search()\n",
    "optParas = {\n",
    "    'x0': torch.tensor([16.23, 23.023], requires_grad=True),\n",
    "    'alpha': 1,\n",
    "    'beta': 0.1, \n",
    "    'max_iter': 1000,\n",
    "    'tol': 1e-3,              \n",
    "    'verbose': True,\n",
    "    'record': False\n",
    "}\n",
    "ln.set_parameters(optParas)\n",
    "exp.set_optimizer(ln)\n",
    "exp.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init and setup one experiment\n",
    "exp = single_experiment()\n",
    "# One experiment: setup objective function\n",
    "ak = ackley()\n",
    "exp.set_objective(ak)\n",
    "ln = line_search()\n",
    "optParas = {\n",
    "    'x0': torch.tensor([16.23, 23.023], requires_grad=True),\n",
    "    'alpha': 1,\n",
    "    'beta': 0.1, \n",
    "    'max_iter': 1000,\n",
    "    'tol': 1e-3,              \n",
    "    'verbose': True,\n",
    "    'record': False\n",
    "}\n",
    "ln.set_parameters(optParas)\n",
    "exp.set_optimizer(ln)\n",
    "exp.do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1000e-05,  2.1000e-05], requires_grad=True)\n",
      "tensor(2.8224e-09, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class nns(nn.Module):\n",
    "    def __init__(self):\n",
    "         super(nns, self).__init__()\n",
    "    def forward(self, x):\n",
    "        y = torch.sum(3.2 * x**2);\n",
    "        print(x)\n",
    "        print(y)\n",
    "        return y\n",
    "ns = nns()\n",
    "x = torch.tensor([-0.000021, 0.000021], requires_grad=True)\n",
    "out = ns(x)\n",
    "y = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0001,  0.0001])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(retain_graph=True)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([x], lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.9884e-08,  9.9884e-08], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimizer.zero_grad()\n",
    "x_pre = x.clone()\n",
    "optimizer.step()\n",
    "x_pre - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9970,  0.0180], requires_grad=True)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out1).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20., 20.], requires_grad=True)\n",
      "tensor(2560., grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'Tensor' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-b1b596e0aeb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'Tensor' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "xn = torch.tensor([out, out], requires_grad=True)\n",
    "out1 = ns(xn) * xn.grad\n",
    "out1.backward()\n",
    "xn.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.6000, 12.8000])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(8).unsqueeze(0).reshape(-1,1)@torch.zeros(8).unsqueeze(0).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(8, dtype=torch.float32).unsqueeze(0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 27.42778432, -24.42778432]),\n",
       " array([[ 0.78291993, -0.77104454],\n",
       "        [ 0.62212248,  0.63678121]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=torch.eig(torch.tensor(x,dtype=float), eigenvectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7829, -0.7710],\n",
       "        [ 0.6221,  0.6368]], dtype=torch.float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([True]).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2]).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathcal{L}_{new} = \\sum_{v \\in V}{ \\left( -\\frac{\\partial \\mathcal{L}_{task}}{\\partial v} \\nabla f_{\\theta}(v, z) \\right) f_{\\theta}(v,z)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.load(\"/Users/huajian/Downloads/MinimalDeepSDF/data/loss.npy\")\n",
    "lambdas = np.load(\"/Users/huajian/Downloads/MinimalDeepSDF/data/lambdas.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3wddZ3/8dcnJ9fm3ua0zaVp09JCS4GWhoogiMqlKlJUdIF1F1Z98FtXVnfdXcXVH7s/XHdZ/a0rPh6oyyqu/lSQlXWtCouAoFyENoXSK6X3Nk0vSZvmfs/n98eZpCfpSZrQTk7a834+HueRM9+ZOfPJtMk735n5zpi7IyIiMlxasgsQEZHJSQEhIiIJKSBERCQhBYSIiCSkgBARkYQUECIiklCoAWFmK8xsq5ltN7O7Esy/3czqzWxd8Pp43LzbzGxb8LotzDpFROREFtY4CDOLAG8A1wC1wBrgFnffHLfM7UC1u985bN2pQA1QDTiwFljm7o0jba+kpMTnzJlzmr8LEZGz29q1axvcPZpoXnqI210ObHf3nQBm9jCwEtg86lox1wFPuvvRYN0ngRXAQyOtMGfOHGpqak65aBGRVGJme0aaF+YhpnJgX9x0bdA23AfNbL2Z/dTMZo1nXTO7w8xqzKymvr7+dNUtIiKEGxCWoG348axfAHPc/ULgKeD741gXd3/A3avdvToaTdhDEhGRNynMgKgFZsVNVwB18Qu4+xF37wom/x1YNtZ1RUQkXGEGxBpgvplVmVkmcDOwKn4BMyuNm7wB2BK8fwK41syKzawYuDZoExGRCRLaSWp37zWzO4n9Yo8AD7r7JjO7B6hx91XAp8zsBqAXOArcHqx71My+RCxkAO4ZOGEtIiITI7TLXCdadXW16yomEZHxMbO17l6daJ5GUouISEIpHxDNnT18/ak3eG3fsWSXIiIyqaR8QLjD15/axprdOsUhIhIv5QOiIDudzPQ06lu7Tr6wiEgKSfmAMDOieVnUtyggRETipXxAAJTkKyBERIZTQIB6ECIiCSgggGh+Fg06ByEiMoQCglhAHGnrprevP9mliIhMGgoIYgHhDkfbu5NdiojIpKGAIHYOAtB5CBGROAoIYj0IUECIiMRTQADTFRAiIidQQAAlA4eYdCWTiMggBQSQkxkhLytdPQgRkTgKiEBUo6lFRIZQQAQ0mlpEZCgFRCCan6VzECIicRQQgWh+Fg3qQYiIDAo1IMxshZltNbPtZnbXKMvdZGZuZtXB9Bwz6zCzdcHr22HWCbGAaO7spbOnL+xNiYicEdLD+mAziwD3A9cAtcAaM1vl7puHLZcPfAp4edhH7HD3JWHVN9zAaOqG1i4qiqdM1GZFRCatMHsQy4Ht7r7T3buBh4GVCZb7EvAVoDPEWk5Ko6lFRIYKMyDKgX1x07VB2yAzWwrMcvdfJli/ysxeNbPfmtkVIdYJKCBERIYL7RATYAnafHCmWRrwr8DtCZY7AFS6+xEzWwb8t5md7+7NQzZgdgdwB0BlZeUpFavR1CIiQ4XZg6gFZsVNVwB1cdP5wGLgWTPbDVwKrDKzanfvcvcjAO6+FtgBLBi+AXd/wN2r3b06Go2eUrHT8jIB9SBERAaEGRBrgPlmVmVmmcDNwKqBme7e5O4l7j7H3ecALwE3uHuNmUWDk9yY2VxgPrAzxFrJiKQxNTdTASEiEgjtEJO795rZncATQAR40N03mdk9QI27rxpl9SuBe8ysF+gD/tTdj4ZV6wCNphYROS7McxC4+2PAY8Pa7h5h2avi3j8KPBpmbYloNLWIyHEaSR0nmp9FgwJCRARQQAwxcEdXdz/5wiIiZzkFRJxoXhadPf20dvUmuxQRkaRTQMTRYDkRkeMUEHEGB8spIEREFBDxBnsQOlEtIqKAiKdDTCIixykg4hTlZJCeZgoIEREUEEOkpRklGk0tIgIoIE6gwXIiIjEKiGF0uw0RkRgFxDC6YZ+ISIwCYpjYIaZu+vt1uw0RSW0KiGFK8jLp63ca27uTXYqISFIpIIaJ5mcDGiwnIqKAGEaD5UREYhQQwyggRERiFBDDKCBERGIUEMPkZkbIyYhosJyIpLxQA8LMVpjZVjPbbmZ3jbLcTWbmZlYd1/b5YL2tZnZdmHUOq2XwyXIiIqksPawPNrMIcD9wDVALrDGzVe6+edhy+cCngJfj2hYBNwPnA2XAU2a2wN37wqo3nkZTi4iE24NYDmx3953u3g08DKxMsNyXgK8AnXFtK4GH3b3L3XcB24PPmxAaTS0iEm5AlAP74qZrg7ZBZrYUmOXuvxzvumEqyc9UQIhIygszICxB2+D9K8wsDfhX4K/Gu27cZ9xhZjVmVlNfX/+mCx0umpdNY3sP3b39p+0zRUTONGEGRC0wK266AqiLm84HFgPPmtlu4FJgVXCi+mTrAuDuD7h7tbtXR6PR01b49ILYpa66kklEUlmYAbEGmG9mVWaWSeyk86qBme7e5O4l7j7H3ecALwE3uHtNsNzNZpZlZlXAfGB1iLUOMT0YC3FYh5lEJIWFdhWTu/ea2Z3AE0AEeNDdN5nZPUCNu68aZd1NZvYIsBnoBT45UVcwwfHBcoebO0+ypIjI2Su0gABw98eAx4a13T3CslcNm/4y8OXQihvF9OCGfepBiEgq00jqBEryMjHT7TZEJLUpIBJIj6QxLTdTPQgRSWkKiBFE87Opb9E5CBFJXQqIEUTzs9SDEJGUpoAYwfT8LA43KyBEJHUpIEYwPT+LhtYu+vtPGMAtIpISFBAjmJ6fRW+/09jenexSRESSQgExgqjGQohIilNAjGDgfkwKCBFJVQqIEUzX7TZEJMUpIEag222ISKpTQIwgJzNCfna6ehAikrIUEKMoK8yhrkkBISKpSQExitKibA40dSS7DBGRpFBAjKK0MJsDx9SDEJHUpIAYRWlhDkfauunsmbBnFYmITBoKiFGUFsauZDqkE9UikoIUEKMoK8oBoE6HmUQkBSkgRjHQg9CJahFJRaEGhJmtMLOtZrbdzO5KMP9PzWyDma0zs+fNbFHQPsfMOoL2dWb27TDrHElpYawHcUCXuopICkoP64PNLALcD1wD1AJrzGyVu2+OW+zH7v7tYPkbgK8BK4J5O9x9SVj1jUVOZoSiKRnqQYhISgqzB7Ec2O7uO929G3gYWBm/gLs3x03mApPu4QulhTm61FVEUlKYAVEO7Iubrg3ahjCzT5rZDuArwKfiZlWZ2atm9lszuyLEOkdVVpit0dQikpLCDAhL0HZCD8Hd73f3ecDngC8GzQeASndfCnwG+LGZFZywAbM7zKzGzGrq6+tPY+nHaTS1iKSqMAOiFpgVN10B1I2y/MPAjQDu3uXuR4L3a4EdwILhK7j7A+5e7e7V0Wj0tBUer7Qwh2PtPXR0a7CciKSWMANiDTDfzKrMLBO4GVgVv4CZzY+bfC+wLWiPBie5MbO5wHxgZ4i1jqisSJe6ikhqCu0qJnfvNbM7gSeACPCgu28ys3uAGndfBdxpZlcDPUAjcFuw+pXAPWbWC/QBf+ruR8OqdTQzC45f6jo3mpeMEkREkiK0gABw98eAx4a13R33/tMjrPco8GiYtY3VQA+i7ph6ECKSWjSS+iRmDo6m1pVMIpJaFBAnkZUeoSQvU+cgRCTlKCDGoLQwRz0IEUk5CogxmKkHB4lIClJAjEFsNLUOMYlIalFAjEFpUQ4tnb20dvUmuxQRkQmjgBiDwedC6FJXEUkhCogxGHiynE5Ui0gqUUCMgZ4sJyKpSAExBjMKsjHTs6lFJLWMKSDM7NNmVmAx3zWzV8zs2rCLmywyImlE87LUgxCRlDLWHsRHg6e/XQtEgT8B7g2tqkmotEiD5UQktYw1IAYe/vMe4Hvu/hqJHwh01iorzFZAiEhKGWtArDWzXxMLiCfMLB/oD6+sySf2bOoO3CfdY7NFREIx1tt9fwxYAux093Yzm0rsMFPKKC3Mpq27j+bOXgpzMpJdjohI6Mbag3grsNXdj5nZR4g9O7opvLImn1I9WU5EUsxYA+JbQLuZXQR8FtgD/CC0qiah0sJgsJwudRWRFDHWgOj12MH3lcB97n4fkB9eWZPP8WdTKyBEJDWM9RxEi5l9Hvgj4AoziwApdSB+en42kTTTISYRSRlj7UH8AdBFbDzEQaAc+GpoVU1CkTRjRn6WRlOLSMoYU0AEofAjoNDMrgc63f2k5yDMbIWZbTWz7WZ2V4L5f2pmG8xsnZk9b2aL4uZ9Plhvq5ldN47vKTQzC7PVgxCRlDHWW218GFgNfAj4MPCymd10knUiwP3Au4FFwC3xARD4sbtf4O5LgK8AXwvWXQTcDJwPrAC+GXxeUmk0tYikkrEeYvoCcIm73+bufwwsB/73SdZZDmx3953u3g08TOwk96Dg9h0DcoGBUWgrgYfdvcvddwHbg89LqrKgB6HBciKSCsYaEGnufjhu+sgY1i0H9sVN1wZtQ5jZJ81sB7EexKfGue4dZlZjZjX19fUn/y5OUWlhDp09/TS294S+LRGRZBtrQPyPmT1hZreb2e3Ar4DHTrJOons1nfCnt7vf7+7zgM8RG4A3nnUfcPdqd6+ORqMnKefUVU6dAsCeI22hb0tEJNnGepL6b4AHgAuBi4AH3P1zJ1mtFpgVN10B1I2y/MPAjW9y3QkxpyQXgN0KCBFJAWMdB4G7Pwo8Oo7PXgPMN7MqYD+xk863xi9gZvPdfVsw+V5g4P0q4Mdm9jWgDJhP7CR5UlVOnUKawa56BYSInP1GDQgzayHBoR1ih4Dc3QtGWtfde83sTuAJIAI86O6bzOweoMbdVwF3mtnVQA/QCNwWrLvJzB4BNgO9wCfdvW/8397plZmeRnlxDruOtCe7FBGR0I0aEO5+SrfTcPfHGHauwt3vjnv/6VHW/TLw5VPZfhjmTMtld4N6ECJy9tMzqcdp9rQp7D2qHoSInP0UEONUXjSFpo4eWrt6k12KiEioFBDjVFEcu+33/kbdckNEzm4KiHEqHwiIYzrMJCJnNwXEOFUUxQKiVj0IETnLKSDGqSQvi8z0NB1iEpGzngJinNLSjNlTp7D9cGuySxERCZUC4k24oKKQ12qbdFdXETmrKSDehIsqimho7dKzIUTkrKaAeBMumlUEwPraY0muREQkPAqIN2FhaT4ZEWPdvqZklyIiEhoFxJuQlR5hYWmBehAiclZTQLxJF1YUsqG2if5+nagWkbOTAuJNuqiiiJauXt443JLsUkREQqGAeJPeNr8EgN9uTfws7KNt3ewbdtfXfUfbWbfvGI1t3UPaWzp7aGzrpr1bNwAUkcljzE+Uk6FKC3M4b2Y+//T46xTnZjJ/eh4XVhSRZnCsvYcb73+BvUfbOb+sgHNn5LOjvpXXamMntXMyIrx9QZQllUVsqmvmsQ0H6Ot3cjIifPH6hdy6vBKzRI/lHpumjh521rfS2N5NmhlpZkTSDDPIjKQRzc9iRkE22RmR07U7ROQsZGfLYK/q6mqvqamZ0G3+xwu7+PtfbB7Sdu6MfI60ddHU0cMdV87lhe1H2FHfyvzpeVw6dxpLK4v51fo6avY0UtvYQV5WOjctq6CiOIentxzm9zuPMC+ay5xpubxl7lQONHWydk8jB5s6KSvK4brzZ3LNoum4w5G2bvYeaedYRzc769tir4ZWGlq7R6h4qILsdIpzMymakklRTgZFUzKCr5kUTcmgMCeD7t5+8rMziOZnMbMgm8ppU8LYlSKSJGa21t2rE85TQJyaI61dfPwHNby69/gVTdWzi7n7fYu4sKJo1HWPtnWTmxUhKz32l3x/v/PoK7X897r97Kpvo66pk5yMCIvLC5g9LZcd9a1DthNvWm4mc6O5zC3Ji32N5jEtLxN3cHf6Hfr6ne6+fupbujjU3Mnh5k6OdfRwrL2HY+3dg++bO3sY6b/FLctn8Y/vvwAz4we/3813ntvFP77/gsFDbhDbzp4jbcyN5o1vZ4rIhFNATIDu3n4aWrsoycsiI2KndIgIYr/Umzt7yctKJ5J2/LPeONTCpromMiJp5GamMy+aR0FOOkVTMk/1WxjU1+80d/RwrKOHjIjR2tVLfUsXj204yEOr9/L4p6+grDCHy+59mrbuPiqKc3jus+8Y/J6/9MvNfPf5Xfzd+xbxJ5dXnba6ROT0Gy0gQj0HYWYrgPuACPAdd7932PzPAB8HeoF64KPuvieY1wdsCBbd6+43hFnrqcpMT6MsuBX46WBmFOZknNC+YEY+C2ac0qPCTyqSZhTnZlKcezx0zpsJhTkZPLR6L/uOtrP1YAtt3X3csrySh1bvZVNdM4vLC9m4v4nvPr8LgK8+sZVbllfqXIfIGSq0q5jMLALcD7wbWATcYmaLhi32KlDt7hcCPwW+Ejevw92XBK9JHQ6porQwFoAHmjpZX9tEdkYan7lmAWkGT285DMDfr9pESV4W9996Me3dfTy3rSGZJYvIKQjzMtflwHZ33+nu3cDDwMr4Bdz9GXcfuBb0JaAixHrkFE3LzSQzkkZdUwfra4+xuKyQaH4WVSW5bKxrorWrl5o9jfzxW2dz7fkzKMhO56nNh4DYIbPvPLeTv/3ZBl3OK3KGCDMgyoF9cdO1QdtIPgY8HjedbWY1ZvaSmd2YaAUzuyNYpqa+PvF4BDl90tKMmYXZ1B7tYFNd8+BJ+IWlBWw50MzWg7FBg4tKC8iIpLG8aiprdh8FYOuhFv7hV1v48ct7eWLTwcHPdHe++N8beKRm34kbFJGkCjMgEp2lTXhG3Mw+AlQDX41rrgxOnNwKfN3M5p3wYe4PuHu1u1dHo9HTUbOcRGlhNi/vOkpHTx8LS2PnQhaWFlDb2EFNEAbnzoy1V8+Zys6GNo60dvF83KGmJ4NeBcD62iZ++NJePvvT9by888gEficicjJhBkQtMCtuugKoG76QmV0NfAG4wd27BtrdvS74uhN4FlgaYq0yRuVFOTS0xv6Zzpkeu4x1ICh+9up+cjMjlAcn66tnFwOwdk8jv9vWwDnT87j1LZX8dms9PX39APz3uv2Dnx0fHCKSfGEGxBpgvplVmVkmcDOwKn4BM1sK/BuxcDgc115sZlnB+xLgcmDoiDRJigUzj19BNRAQS2bFguD1gy0sKisgLbgsd3F5IZmRNF7Y3sDLO49wxfwSLp9XQlt3H5vqmunrd37x2gGuO38Gl82bxvPbdUJbZDIJLSDcvRe4E3gC2AI84u6bzOweMxu4KumrQB7wn2a2zswGAmQhUGNmrwHPAPe6uwJiEnjnedMH3+dnxy7DnZobG3kN8I64+dkZES6sKOT7v99DV28/V8wv4ZKqWJis3nWEF3c00NDaxY1Lyrn8nBJeP9gyeJ+q1w8283c/38gLCg2RpAl1HIS7PwY8Nqzt7rj3V4+w3ovABWHWJm/O/KDXkBkZ+rfFOdE8avY0cvXCGUPal80ppmZPIwBvqZpGblY6c0tyeWLTIZ7acpjiKRm847zpTNl1/GT2JXOm8mc/eoWd9W08teUwz/7NVWREdF9JkYmmnzoZFzPjN3/1dp75m6uGtH/jlqXc+4ELBgNkwPUXlHHujHzu/cAF5GbF/h75k7dVsXZPI6t3HeWvrzuX7IwI5waD/9441MJTWw6xs76Nm5ZVsP9YB49vjF311NrVy7ee3UF3b3/436iI6G6uMn6J7rFUVpTDzcsrT2i/oKKQJ/7yyiFtty6v5MCxDuZMy+VD1bGhLzMKsijMyeD1gy1sqG2iIDudf/rABfx600F+v6OBGy4q419+vZXvvbCbsqJsVi4Z7Yrps09nTx/NHT0cbe/m1b3HmJabyd6j7Ww71Eprdy8d3X20d/fS0dNPdnoat76lkhsuKjvlW75IalNAyISLpBmfXXHekDYz49wZ+Wzc30R9Sxdvm19CRiSNZbOLqdkdO0T1SnCo6o1DZ+dDmjq6+2ho7eJIWzfbDrXw3LYGDjV3sqO+jaaObnr6TrxKvCQvi4KcdKZkRpiSkU5hTga1je18+uF1rFpXx8feVsX+Yx0cbumitDCb7t5+SotymFuSC0BxbiZPbznEvqPtLK0s5rJ50xQqMkgBIZPGtefP4B9+tQWAT8+PjWupnjOVZ7Zu5eWdR9iwP/Y8jZHuaDvZNbZ18+q+RgzjpZ1H2FHfxpG2Lo60dtPQ2kV7d9+Q5WcWZFNRnMM7zo1Skp9FeVEOaWZcPLso9ou+MIdoftYJ2+nrd777/E7ue2obT79++IT58cwYcufeiuIcyotyKMnPoq/POdDcyeKyAq6/sIzlVVOH3DhSzn66m6tMGp09faz4+u+YF83j/j+8mOyMCDvrW3n3fc/R1dtPTkaEd5wX5ZnX6/nt31wFBtG8rEn5F293bz+PvlLLpromDjZ1su9oB9sOtzDwCPOMiDEvmkdJXhYleZlMy8tiWl7m4PTMghwWluaf2oOj2nt4ZV8jZYU5zCzI5mh7N5npadQebWdXQxtdvf0caOrkHedGOb+8kMc2HODZrYdpaIkFVr87ZUU5vLr3GB09fWREjKm5mcwsyOac6flcuaCE2dNyqSrJJTsjbfC29XJm0e2+5YzR09d/whVLj284wPde3M2tyyu5oKKQ99z3HD19/fQ7LJlVxA8+tpyC7BPvfDsRjrV384v1B9h6sJlDzV28ti/2y7Stq5d+h/ysdMqLc6gozmFhaQGXnxM7dDYvmntab9EepvbuXp7ecpjNB5o50trFgaZONu5vorG9Z8hyRVMyeO8FpVx+TglVJbnMn55Huq4+m/QUEHJWeWrzIR5avZfCnAx+/lodbzunhK99+CL2BsfRIXaYpaOnj7zgyqnevn6e295Ad28/RTkZFORkUN/SxbGOHuZFc9l2qJXuvn7ed2EZOZmJ/xJu6+ply4FmHqnZx476NvY3dnCwuROA3MwIXb39vPfCUqbmZpKXlc7Fs4u5akF0UvZwTlVfv7PlQDO1jR3UNrbT1dvPG4da+J+NB+kKrjIryE7n+ovKuGzeNK47f6YuVZ6kFBBy1np49V7+9mcbBg/d/NU1C8jLTufBF3ax72gHU3MzKcnLZN/RDjp6+kb/MGK/1LIyIvT3OzmZEfKy0plekE3dsQ52N7TR2+/kZkZYXF5IWVEO587M5y1VU1kyq4iu3v6Uf/ZFS2fP4OG0X28+xLOvH6atu49ZU3O4cn6UqxfO4OLKYgqnJKfHJydSQMhZ7ekth7j755vYf6xjsG3JrCKuWTSD2sYO6lu6qJw6hbfOm0ZpYTZNwaNVp+VlUpiTwbbDrVROnUJ7Vy/f/t1OstPTKMnPoqM7dmnpvsZ2qkpymRfN4/yyQt5+bnSwZyKj6+3r5/GNsScRrt51lN5+J5JmLKssZunsIq44J8rl5+jKqWRSQEhK6OnrZ3NdM/nZ6VSV5OqXziRzsKmTXQ1t/G5bPb/fcYRNdU309DkXVRTyuRXncdk5JSf/EDntFBAiMul0dPfxi/V1fP3JN6hr6qSiOId3L57JpXOncaS1m7Q0Izsjjez0CMW5mSwuL9CVUiFQQIjIpNXZ08d/vbKf37x+iN++UZ9wQOCAnIwIhTkZRNKMoikZvOeCUm5ZXsnU3DPjirDJSAEhImeEpo4eth9uoSQvizQzOnv66OjpY39jB9sOt9Lc0UNTRw997tQe7WD17qNkpqexuKyAty+YzkcurWRa3omDB2VkCggROSttO9TCD1/aw/r9Tby69xiZ6Wl8YGk5t18+h3NnnNpAw1ShgBCRs972wy08+MJuHl1bS1dvP0VTMlg6q4jSohzKCrOZF83j0rnTKNbhqCEUECKSMo62dfOrDQdYt/cYrx9s5kBTJ0eDB1GZweypUyjMyaCieArnzsznjy6dndKhoYAQkZTW2RN7zO2L2xvYcrCZY+09sctuj7SRkZbGBRWFXFxZxPllhVx7/gymZKbOOJfRAiJ19oKIpKzsjAjLZhezbHbxkPbXDzbz6Npa1u5p5Psv7qG7r5+s9DTeOm8a1yyawYeWzSIzPXVvEaIehIgIsftLrd3TyOMbD/Ds1np2NbRRVZLLP3/wQpZXTU12eaEZrQcRajSa2Qoz22pm283srgTzP2Nmm81svZk9bWaz4+bdZmbbgtdtYdYpIhJJM5ZXTeXv3nc+z/z1VfzHn1yCu/OR77zMd5/flZKPug2tB2FmEeAN4BqgFlgD3OLum+OWeQfwsru3m9kngKvc/Q/MbCpQA1QDDqwFlrl740jbUw9CRE63pvYe/uInr/LM1noKstN5/9JyPnzJLBbOLMCMs+Iy2mSdg1gObHf3nUERDwMrgcGAcPdn4pZ/CfhI8P464El3Pxqs+ySwAngoxHpFRIYonJLBg7dfwnPbGvjZq/v54ct7+f7v9ww+iW/OtCm8fUE09oyP6Xlcu2jGWTVQL8yAKAf2xU3XAm8ZZfmPAY+Psu4JT6k3szuAOwAqKytPpVYRkYTMjCsXRLlyQZS73n0ez29rYFdDGwCb6pp4pKaWvn6nu6+fL/xsA8urplI9eyofrp5F5bQpSa7+1IQZEIn6XgmPZ5nZR4gdTnr7eNZ19weAByB2iOnNlSkiMjYzCrL54LKKIW3ujju8frCF/9l4gCc2HeJbv93Bv/1uBzdcVM4Hl5Vz2bwz8061YQZELTArbroCqBu+kJldDXwBeLu7d8Wte9WwdZ8NpUoRkVNgZpjBorICFpUV8Jlrz+VQcyffeHobq16r49FXavn0u+bzl9csSHap4xbmVUxrgPlmVmVmmcDNwKr4BcxsKfBvwA3ufjhu1hPAtWZWbGbFwLVBm4jIpDejIJsvv/8C1nzhaj54cQX3Pb2NF7c3JLuscQstINy9F7iT2C/2LcAj7r7JzO4xsxuCxb4K5AH/aWbrzGxVsO5R4EvEQmYNcM/ACWsRkTNFdkaEL79/MRXFOXzx5xtp6exJdknjooFyIiIhe3FHA3/03dWsvKiMr/3BkmSXM0TSBsqJiAhcNq+Ej19Rxc/W7Wf74ZZklzNmCggRkQlwxxVzyctK53OPbqC378wYla2AEBGZANPysviHGxezdk8j33x2R7LLGRMFhIjIBFm5pJwbLirjvqe3sXbP5L/uRgEhIjKB/qOWyI0AAApjSURBVOH9iykryuZTD62jqWNyX9WkgBARmUAF2Rl84+alHGzu5N7HX092OaNSQIiITLCllcX88Vtn85M1e9lc15zsckakgBARSYK/eNcCCnIy+N8/38iR1q6Tr5AECggRkSQonJLB3dcvYt2+Y3zo27+nvbs32SWdQAEhIpIkH7i4gh98dDm7jrTxgW++yOHmzmSXNIQCQkQkiS4/p4Rv/eEyth1u5Xsv7k52OUMoIEREkmzF4pm887zp/GfNvkn17GsFhIjIJHDr8koaWrt5cvOhZJcySAEhIjIJXLkgSnlRDg+t3pvsUgYpIEREJoFImvHBZRW8sKOBA00dyS4HUECIiEwa719ajjv8tKY22aUACggRkUmjqiSXd503nW8+u4N9R9uTXY4CQkRkMrnnxsWkGdz1X+uT/twIBYSIyCRSXpTDF69fxAvbj/BnP3qFvv7kPRY61IAwsxVmttXMtpvZXQnmX2lmr5hZr5ndNGxen5mtC16rwqxTRGQyuWV5JV9870J+vfkQf7dqIz1J6kmkh/XBZhYB7geuAWqBNWa2yt03xy22F7gd+OsEH9Hh7pPr6d4iIhPkY2+r4nBLFw/8bieZkQh3v2/RhNcQWkAAy4Ht7r4TwMweBlYCgwHh7ruDeZNn6KCIyCRgZvztexbS1dPHgy/s4rzSfD5cPWtCawjzEFM5sC9uujZoG6tsM6sxs5fM7MZEC5jZHcEyNfX19adSq4jIpPS3713IFfNLuOvR9fzitboJ3XaYAWEJ2sZztqXS3auBW4Gvm9m8Ez7M/QF3r3b36mg0+mbrFBGZtLLSIzzwR9VUz5nKX/xkHf+z8eCEbTvMgKgF4vtDFcCY48/d64KvO4FngaWnszgRkTNFTmaEB2+/hAsrCrnzx6/w2IYDE7LdMANiDTDfzKrMLBO4GRjT1UhmVmxmWcH7EuBy4s5diIikmrysdH7w0eVcNKuIP3/oVR6fgJAILSDcvRe4E3gC2AI84u6bzOweM7sBwMwuMbNa4EPAv5nZpmD1hUCNmb0GPAPcO+zqJxGRlJOfncH3P7qcCysK+eyj6zncEu4Dhsw9eYMwTqfq6mqvqalJdhkiIqHbWd/Kiq8/x8KyAn708beQl/XmL0g1s7XB+d4TaCS1iMgZZm40j/v/8GLW1x7j3se3hLYdBYSIyBnomkUzuP2yOfzo5b1sPdgSyjYUECIiZ6hPvXM+uZnpfOM320L5/DBHUouISIiKczP5xFXz6Ojuw90xSzT87M1TQIiInME++Y5zQvtsHWISEZGEFBAiIpKQAkJERBJSQIiISEIKCBERSUgBISIiCSkgREQkIQWEiIgkdNbczdXM6oE9p/ARJUDDaSrndFJd46O6xmey1gWTt7azra7Z7p7wkZxnTUCcKjOrGemWt8mkusZHdY3PZK0LJm9tqVSXDjGJiEhCCggREUlIAXHcA8kuYASqa3xU1/hM1rpg8taWMnXpHISIiCSkHoSIiCSkgBARkYRSPiDMbIWZbTWz7WZ2V5Jr2W1mG8xsnZnVBG1TzexJM9sWfC2eoFoeNLPDZrYxri1hLRbzjWAfrjeziye4rr83s/3BfltnZu+Jm/f5oK6tZnZdiHXNMrNnzGyLmW0ys08H7UndZ6PUldR9ZmbZZrbazF4L6vo/QXuVmb0c7K+fmFlm0J4VTG8P5s+Z4Lr+w8x2xe2vJUH7hP3fD7YXMbNXzeyXwXS4+8vdU/YFRIAdwFwgE3gNWJTEenYDJcPavgLcFby/C/jnCarlSuBiYOPJagHeAzwOGHAp8PIE1/X3wF8nWHZR8G+aBVQF/9aRkOoqBS4O3ucDbwTbT+o+G6WupO6z4PvOC95nAC8H++ER4Oag/dvAJ4L3fwZ8O3h/M/CTkPbXSHX9B3BTguUn7P9+sL3PAD8GfhlMh7q/Ur0HsRzY7u473b0beBhYmeSahlsJfD94/33gxonYqLv/Djg6xlpWAj/wmJeAIjMrncC6RrISeNjdu9x9F7Cd2L95GHUdcPdXgvctwBagnCTvs1HqGsmE7LPg+24NJjOClwPvBH4atA/fXwP78afAu8xO8wOYR69rJBP2f9/MKoD3At8Jpo2Q91eqB0Q5sC9uupbRf3jC5sCvzWytmd0RtM1w9wMQ+2EHpietupFrmQz78c6gi/9g3GG4pNQVdOeXEvvrc9Lss2F1QZL3WXC4ZB1wGHiSWG/lmLv3Jtj2YF3B/CZg2kTU5e4D++vLwf76VzPLGl5XgppPt68DnwX6g+lphLy/Uj0gEiVqMq/7vdzdLwbeDXzSzK5MYi3jkez9+C1gHrAEOAD8S9A+4XWZWR7wKPAX7t482qIJ2kKrLUFdSd9n7t7n7kuACmK9lIWjbDtpdZnZYuDzwHnAJcBU4HMTWZeZXQ8cdve18c2jbPu01JXqAVELzIqbrgDqklQL7l4XfD0M/IzYD82hgS5r8PVwsuobpZak7kd3PxT8UPcD/87xQyITWpeZZRD7Jfwjd/+voDnp+yxRXZNlnwW1HAOeJXYMv8jM0hNse7CuYH4hYz/UeKp1rQgO1bm7dwHfY+L31+XADWa2m9ih8HcS61GEur9SPSDWAPODKwEyiZ3MWZWMQsws18zyB94D1wIbg3puCxa7Dfh5MuoLjFTLKuCPgys6LgWaBg6rTIRhx3zfT2y/DdR1c3BFRxUwH1gdUg0GfBfY4u5fi5uV1H02Ul3J3mdmFjWzouB9DnA1sfMjzwA3BYsN318D+/Em4DcenIGdgLpejwt5I3acP35/hf7v6O6fd/cKd59D7PfUb9z9Dwl7f4V1tv1MeRG7CuENYsc/v5DEOuYSu3rkNWDTQC3Ejhs+DWwLvk6doHoeInbooYfYXyMfG6kWYt3Z+4N9uAGonuC6/l+w3fXBD0Zp3PJfCOraCrw7xLreRqwLvx5YF7zek+x9NkpdSd1nwIXAq8H2NwJ3x/0crCZ2cvw/gaygPTuY3h7MnzvBdf0m2F8bgR9y/EqnCfu/H1fjVRy/iinU/aVbbYiISEKpfohJRERGoIAQEZGEFBAiIpKQAkJERBJSQIiISEIKCJFTYGYvBl/nmNmtya5H5HRSQIicAne/LHg7BxhXQJhZ5LQXJHIaKSBEToGZDdz5817giuBZAX8Z3PDtq2a2JrjB2/8Klr/KYs9n+DGwIRhB/yuLPX9go5n9QdK+GZFh0k++iIiMwV3Enq9wPUBwN94md78kuPPnC2b262DZ5cBid99lZh8E6tz9vcF6hckoXiQR9SBEwnEtsXv0rCN2e+1pxO5rBLDaY89agNjtGa42s382syvcvSkJtYokpIAQCYcBf+7uS4JXlbsP9CDaBhZy9zeAZcSC4p/M7O4k1CqSkAJC5PRoIfZIzwFPAJ8IbrWNmS0I7tI7hJmVAe3u/kPg/xJ7nKrIpKBzECKnx3qg18xeI/b84vuIXdn0SnCL6HoSPy72AuCrZtZP7A61n5iQakXGQHdzFRGRhHSISUREElJAiIhIQgoIERFJSAEhIiIJKSBERCQhBYSIiCSkgBARkYT+PzIfuVwtV4qyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"iters\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'lambdas')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambdas)\n",
    "plt.xlabel(\"iters\")\n",
    "plt.ylabel(\"lambdas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## toy neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [4875503568, 4875501808, 4873249888, 4873249088, 4873249648, 4874232848, 4873015456, 4874298864, 4870762976, 4870766016]}]\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.01352374, dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.state_dict()['conv1.weight'][0,1,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'latent_codes'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## neural network weights\n",
    "all_codes = torch.load(\"../MinimalDeepSDF/example1/LatentCodes/latest.pth\", map_location=torch.device(\"cpu\"))\n",
    "all_codes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codes['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3412, -0.4759, -0.1524,  0.0231,  0.1486,  0.3323, -0.1601, -0.1239])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sphere\n",
    "sphere = all_codes['latent_codes']['weight'][999]\n",
    "sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sphere.unsqueeze(0).detach().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0562, -0.2882,  0.1230,  0.2264,  0.0941,  0.1983,  0.1402, -0.1180])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torsus\n",
    "torsus = all_codes['latent_codes']['weight'][2]\n",
    "torsus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([sphere.unsqueeze(0), torsus.reshape(1,-1)], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1588, -0.3376,  0.0932, -0.0402,  0.1580,  0.2382, -0.0432, -0.0909],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best got by Adam \n",
    "PATH399 = \"/Users/huajian/Downloads/MinimalDeepSDF/example1/Optimizations/750/Codes/399.pth\"\n",
    "code399 = torch.load(PATH399).squeeze()\n",
    "code399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15883543, -0.33760908,  0.09318182, -0.0401662 ,  0.15800397,\n",
       "        0.2382426 , -0.04322775, -0.09089346], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code399.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3747, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance between found optimum and initial guess\n",
    "(code399 - sphere).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3535, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance between found optimum and global minimum\n",
    "(code399 - torsus).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4913, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(code399,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4841)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torsus,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7349)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(sphere,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,10,1, out=torch.LongTensor())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1588, -0.3376,  0.0932, -0.0402,  0.1580,  0.2382, -0.0432, -0.0909],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1,2]).grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remark:\n",
    "direction is consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2851,  0.1876,  0.2754,  0.2032, -0.0545, -0.1340,  0.3002,  0.0058])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target direction\n",
    "torsus - sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1824,  0.1383,  0.2456, -0.0633,  0.0094, -0.0941,  0.1168,  0.0330],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code399 - sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1801, grad_fn=<DotBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torsus - sphere).dot(code399 - sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/huajian/Downloads/MinimalDeepSDF/example1/Optimizations/750/Codes'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(PATH399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3412, -0.4759, -0.1524,  0.0231,  0.1486,  0.3323, -0.1601,\n",
       "          -0.1239]]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code of sphere\n",
    "PATH0 = \"/Users/huajian/Downloads/MinimalDeepSDF/example1/Optimizations/750/Codes/0.pth\"\n",
    "code0 = torch.load(PATH0, map_location=torch.device('cpu'))\n",
    "code0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code0.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3412, -0.4759, -0.1524,  0.0231,  0.1486,  0.3323, -0.1601,\n",
       "          -0.1239, -0.3412, -0.4759, -0.1524,  0.0231,  0.1486,  0.3323,\n",
       "          -0.1601, -0.1239]],\n",
       "\n",
       "        [[-0.3412, -0.4759, -0.1524,  0.0231,  0.1486,  0.3323, -0.1601,\n",
       "          -0.1239, -0.3412, -0.4759, -0.1524,  0.0231,  0.1486,  0.3323,\n",
       "          -0.1601, -0.1239]]], grad_fn=<RepeatBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code0.repeat(2,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3412, -0.4759, -0.1524,  0.0231,  0.1486,  0.3323, -0.1601,\n",
       "          -0.1239]],\n",
       "\n",
       "        [[-0.3412, -0.4759, -0.1524,  0.0231,  0.1486,  0.3323, -0.1601,\n",
       "          -0.1239]]], grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code0.expand(2,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3412]],\n",
       "\n",
       "        [[-0.4759]],\n",
       "\n",
       "        [[-0.1524]],\n",
       "\n",
       "        [[ 0.0231]],\n",
       "\n",
       "        [[ 0.1486]],\n",
       "\n",
       "        [[ 0.3323]],\n",
       "\n",
       "        [[-0.1601]],\n",
       "\n",
       "        [[-0.1239]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code0.transpose(2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinimalDeepSDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python optim.py -s example1/synth_test.json -e example1\n",
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = __import__(\"library.optimiser\", globals(), fromlist=[\"do_nothing\", \"cma_es\"])\n",
    "m.cma_es()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## neural network weights\n",
    "saved_model_state = torch.load(\"../MinimalDeepSDF/example1/ModelParameters/latest.pth\", map_location=torch.device(\"cpu\"))\n",
    "saved_model_state[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(saved_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## mass code representation of torus\n",
    "split = json.load(open(\"../MinimalDeepSDF/example1/synth_test.json\", \"r\"))\n",
    "type(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codes = torch.load(\"../MinimalDeepSDF/example1/LatentCodes/latest.pth\")['latent_codes']['weight']\n",
    "type(all_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 8])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = all_codes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codes[0].detach().requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= 8e-3\n",
    "l2reg= True\n",
    "decreased_by = 1.5    \n",
    "adjust_lr_every = 50\n",
    "\n",
    "N_MARCHING_CUBE = 64\n",
    "regl2 = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$lr_t = lr_0  (\\frac{1}{\\alpha})^{\\frac{t}{t_p}}$\n",
    "\n",
    "$lr_t = 8e^{-3} (\\frac{1}{1.5})^{\\frac{t}{50}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright 2004-present Facebook. All Rights Reserved.\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import deep_sdf\n",
    "import deep_sdf.workspace as ws\n",
    "\n",
    "import pdb\n",
    "\n",
    "def adjust_learning_rate(initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every):\n",
    "    lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "def chamfer_distance(p1, p2):\n",
    "    '''\n",
    "    Calculate Chamfer Distance between two point sets\n",
    "    '''\n",
    "\n",
    "    p1 = p1.unsqueeze(0)\n",
    "    p2 = p2.unsqueeze(0)\n",
    "\n",
    "    p1 = p1.repeat(p2.size(1), 1, 1)\n",
    "    p1 = p1.transpose(0, 1)\n",
    "\n",
    "    p2 = p2.repeat(p1.size(0), 1, 1)\n",
    "\n",
    "    # compute distance tensor\n",
    "    dist = torch.add(p1, torch.neg(p2))\n",
    "    dist = torch.norm(dist, 2, dim=2)\n",
    "\n",
    "    dist1, _ = torch.min(dist, dim = 1)\n",
    "    dist2, _ = torch.min(dist, dim = 0)\n",
    "\n",
    "    return torch.mean(dist1) + torch.mean(dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    arg_parser = argparse.ArgumentParser(\n",
    "        description=\"Use a trained DeepSDF decoder to reconstruct a shape given SDF samples.\"\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"--experiment\",\n",
    "        \"-e\",\n",
    "        dest=\"experiment_directory\",\n",
    "        required=True,\n",
    "        help=\"The experiment directory which includes specifications and saved model \"\n",
    "        + \"files to use for reconstruction\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"--checkpoint\",\n",
    "        \"-c\",\n",
    "        dest=\"checkpoint\",\n",
    "        default=\"latest\",\n",
    "        help=\"The checkpoint weights to use. This can be a number indicating an epoch \"\n",
    "        + \"or 'latest' for the latest weights (this is the default)\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"--split\",\n",
    "        \"-s\",\n",
    "        dest=\"split_filename\",\n",
    "        required=True,\n",
    "        help=\"The split to reconstruct.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"--iters\",\n",
    "        dest=\"iterations\",\n",
    "        default=400,\n",
    "        help=\"The number of iterations of latent code optimization to perform.\",\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    # Initialization\n",
    "    N_MARCHING_CUBE = 64\n",
    "    deep_sdf.add_common_args(arg_parser)\n",
    "    args = arg_parser.parse_args()\n",
    "    deep_sdf.configure_logging(args)\n",
    "\n",
    "    specs_filename = os.path.join(args.experiment_directory, \"specs.json\")\n",
    "\n",
    "    if not os.path.isfile(specs_filename):\n",
    "        raise Exception(\n",
    "            'The experiment directory does not include specifications file \"specs.json\"'\n",
    "        )\n",
    "\n",
    "    specs = json.load(open(specs_filename))\n",
    "    arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
    "    latent_size = specs[\"CodeLength\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Load decoder: this is our black box function\n",
    "    decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "    decoder = torch.nn.DataParallel(decoder)\n",
    "    saved_model_state = torch.load(\n",
    "        os.path.join(\n",
    "            args.experiment_directory, ws.model_params_subdir, args.checkpoint + \".pth\"\n",
    "        ),\n",
    "        map_location=torch.device('cpu') # Remove this if you want to run on GPU\n",
    "    )\n",
    "    saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "    decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "    # Optionally: put decoder on GPU\n",
    "    #decoder = decoder.module.cuda()\n",
    "\n",
    "\n",
    "    ## read by here\n",
    "\n",
    "    logging.debug(decoder)\n",
    "    optimization_dir = os.path.join(\n",
    "        args.experiment_directory, ws.optimizations_subdir, str(saved_model_epoch)\n",
    "    )\n",
    "\n",
    "    if not os.path.isdir(optimization_dir):\n",
    "        os.makedirs(optimization_dir)\n",
    "\n",
    "    optimization_meshes_dir = os.path.join(\n",
    "        optimization_dir, ws.optimizations_meshes_subdir\n",
    "    )\n",
    "    if not os.path.isdir(optimization_meshes_dir):\n",
    "        os.makedirs(optimization_meshes_dir)\n",
    "\n",
    "    optimization_codes_dir = os.path.join(\n",
    "        optimization_dir, ws.optimizations_codes_subdir\n",
    "    )\n",
    "    if not os.path.isdir(optimization_codes_dir):\n",
    "        os.makedirs(optimization_codes_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    lr= 8e-3\n",
    "    l2reg= True\n",
    "    decreased_by = 1.5\n",
    "    adjust_lr_every = 50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # pick initialization and samples\n",
    "    # Load collection of all latent codes\n",
    "    all_codes_path = os.path.join(\n",
    "        args.experiment_directory,\n",
    "        ws.latent_codes_subdir,\n",
    "        'latest.pth')\n",
    "    all_codes = torch.load(all_codes_path)['latent_codes']['weight']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    source_id = 999 # zywvjkvz2492e6xpq4hd1jzy2r9lht        # This will be the source shape (ie starting point)\n",
    "    latent = all_codes[source_id].unsqueeze(0).detach()#.cuda()   #Add .cuda() if you want to run on GPU\n",
    "    latent.requires_grad = True\n",
    "\n",
    "    target_id = 2 # 0bucd9ryckhaqtqvbiagilujeqzek4          # This is be the target shape (ie objective)\n",
    "    latent_target = all_codes[target_id].unsqueeze(0).detach()#.cuda()   #Add .cuda() if you want to run on GPU\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get a mesh representation of the target shape\n",
    "    verts_target, faces_target = deep_sdf.mesh.create_mesh_optim(\n",
    "        decoder, latent_target, N=N_MARCHING_CUBE, max_batch=int(2 ** 18)\n",
    "    )\n",
    "\n",
    "    # Store the mesh\n",
    "    mesh_filename = os.path.join(optimization_meshes_dir, \"target\") + \".ply\"\n",
    "    if not os.path.exists(os.path.dirname(mesh_filename)):\n",
    "        os.makedirs(os.path.dirname(mesh_filename))\n",
    "    deep_sdf.mesh.write_verts_faces_to_file(verts_target, faces_target, mesh_filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam([latent], lr=lr)\n",
    "\n",
    "    losses = []\n",
    "    lambdas = []\n",
    "\n",
    "    verts_target_sample = verts_target[torch.randperm(verts_target.shape[0])]\n",
    "    verts_target_sample = verts_target_sample[0:20000, :]\n",
    "    np.save(os.path.join(optimization_meshes_dir, \"target_verts.npy\"), verts_target_sample)\n",
    "\n",
    "    regl2 = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "    # first show latent interpolation form source to target for reference\n",
    "    for i in range(21):\n",
    "        alpha = i/20\n",
    "        print(\"interpolate at:\", alpha)\n",
    "        latent_interp = alpha*latent_target + (1-alpha)*latent\n",
    "        verts, faces = deep_sdf.mesh.create_mesh_optim(\n",
    "            decoder, latent_interp, N=N_MARCHING_CUBE, max_batch=int(2 ** 18)\n",
    "        )\n",
    "        mesh_filename = os.path.join(optimization_meshes_dir, \"interpolation_\" + str(i)) + \".ply\"\n",
    "        if not os.path.exists(os.path.dirname(mesh_filename)):\n",
    "            os.makedirs(os.path.dirname(mesh_filename))\n",
    "        deep_sdf.mesh.write_verts_faces_to_file(verts, faces, mesh_filename)\n",
    "\n",
    "\n",
    "\n",
    "    # Use Adam optimizer, with source as starting point, and a loss defined on meshes\n",
    "    # latent is the input of our function\n",
    "    print(\"Starting optimization:\")\n",
    "    for e in range(args.iterations):\n",
    "\n",
    "\n",
    "        # Get a point cloud sampling of the target shape\n",
    "        verts_target_sample = verts_target[torch.randperm(verts_target.shape[0])]\n",
    "        verts_target_sample = verts_target_sample[0:20000, :]\n",
    "        xyz_target = torch.tensor(verts_target_sample.astype(float), requires_grad = False, dtype=torch.float32) # For GPU, add: , device=torch.device('cuda:0'))\n",
    "\n",
    "        decoder.eval()\n",
    "        adjust_learning_rate(lr, optimizer, e, decreased_by, adjust_lr_every)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        # Get a mesh representation of our current guess: decoder is evaluated at position latent\n",
    "        # first create mesh running full forward pass\n",
    "        verts, faces = deep_sdf.mesh.create_mesh_optim(\n",
    "            decoder, latent, N=N_MARCHING_CUBE, max_batch=int(2 ** 18)\n",
    "        )\n",
    "        end = time.time()\n",
    "        print(\"time to mesh:\", end-start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # store the current mesh for visualization\n",
    "        mesh_filename   = os.path.join(optimization_meshes_dir, str(e) + \".ply\")\n",
    "        latent_filename = os.path.join(optimization_codes_dir,  str(e) + \".pth\")\n",
    "\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(mesh_filename)):\n",
    "            os.makedirs(os.path.dirname(mesh_filename))\n",
    "        deep_sdf.mesh.write_verts_faces_to_file(verts, faces, mesh_filename)\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(latent_filename)):\n",
    "            os.makedirs(os.path.dirname(latent_filename))\n",
    "        torch.save(latent.unsqueeze(0), latent_filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # subsample vertices for gradients computations\n",
    "        verts = verts[torch.randperm(verts.shape[0])]\n",
    "        verts = verts[0:20000, :]\n",
    "        start = time.time()\n",
    "        # forward pass within loss layer\n",
    "        xyz_upstream = torch.tensor(verts.astype(float), requires_grad = True, dtype=torch.float32)#, device=torch.device('cuda:0')) # For GPU,\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        # At this point we have 2 outputs for decoder: the target xyz_target, and the current value xyz_upstream\n",
    "        # The following lines compute a loss and backpropagate\n",
    "\n",
    "        # compute loss function: Chamfer between current guess (xyz_upstream) and objective (xyz_target)\n",
    "        loss = chamfer_distance(xyz_upstream, xyz_target)\n",
    "        print(\"Loss at iter\", e, \":\", loss.item(), \", latent norm: \", torch.norm(latent) )\n",
    "        losses.append(loss.detach().cpu().numpy())                                  ## Loss value\n",
    "        #np.save(os.path.join(optimization_meshes_dir, \"log.npy\"), losses)\n",
    "        lambdas.append(torch.norm(latent_target-latent).detach().cpu().numpy())     ## Distance in the domain\n",
    "        #np.save(os.path.join(optimization_meshes_dir, \"lambda.npy\"), lambdas)\n",
    "        \n",
    "\n",
    "\n",
    "        # now store upstream gradients\n",
    "        loss.backward()\n",
    "        dL_dx_i = xyz_upstream.grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # use vertices to compute full backward pass\n",
    "        xyz = torch.tensor(verts.astype(float), requires_grad = True,dtype=torch.float32)#, device=torch.device('cuda:0')) # For GPU,\n",
    "        latent_inputs = latent.expand(xyz.shape[0], -1)\n",
    "        inputs = torch.cat([latent_inputs, xyz], 1)#.cuda()      #Add .cuda() if you want to run on GPU\n",
    "        #first compute normals\n",
    "        pred_sdf = decoder(inputs)\n",
    "\n",
    "\n",
    "\n",
    "        loss_normals = torch.sum(pred_sdf)\n",
    "        loss_normals.backward(retain_graph = True)\n",
    "        normals = xyz.grad/torch.norm(xyz.grad, 2, 1).unsqueeze(-1)\n",
    "        # now assemble inflow derivative\n",
    "        optimizer.zero_grad()\n",
    "        dL_ds_i_fast = -torch.matmul(dL_dx_i.unsqueeze(1), normals.unsqueeze(-1)).squeeze(-1)\n",
    "        loss_backward = torch.sum(dL_ds_i_fast * pred_sdf)\n",
    "\n",
    "\n",
    "\n",
    "        if e % 20 == 0 and e > 0:\n",
    "            regl2 = regl2/2\n",
    "        if l2reg:\n",
    "            loss_backward+= regl2* torch.mean(latent.pow(2))\n",
    "\n",
    "\n",
    "        # Backpropagate\n",
    "        loss_backward.backward()\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"time to backward:\", end-start)\n",
    "\n",
    "        # update latent\n",
    "        # Explicit gradient is accessible via latent.grad\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-ada] *",
   "language": "python",
   "name": "conda-env-miniconda3-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
