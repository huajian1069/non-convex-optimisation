{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "import skimage.measure\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import (NNConv, GMMConv, GraphConv, Set2Set)\n",
    "from torch_geometric.nn import (SplineConv, graclus, max_pool, max_pool_x, global_mean_pool)\n",
    "\n",
    "import plyfile\n",
    "from plyfile import PlyData\n",
    "import trimesh\n",
    "#from neuralnet_pytorch.metrics import chamfer_loss\n",
    "\n",
    "import trimesh\n",
    "\n",
    "#from visualization_utils import plot_mesh_3d\n",
    "\n",
    "import deep_sdf\n",
    "import deep_sdf.workspace as ws\n",
    "#from models import *\n",
    "#from datasets import *\n",
    "#from custom_utils import *\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from pyntcloud import PyntCloud\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAvgTransform():\n",
    "    objects = list()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(\"/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/transforms/\"):\n",
    "        objects += [os.path.join(dirpath, file) for file in filenames if file[-4:] == '.npy']\n",
    "    \n",
    "    matricies = []\n",
    "    for obj in objects:\n",
    "        matricies.append(np.load(obj))\n",
    "    \n",
    "    return np.mean(np.array(matricies), axis=0)\n",
    "\n",
    "def transformPoints(points, matrix):\n",
    "    matrix = torch.cuda.FloatTensor(matrix)\n",
    "    column = torch.zeros((len(points), 1), device=\"cuda:0\") + 1\n",
    "    stacked = torch.cat([points, column], dim=1)\n",
    "    transformed = torch.matmul(matrix, stacked.T).T[:, :3]\n",
    "    return transformed\n",
    "\n",
    "def make_mesh_from_points(points, ply_mesh):\n",
    "    transformed_points = transformPoints(points, AvgTransform)\n",
    "    \n",
    "    edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
    "    np_points = transformed_points.cpu().detach().numpy()\n",
    "    edge_attr = [np_points[a] - np_points[b] for a, b in edges]\n",
    "\n",
    "    data = torch_geometric.data.Data(x   = transformed_points, \n",
    "                                     pos = transformed_points, \n",
    "                                     face = torch.tensor(ply_mesh['face']['vertex_indices'], \n",
    "                                                         dtype=torch.long).to('cuda:0').t(),\n",
    "                                     edge_attr=torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "                                     edge_index=torch.tensor(edges, dtype=torch.long).t().contiguous().to('cuda:0'))\n",
    "    return data\n",
    "\n",
    "\n",
    "def compute_volume(vertices_in, faces_in):\n",
    "\n",
    "    bs, nv = vertices_in.shape[:2]\n",
    "    bs, nf = faces_in.shape[:2]\n",
    "    device = vertices_in.device\n",
    "    faces = faces_in + (torch.arange(bs, dtype=torch.int32).to(device) * nv)[:, None, None]\n",
    "    vertices = vertices_in #.reshape((bs * nv / 2, 3))\n",
    "    # pytorch only supports long and byte tensors for indexing\n",
    "    face_coordinates = vertices[faces.long()].squeeze(0)\n",
    "\n",
    "    x1y2z3 = face_coordinates[:,0,0]*face_coordinates[:,1,1]*face_coordinates[:,2,2]\n",
    "    x2y1z3 = face_coordinates[:,1,0]*face_coordinates[:,0,1]*face_coordinates[:,2,2]\n",
    "    x3y1z2 = face_coordinates[:,2,0]*face_coordinates[:,0,1]*face_coordinates[:,1,2]\n",
    "    x1y3z2 = face_coordinates[:,0,0]*face_coordinates[:,2,1]*face_coordinates[:,1,2]\n",
    "    x2y3z1 = face_coordinates[:,1,0]*face_coordinates[:,2,1]*face_coordinates[:,0,2]\n",
    "    x3y2z1 = face_coordinates[:,2,0]*face_coordinates[:,1,1]*face_coordinates[:,0,2]\n",
    "\n",
    "    V = x1y2z3 - x2y1z3 + x3y1z2 - x1y3z2 + x2y3z1 - x3y2z1\n",
    "    return 1.0/6.0*torch.abs(torch.sum(V))\n",
    "\n",
    "def compute_lift_faces_diff(data_instance, answers, axis=0):\n",
    "    pressures = torch.mean(answers[data_instance.face, 0], axis=0)\n",
    "\n",
    "    # TODO: cahnge to x if needed\n",
    "    pos = data_instance.x\n",
    "    cross_prod = (pos[data_instance.face[1]] - pos[data_instance.face[0]]).cross(\n",
    "                  pos[data_instance.face[2]] - pos[data_instance.face[0]])\n",
    "    mult = -cross_prod[:, axis] / 2\n",
    "    lift = torch.mul(pressures, mult)\n",
    "    return torch.sum(lift[~torch.isnan(lift)])\n",
    "\n",
    "def boundsLoss(points, box=[(-1, 1, 0)]):\n",
    "    loss = 0\n",
    "    for l, r, i in box:\n",
    "        loss +=  torch.mean(F.relu(-points[:, i] + l))  \\\n",
    "               + torch.mean(F.relu( points[:, i] - r))\n",
    "    return loss\n",
    "\n",
    "def innerBoundsLoss(points, r=1, center=(0, 0, 0)):\n",
    "    radiuses = torch.sum( (points - torch.Tensor(center).to('cuda:0')) ** 2 , dim=1)\n",
    "    return torch.mean(F.relu(r - radiuses))\n",
    "\n",
    "def calculate_loss(mesh, local_preds, axis=0, constraint_rad=0.1):\n",
    "    loss =  (1 - axis) * compute_lift_faces_diff(mesh, local_preds, axis=0) + \\\n",
    "                  axis * compute_lift_faces_diff(mesh, local_preds, axis=1)\n",
    "    \n",
    "    loss += boundsLoss(mesh.x, box=[(-0.6, 0.6, 0)])\n",
    "    loss += innerBoundsLoss(mesh.x, r=constraint_rad**2, center=(-0.05, 0.05, 0))  \\\n",
    "          + innerBoundsLoss(mesh.x, r=(constraint_rad / 2)**2, center=(0.3, 0, 0))\n",
    "    \n",
    "\n",
    "    return loss\n",
    "def get_trimesh_from_torch_geo_with_colors(mesh, preds, vmin=-8, vmax=8):\n",
    "    norm = mpl.colors.Normalize(vmin= vmin, vmax=vmax)\n",
    "    cmap = cm.hot\n",
    "    m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    \n",
    "    verticies = mesh.x.cpu().detach()\n",
    "    faces = mesh.face.t().cpu().detach()\n",
    "    return trimesh.Trimesh(vertices=verticies, faces=faces, \n",
    "                           vertex_colors=list(map(lambda c: m.to_rgba(c),  preds[:, 0].cpu().detach())))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineBlock(nn.Module):\n",
    "    def __init__(self, num_in_features, num_outp_features, mid_features, kernel=3, dim=3, batchnorm1=True):\n",
    "        super(SplineBlock, self).__init__()\n",
    "        self.batchnorm1 = batchnorm1\n",
    "        self.conv1 = SplineConv(num_in_features, mid_features, dim, kernel, is_open_spline=False)\n",
    "        if self.batchnorm1:\n",
    "            self.batchnorm1 = torch.nn.BatchNorm1d(mid_features)\n",
    "        self.conv2 = SplineConv(mid_features, 2 * mid_features, dim, kernel, is_open_spline=False)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm1d(2 * mid_features)\n",
    "        self.conv3 = SplineConv(2 * mid_features + 3, num_outp_features, dim, kernel, is_open_spline=False)\n",
    "  \n",
    "    def forward(self, res, data):\n",
    "        if self.batchnorm1:\n",
    "            res = F.elu(self.batchnorm1(self.conv1(res, data.edge_index, data.edge_attr)))\n",
    "        else:\n",
    "            res = F.elu(self.conv1(res, data.edge_index, data.edge_attr))\n",
    "        res = F.elu(self.batchnorm2(self.conv2(res, data.edge_index, data.edge_attr)))\n",
    "#         res = F.elu(self.conv2(res, data.edge_index, data.edge_attr))\n",
    "        res = torch.cat([res, data.pos], dim=1)\n",
    "        res = self.conv3(res, data.edge_index, data.edge_attr)\n",
    "        return res\n",
    "\n",
    "class SplineCNN8Residuals(nn.Module):\n",
    "    def __init__(self, num_features, kernel=3, dim=3):\n",
    "        super(SplineCNN8Residuals, self).__init__()\n",
    "        self.block1 = SplineBlock(num_features, 16, 8, kernel, dim)\n",
    "        self.block2 = SplineBlock(16, 64, 32, kernel, dim)\n",
    "        self.block3 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block4 = SplineBlock(64, 8, 16, kernel, dim)\n",
    "        self.block5 = SplineBlock(11, 32, 16, kernel, dim)\n",
    "        self.block6 = SplineBlock(32, 64, 32, kernel, dim)\n",
    "        self.block7 = SplineBlock(64, 64, 128, kernel, dim)\n",
    "        self.block8 = SplineBlock(75, 4, 16, kernel, dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        res = data.x\n",
    "        res = self.block1(res, data)\n",
    "        res = self.block2(res, data)\n",
    "        res = self.block3(res, data)\n",
    "        res4 = self.block4(res, data)\n",
    "        res = torch.cat([res4, data.x], dim=1)\n",
    "        res = self.block5(res, data)\n",
    "        res = self.block6(res, data)\n",
    "        res = self.block7(res, data)\n",
    "        res = torch.cat([res, res4, data.x], dim=1)\n",
    "        res = self.block8(res, data)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(experiment_directory, checkpoint):\n",
    "    specs_filename = os.path.join(experiment_directory, \"specs.json\")\n",
    "\n",
    "    if not os.path.isfile(specs_filename):\n",
    "        raise Exception(\n",
    "            'The experiment directory does not include specifications file \"specs.json\"'\n",
    "        )\n",
    "\n",
    "    specs = json.load(open(specs_filename))\n",
    "\n",
    "    arch = __import__(\"networks.\" + specs[\"NetworkArch\"], fromlist=[\"Decoder\"])\n",
    "\n",
    "    latent_size = specs[\"CodeLength\"]\n",
    "\n",
    "    decoder = arch.Decoder(latent_size, **specs[\"NetworkSpecs\"])\n",
    "\n",
    "    decoder = torch.nn.DataParallel(decoder)\n",
    "\n",
    "    saved_model_state = torch.load(\n",
    "        os.path.join(experiment_directory, ws.model_params_subdir, checkpoint + \".pth\")\n",
    "    )\n",
    "    saved_model_epoch = saved_model_state[\"epoch\"]\n",
    "\n",
    "    decoder.load_state_dict(saved_model_state[\"model_state_dict\"])\n",
    "\n",
    "    decoder = decoder.module.cuda()\n",
    "\n",
    "    decoder.eval()\n",
    "    \n",
    "    return decoder\n",
    "def create_mesh(\n",
    "    decoder, latent_vec, filename='', N=256, max_batch=32 ** 3, offset=None, scale=None\n",
    "):\n",
    "    start = time.time()\n",
    "    ply_filename = filename\n",
    "\n",
    "    decoder.eval()\n",
    "\n",
    "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "    voxel_origin = [-1, -1, -1]\n",
    "    voxel_size = 2.0 / (N - 1)\n",
    "\n",
    "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "    samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z index\n",
    "    samples[:, 2] = overall_index % N\n",
    "    samples[:, 1] = (overall_index.long() / N) % N\n",
    "    samples[:, 0] = ((overall_index.long() / N) / N) % N\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z coordinate\n",
    "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
    "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
    "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
    "\n",
    "    num_samples = N ** 3\n",
    "\n",
    "    samples.requires_grad = False\n",
    "\n",
    "    head = 0\n",
    "\n",
    "    while head < num_samples:\n",
    "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()\n",
    "\n",
    "        samples[head : min(head + max_batch, num_samples), 3] = \\\n",
    "                decode_sdf(decoder, latent_vec, sample_subset).squeeze(1).detach().cpu()\n",
    "        head += max_batch\n",
    "\n",
    "    sdf_values = samples[:, 3]\n",
    "    sdf_values = sdf_values.reshape(N, N, N)\n",
    "\n",
    "    end = time.time()\n",
    "    #print(\"sampling takes: %f\" % (end - start))\n",
    "\n",
    "    return convert_sdf_samples_to_ply(\n",
    "        sdf_values.data.cpu(),\n",
    "        voxel_origin,\n",
    "        voxel_size,\n",
    "        ply_filename + \".ply\",\n",
    "        offset,\n",
    "        scale,\n",
    "    )\n",
    "\n",
    "def convert_sdf_samples_to_ply(\n",
    "    pytorch_3d_sdf_tensor,\n",
    "    voxel_grid_origin,\n",
    "    voxel_size,\n",
    "    ply_filename_out,\n",
    "    offset=None,\n",
    "    scale=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert sdf samples to .ply\n",
    "\n",
    "    :param pytorch_3d_sdf_tensor: a torch.FloatTensor of shape (n,n,n)\n",
    "    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n",
    "    :voxel_size: float, the size of the voxels\n",
    "    :ply_filename_out: string, path of the filename to save to\n",
    "\n",
    "    This function adapted from: https://github.com/RobotLocomotion/spartan\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    numpy_3d_sdf_tensor = pytorch_3d_sdf_tensor.numpy()\n",
    "\n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes_lewiner(\n",
    "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3\n",
    "    )\n",
    "\n",
    "    # transform from voxel coordinates to camera coordinates\n",
    "    # note x and y are flipped in the output of marching_cubes\n",
    "    mesh_points = np.zeros_like(verts)\n",
    "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
    "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
    "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
    "\n",
    "    # apply additional offset and scale\n",
    "    if scale is not None:\n",
    "        mesh_points = mesh_points / scale\n",
    "    if offset is not None:\n",
    "        mesh_points = mesh_points - offset\n",
    "\n",
    "    # try writing to the ply file\n",
    "\n",
    "    num_verts = verts.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "\n",
    "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "    norms_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "\n",
    "    for i in range(0, num_verts):\n",
    "        verts_tuple[i] = tuple(mesh_points[i, :])\n",
    "        norms_tuple[i] = tuple(normals[i, :])\n",
    "\n",
    "    faces_building = []\n",
    "    for i in range(0, num_faces):\n",
    "        faces_building.append(((faces[i, :].tolist(),)))\n",
    "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
    "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
    "    el_norms = plyfile.PlyElement.describe(norms_tuple, \"normals\")\n",
    "\n",
    "    ply_data = plyfile.PlyData([el_verts, el_faces, el_norms])\n",
    "    return ply_data\n",
    "\n",
    "def decode_sdf(decoder, latent_vector, queries):\n",
    "    num_samples = queries.shape[0]\n",
    "\n",
    "    if latent_vector is None:\n",
    "        inputs = queries\n",
    "    else:\n",
    "        latent_repeat = latent_vector.expand(num_samples, -1)\n",
    "        inputs = torch.cat([latent_repeat, queries], 1)\n",
    "\n",
    "    sdf = decoder(inputs)\n",
    "\n",
    "    return sdf\n",
    "\n",
    "def plot_points_from_torch(tensor):\n",
    "    cloud = PyntCloud(pd.DataFrame(tensor, columns=['x', 'y', 'z']))\n",
    "    cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qiu/Non-convex\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_instance= make_data_instance_from_stl(\n",
    "#                '/cvlabdata2/home/artem/Data/cars_remeshed_dsdf/outputs/fld/0003_0015.fld') # /cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0002_0005.fld\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# modelOld = SplineCNN8(3, batchnorm1=False)\n",
    "# modelOld.load_state_dict(torch.load(\"Expirements/SplineCNN8.nn\"))\n",
    "# modelOld = modelOld.to(device)\n",
    "\n",
    "model = SplineCNN8Residuals(3)\n",
    "model.load_state_dict(torch.load(\"/cvlabdata2/home/artem/DeepSDF/Expirements/Networks15/normilized_full_latest.nn\"))\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205 of latent vectors, each 256 long\n"
     ]
    }
   ],
   "source": [
    "experiment_directory = \"/cvlabdata2/home/artem/DeepSDF/examples/cars_cleared/\"\n",
    "checkpoint = \"latest\"\n",
    "\n",
    "AvgTransform = computeAvgTransform()\n",
    "decoder = load_model(experiment_directory, checkpoint).to('cuda:0')\n",
    "latent_vectors = ws.load_latent_vectors(experiment_directory, checkpoint)\n",
    "LATENT_KD_TREE = KDTree(np.array([lv.cpu().detach().numpy()[0] for lv in latent_vectors]))\n",
    "latent_size = latent_vectors[0].size()[1]\n",
    "print(f\"{len(latent_vectors)} of latent vectors, each {latent_size} long\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex-vise Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BB Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Foam Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Foam Furrier Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AtlasNet Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSDF Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method4_to_arbitatry_loss(points, ply_mesh, model, constraint_rad=0.1, axis=0):\n",
    "\n",
    "    initial_dir = points.grad.clone()\n",
    "    points.grad.data.zero_()\n",
    "\n",
    "    mesh = make_mesh_from_points(points, ply_mesh)\n",
    "    #signs = compute_signs_for_loss(mesh, transformPoints(normals, AvgTransform))\n",
    "    local_preds = model(mesh)\n",
    "    loss = calculate_loss(mesh, local_preds, axis=axis, constraint_rad=constraint_rad)\n",
    "    loss.backward()\n",
    "\n",
    "    sign = [-p1.dot(p2) for p1, p2 in zip(initial_dir, points.grad)]\n",
    "    \n",
    "    return sign, loss, local_preds, mesh\n",
    "\n",
    "def optimize_shape_deepSDF(decoder, latent, ref_latent, initial_points=None, num_points=None, \n",
    "                           num_iters=100, point_iters=100,  punch_lr_at_reindex_by=1, num_neignours_constr=10,\n",
    "                           reindex_latent_each=50, reindex_num_iterations=500, reindex_num_samples=100,\n",
    "                           lr=0.2, decreased_by=2, adjust_lr_every=10, alpha_penalty=0.05,\n",
    "                           multiplier_func=method4_to_arbitatry_loss, verbose=None, save_to_dir=None, N=256):\n",
    "\n",
    "    def adjust_learning_rate(\n",
    "        initial_lr, optimizer, num_iterations, decreased_by, adjust_lr_every\n",
    "    ):\n",
    "        lr = initial_lr * ((1 / decreased_by) ** (num_iterations // adjust_lr_every)) \\\n",
    "                        * ((punch_lr_at_reindex_by) ** (num_iterations // reindex_latent_each))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        return lr\n",
    "    \n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'meshes')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'meshes'))\n",
    "    if not os.path.exists(os.path.join(save_to_dir, 'predictions')):\n",
    "        os.makedirs(os.path.join(save_to_dir, 'predictions'))\n",
    "\n",
    "    decoder.eval()\n",
    "    latent = latent.clone()\n",
    "    latent.requires_grad = True\n",
    "    optimizer = torch.optim.SGD([latent], lr=lr)\n",
    "\n",
    "    loss_plot = []\n",
    "    latent_dist = []\n",
    "    lr_plot = []\n",
    "\n",
    "    #if initial_points is not None:\n",
    "    #    points = initial_points.clone()\n",
    "    #else:\n",
    "    #    points = get_points_from_latent(decoder, latent, N=N, point_num=num_points)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        time_start = time.time()\n",
    "\n",
    "        save_path = os.path.join(save_to_dir, 'meshes/' + str(i).zfill(5) + \".ply\")\n",
    "        preds_save_path = os.path.join(save_to_dir, 'predictions/' + str(i).zfill(5) + \".npy\")\n",
    "\n",
    "#             if i > 0 and i == reindex_latent_each:\n",
    "#                 new_latent = get_latent_from_mesh(decoder, latent_size=latent.size()[1], \n",
    "#                                                   num_iterations=reindex_num_iterations, \n",
    "#                                                   num_samples=reindex_num_samples)\n",
    "#                 latent = torch.Tensor(new_latent.cpu().detach().numpy()).cuda()\n",
    "#                 latent.requires_grad = True\n",
    "#                 optimizer = torch.optim.Adam([latent], lr=lr)\n",
    "\n",
    "        cur_rl = adjust_learning_rate(lr, optimizer, i, decreased_by, adjust_lr_every)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ply_mesh = create_mesh( decoder,\n",
    "                                    latent,\n",
    "                                    N=N,\n",
    "                                    max_batch=int(2 ** 18),\n",
    "                                    offset=None,\n",
    "                                    scale=None)\n",
    "\n",
    "        points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                                    ply_mesh['vertex']['y'][:, None], \n",
    "                                                    ply_mesh['vertex']['z'][:, None])))\n",
    "\n",
    "        points.requires_grad = True\n",
    "\n",
    "        sdf_value = deep_sdf.utils.decode_sdf(decoder, latent, points)\n",
    "        sdf_value.backward(torch.ones([len(points), 1], dtype=torch.float32).cuda())\n",
    "\n",
    "        mults, loss_value, preds, transformed_mesh = multiplier_func(points, ply_mesh)         \n",
    "        multipliers = torch.cuda.FloatTensor(mults)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sdf_value = torch.squeeze(deep_sdf.utils.decode_sdf(decoder, latent, points))\n",
    "\n",
    "        final_loss = torch.sum(sdf_value * multipliers)\n",
    "        final_loss.backward()\n",
    "#             print( \"Latent size: \", torch.sum(latent ** 2) )\n",
    "#             print( \"Latent grad: \", torch.sum(latent.grad ** 2) )\n",
    "\n",
    "#           sdf_value.backward(multipliers)\n",
    "\n",
    "\n",
    "        # Soft-constraints\n",
    "        distances, indeces = LATENT_KD_TREE.query(latent.cpu().detach(), k=num_neignours_constr)\n",
    "        penalty = torch.mean(\n",
    "                    torch.stack([torch.sum( \n",
    "                                    (latent - latent_vectors[indeces[0][i]]) ** 2\n",
    "                                 )\n",
    "                                 for i in range(len(indeces[0]))]\n",
    "                               )\n",
    "                    )\n",
    "        apenalty = penalty * alpha_penalty\n",
    "        apenalty.backward()\n",
    "        #print(\"Latent grad penalized: \", torch.sum(latent.grad ** 2))\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        tri_mesh = get_trimesh_from_torch_geo_with_colors(transformed_mesh, preds)\n",
    "        tri_mesh.export(save_path)\n",
    "        np.save(preds_save_path, preds.cpu().detach().numpy())\n",
    "\n",
    "        #if save_to_dir is not None:\n",
    "        #    plot_points_from_torch\n",
    "\n",
    "        loss_plot.append(loss_value.cpu().detach().numpy())\n",
    "        latent_dist.append(torch.sum((latent - ref_latent) ** 2 ).cpu().detach().numpy() )\n",
    "        lr_plot.append(penalty.cpu().detach().numpy())\n",
    "\n",
    "        time_end = time.time()\n",
    "\n",
    "        if verbose is not None and i % verbose == 0:\n",
    "            print('Iter ', i, 'Loss: ', loss_value.detach().cpu().numpy(), ' LD: ', lr_plot[-1])\n",
    "        np.save(os.path.join(save_to_dir, \"latent%d.npy\" % i), latent.cpu().detach().numpy())\n",
    "        \n",
    "    np.save(os.path.join(save_to_dir, \"loss_plot.npy\"), loss_plot)\n",
    "    np.save(os.path.join(save_to_dir, \"latent_dist.npy\"), latent_dist)\n",
    "    np.save(os.path.join(save_to_dir, \"lr_plot.npy\"), lr_plot)\n",
    "\n",
    "\n",
    "\n",
    "def make_full_transformation(initial_latent, ref_latent, experiment_name, \n",
    "                             decoder, model, alpha_penalty=0.05, constraint_rad=0.1, axis=0, **kwargs):\n",
    "    '''\n",
    "    kwargs:\n",
    "        num_iters=1000, \n",
    "        adjust_lr_every=10, \n",
    "        decreased_by=1.2,\n",
    "        lr=0.005,\n",
    "        \n",
    "        reindex_latent_each=100,\n",
    "        punch_lr_at_reindex_by=1,\n",
    "        reindex_num_iterations=500, \n",
    "        reindex_num_samples=100,\n",
    "        \n",
    "        verbose=10,\n",
    "    '''\n",
    "\n",
    "    #ref_points = get_points_from_latent(decoder, ref_latent, N=128)\n",
    "\n",
    "    save_to_dir = experiment_name\n",
    "    if not os.path.exists(save_to_dir):\n",
    "        os.makedirs(save_to_dir)\n",
    "\n",
    "    #np.save(os.path.join(save_to_dir, \"target_verts.npy\"), ref_points)\n",
    "\n",
    "    optimize_shape_deepSDF(decoder, initial_latent, ref_latent, initial_points=None,\n",
    "                                           alpha_penalty=alpha_penalty,\n",
    "                                           num_points=None, point_iters=2,\n",
    "                                           multiplier_func=lambda x, y: \n",
    "                                               method4_to_arbitatry_loss(x, y, model, \n",
    "                                                                         constraint_rad=constraint_rad, \n",
    "                                                                         axis=axis),\n",
    "                                           save_to_dir=save_to_dir, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0 Loss:  0.09731689  LD:  0.3987185\n",
      "Iter  1 Loss:  0.0863896  LD:  0.36342707\n",
      "Iter  2 Loss:  0.090333864  LD:  0.34481293\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(102)\n",
    "LATENT_TO_OPTIMIZE = latent_vectors[32]\n",
    "make_full_transformation(LATENT_TO_OPTIMIZE.detach(), LATENT_TO_OPTIMIZE.clone(), \n",
    "                                    'Experiments/OptimizationPaper/', decoder, model,\n",
    "                         alpha_penalty=0.2, axis=0,\n",
    "                         constraint_rad=0.05,\n",
    "                         num_iters=5,\n",
    "                         adjust_lr_every=20,\n",
    "                         decreased_by=1.1, \n",
    "                         lr=0.2,\n",
    "                         verbose=1,\n",
    "                         N=256,\n",
    "                         num_neignours_constr=10,\n",
    "                         reindex_latent_each=10000,\n",
    "                         punch_lr_at_reindex_by=1,\n",
    "                         reindex_num_iterations=500,\n",
    "                         reindex_num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Iter  0 Loss:  0.09731689  LD:  0.3987185\n",
    "Iter  1 Loss:  0.08640832  LD:  0.36342707\n",
    "Iter  2 Loss:  0.09052619  LD:  0.34481156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load(\"Expirements/OptimizationPaper/predictions/00000.npy\")\n",
    "mesh = trimesh.load_mesh(\"Expirements/OptimizationPaper/meshes/00000.ply\")\n",
    "loss_plot = np.load(\"Expirements/OptimizationPaper/loss_plot.npy\", allow_pickle=True)\n",
    "lr_plot = np.load(\"Expirements/OptimizationPaper/lr_plot.npy\", allow_pickle=True)\n",
    "latent0 = np.load(\"Expirements/OptimizationPaper/latent0.npy\", allow_pickle=True)\n",
    "latent1 = np.load(\"Expirements/OptimizationPaper/latent1.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13065428, -0.01960552, -0.06631227,  0.02476818], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09731689, 0.0864084 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_TO_OPTIMIZE = latent_vectors[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028872395351264624"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(LATENT_TO_OPTIMIZE.detach().cpu().numpy() - latent1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01667565, 0.0288724 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dist = np.load(\"Expirements/OptimizationPaper/latent_dist.npy\")\n",
    "latent_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([tensor(0.3987, device='cuda:0', requires_grad=True),\n",
       "       tensor(0.3634, device='cuda:0', requires_grad=True)], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh2 =  trimesh.load_mesh(\"Expirements/OptimizationPaper/meshes/00001.ply\")\n",
    "#mesh2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesh.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(mesh, local_preds, axis=0, constraint_rad=0.1):\n",
    "    loss =  (1 - axis) * compute_lift_faces_diff(mesh, local_preds, axis=0) + \\\n",
    "                  axis * compute_lift_faces_diff(mesh, local_preds, axis=1)\n",
    "    \n",
    "    loss += boundsLoss(mesh.x, box=[(-0.6, 0.6, 0)])\n",
    "    loss += innerBoundsLoss(mesh.x, r=constraint_rad**2, center=(-0.15, 0.05, 0))  \\\n",
    "          + innerBoundsLoss(mesh.x, r=(constraint_rad / 2)**2, center=(0.3, 0, 0))\n",
    "    return loss\n",
    "\n",
    "make_full_transformation(LATENT_TO_OPTIMIZE.detach(), LATENT_TO_OPTIMIZE.clone(), \n",
    "                                    'Expirements/OptimizationPaper/' + experiment_dir + '/32/cabinBackSmall15', decoder, model,\n",
    "                         alpha_penalty=0.2, axis=0,\n",
    "                         constraint_rad=0.05,\n",
    "                         num_iters=30,\n",
    "                         adjust_lr_every=20,\n",
    "                         decreased_by=1.1, \n",
    "                         lr=0.2,\n",
    "                         verbose=None,\n",
    "                         N=256,\n",
    "                         num_neignours_constr=10,\n",
    "                         reindex_latent_each=10000,\n",
    "                         punch_lr_at_reindex_by=1,\n",
    "                         reindex_num_iterations=500,\n",
    "                         reindex_num_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/ListenerCheck/processed/fld/0000_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/ListenerCheck/processed/fld/0001_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "npar = np.genfromtxt(\"/cvlabdata2/home/artem/Data/check_simulations/ListenerCheck/processed/fld/0002_0005.fld\", delimiter=',', skip_header=1)\n",
    "plt.hist(npar[:, 3], bins=100, alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di0 = make_data_instance_from_stl(\"../Expirements/SimulatedResults/foam_npy/fld/0000_0005.fld\")\n",
    "di1 = make_data_instance_from_stl(\"../Expirements/SimulatedResults/foam_npy/fld/0001_0005.fld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(di0.y[:, 0], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(di1.y[:, 0], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load('/cvlabdata2/home/artem/Data/cars_refined/simulated/stl/0005.stl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Expirements/SavedTransforms/DeepSDF-CFD8-m3-holes/meshes/00000.ply'\n",
    "tri_mesh = trimesh.load(path)\n",
    "points = torch.tensor(tri_mesh.vertices, dtype=torch.float).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innerBoundsLoss(points, r=0.12**2, center=(0.55, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "bvecs = genfromtxt('examples/cars/vine_latentVecs_tll_0.1_1.csv', delimiter=' ', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvecs = [torch.FloatTensor(v).to('cuda:0') for v in bvecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_mesh = create_mesh( decoder,\n",
    "                        latent_vectors[0],\n",
    "                        N=128,\n",
    "                        max_batch=int(2 ** 18),\n",
    "                        offset=None,\n",
    "                        scale=None)\n",
    "\n",
    "points = torch.cuda.FloatTensor(\n",
    "    np.array([ply_mesh['vertex']['x'], ply_mesh['vertex']['y'], ply_mesh['vertex']['z']]).transpose()\n",
    ")\n",
    "\n",
    "transformed_points = make_mesh_from_points(points, ply_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(transformed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = get_trimesh_from_torch_geo_with_colors(transformed_points, pred.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = mesh.export('examples/cars/BeautifiedMeshes/o0.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_latent_from_mesh_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = trimesh.geometry.faces_to_edges(ply_mesh['face']['vertex_indices'])\n",
    "edge_attr = torch.stack([points[a] - points[b] for a, b in edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_attr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(points.cpu().detach().numpy(), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(points_transformed.cpu().detach().numpy(), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = make_data_instance_from_stl('/cvlabdata2/home/artem/Data/cars_refined/simulated/fld/0007_0005.fld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = get_trimesh_from_torch_geo_with_colors(di, di.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(di.pos.cpu().detach().numpy(), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(transformed_points.pos.cpu().detach().numpy(), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ply_mesh = create_mesh( decoder,\n",
    "                            latent,\n",
    "                            N=128,\n",
    "                            max_batch=int(2 ** 18),\n",
    "                            offset=None,\n",
    "                            scale=None)\n",
    "\n",
    "points = torch.cuda.FloatTensor(np.hstack(( ply_mesh['vertex']['x'][:, None], \n",
    "                                            ply_mesh['vertex']['y'][:, None], \n",
    "                                            ply_mesh['vertex']['z'][:, None])))\n",
    "\n",
    "mesh = trimesh.Trimesh(vertices=points.cpu().detach(), faces=ply_mesh['face']['vertex_indices'])\n",
    "edge_attr = [mesh.vertices[a] - mesh.vertices[b] for a, b in mesh.edges]\n",
    "\n",
    "data = torch_geometric.data.Data(x  = points, \n",
    "                                 pos= torch.tensor(mesh.vertices, dtype=torch.float).to('cuda:0'), \n",
    "                                 faces = torch.tensor(mesh.faces, dtype=torch.long).to('cuda:0'),\n",
    "                                 edge_attr = torch.tensor(edge_attr, dtype=torch.float).to('cuda:0'),\n",
    "                                 edge_index= torch.tensor(mesh.edges, dtype=torch.long).t().contiguous().to('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_instance= make_data_instance_from_stl(\n",
    "                    '/cvlabsrc1/cvlab/dataset_shapenet/code/foam_npy/fld/0100_0005.fld', data_step=1)\n",
    "mesh = trimesh.Trimesh(vertices=data_instance.pos, faces=data_instance.faces)\n",
    "a = mesh.export('../Expirements/data/original_mesh.ply')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirements with PreprocessMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = get_latent_from_mesh_cpu(decoder, latent_size, mesh, num_iterations=300, num_samples=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_gpu = get_latent_from_mesh(decoder, latent_size, mesh_path='../Expirements/data/original_mesh.ply', \n",
    "                         num_iterations=300, num_samples=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_points = deep_sdf.data.read_sdf_samples_into_ram('../Expirements/data/original_SDF.npz')\n",
    "gpu_points[1][:, 3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(np.array(gpu_points[0][:, :3]), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.03, elev=-45, azim=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points, sdf = sample_sdf_near_surface(mesh)\n",
    "sdfs = np.hstack((points, sdf[:, None]))\n",
    "data_sdf = [torch.from_numpy(sdfs[sdfs[:, 3] > 0, :]), \n",
    "            torch.from_numpy(sdfs[sdfs[:, 3] < 0, :])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_sdf[0].shape)\n",
    "print(gpu_points[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = PyntCloud(pd.DataFrame(np.array(data_sdf[0][:, :3]), columns=['x', 'y', 'z']))\n",
    "cloud.plot(background='white', initial_point_size=0.03, elev=-45, azim=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_from_vector(decoder, latent, N=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plydata = create_mesh(decoder, latent_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plydata.write(\"../Expirements/mesh.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
